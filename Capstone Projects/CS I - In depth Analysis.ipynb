{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bike Sharing Dataset using Decision Tree Regressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>This is Supervised problem as the output datasets are provided and I used this to predict the future outcomes of target variable.\n",
    "    \n",
    "This is regression problem as dependent variable i.e. Bike Rental Count is continuous values or ordered whole values. Regression means to predict the output value using training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Based on Bike Sharing dataset from UCI Machine Learning Repository\n",
    "This notebook is based upon the hourly data file, i.e. hour.csv\n",
    "This notebook showcases regression using Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the Bike Sharing dataset with hourly level information of bikes along with weather, User type Registered/Casual and other attributes, model a system which can predict the bike count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# data manuipulation\n",
    "import numpy as np \n",
    "#library for the Python programming language, \n",
    "#adding support for large, multi-dimensional arrays and matrices, \n",
    "#along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "import pandas as pd\n",
    "#Data Analysis Library. pandas is an open source, BSD-licensed library \n",
    "#providing high-performance, \n",
    "#easy-to-use data structures and data analysis tools for the Python programming language\n",
    "\n",
    "# modeling utilities\n",
    "import pydotplus\n",
    "#PyDotPlus is an improved version of the \n",
    "#old pydot project that provides a Python Interface to Graphviz’s Dot language\n",
    "from sklearn import tree\n",
    "#Decision Tree regressor\n",
    "from sklearn import metrics\n",
    "#Metrics accuracy score\n",
    "from sklearn import preprocessing\n",
    "#pre-processing refers to the transformations centering/scaling\n",
    "#applied to your data before feeding it to the algorithm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#GridSearchCV implements a “fit” and a “score” method. It also implements “predict”, \n",
    "#“predict_proba”, “decision_function”, \n",
    "#“transform” and “inverse_transform” if they are implemented in the estimator used.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#cross_val_score uses KFold cross-validation. \n",
    "#This works by splitting the data set into K equal folds\n",
    "from sklearn.model_selection import train_test_split\n",
    "#the data we use is usually split into training data and test data. The training set contains a known \n",
    "#output and the model learns on this data in order to be generalized to other data later on\n",
    "\n",
    "\n",
    "# plotting libraries\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "\n",
    "sn.set_style('whitegrid')\n",
    "sn.set_context('talk')\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (30, 10),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "stats = pd.read_csv('hour.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of dataset\n",
    "stats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>The dataset contains more than 17K records with 17 features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/1/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/1/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/1/11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  1/1/11       1   0     1   0        0        6           0   \n",
       "1        2  1/1/11       1   0     1   1        0        6           0   \n",
       "2        3  1/1/11       1   0     1   2        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 3 rows from the dataset\n",
    "stats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 17 columns):\n",
      "instant       17379 non-null int64\n",
      "dteday        17379 non-null object\n",
      "season        17379 non-null int64\n",
      "yr            17379 non-null int64\n",
      "mnth          17379 non-null int64\n",
      "hr            17379 non-null int64\n",
      "holiday       17379 non-null int64\n",
      "weekday       17379 non-null int64\n",
      "workingday    17379 non-null int64\n",
      "weathersit    17379 non-null int64\n",
      "temp          17379 non-null float64\n",
      "atemp         17379 non-null float64\n",
      "hum           17379 non-null float64\n",
      "windspeed     17379 non-null float64\n",
      "casual        17379 non-null int64\n",
      "registered    17379 non-null int64\n",
      "cnt           17379 non-null int64\n",
      "dtypes: float64(4), int64(12), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#finding if any nulls and data types of the features\n",
    "stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Renaming the columns, Type casting the attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.rename(columns = {'instant': 'rec_id',\n",
    "                       'dteday':'datetime',\n",
    "                       'holiday': 'is_holiday',\n",
    "                       'workingday': 'is_workingday',\n",
    "                       'weathersit': 'weather_condition',\n",
    "                       'hum': 'humidity', \n",
    "                       'mnth': 'month',\n",
    "                       'cnt': 'total_count',\n",
    "                       'hr': 'hour',\n",
    "                       'yr': 'year'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type casting the attributes\n",
    "stats['datetime'] = pd.to_datetime(stats.datetime)#dae time conversion\n",
    "# categorical variables\n",
    "stats['season'] = stats.season.astype('category')\n",
    "stats['is_holiday'] = stats.is_holiday.astype('category')\n",
    "stats['weekday'] = stats.weekday.astype('category')\n",
    "stats['weather_condition'] = stats.weather_condition.astype('category')\n",
    "stats['is_workingday'] = stats.is_workingday.astype('category')\n",
    "stats['month'] = stats.month.astype('category')\n",
    "stats['year'] = stats.year.astype('category')\n",
    "stats['hour'] = stats.hour.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Decision Tree Regression on All the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the DEcision Tree Regression Model to the dataset\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X, X_test, y, y_test = train_test_split(stats.iloc[:,2:-3], stats.iloc[:,16], \n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([360., 103.,   9., ..., 182., 563., 136.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      season year month hour is_holiday weekday is_workingday  \\\n",
      "5749       3    0     9    0          0       5             1   \n",
      "1843       2    0     3   13          0       2             1   \n",
      "13855      3    1     8   12          0       0             0   \n",
      "9723       1    1     2    2          0       3             1   \n",
      "10981      2    1     4   17          0       6             0   \n",
      "1285       1    0     2   17          0       6             0   \n",
      "16759      4    1    12    2          0       4             1   \n",
      "4303       3    0     7    5          0       0             0   \n",
      "6366       4    0     9   20          0       2             1   \n",
      "1941       2    0     3   16          0       6             0   \n",
      "16397      4    1    11   23          0       2             1   \n",
      "1091       1    0     2    5          0       5             1   \n",
      "6891       4    0    10   18          0       3             1   \n",
      "73         1    0     1    5          0       2             1   \n",
      "3397       2    0     5   11          0       4             1   \n",
      "14067      3    1     8    8          0       2             1   \n",
      "8604       1    0    12    7          0       5             1   \n",
      "4192       3    0     6   14          0       2             1   \n",
      "14875      3    1     9    0          0       1             1   \n",
      "14488      3    1     8   21          0       5             1   \n",
      "9149       1    1     1    3          0       0             0   \n",
      "5064       3    0     8   22          0       3             1   \n",
      "4387       3    0     7   17          0       3             1   \n",
      "17126      1    1    12    9          0       5             1   \n",
      "16539      4    1    11   21          0       1             1   \n",
      "12560      2    1     6   13          0       2             1   \n",
      "10269      1    1     3   23          0       4             1   \n",
      "14106      3    1     8   23          0       3             1   \n",
      "13139      3    1     7   16          0       5             1   \n",
      "7882       4    0    11    2          0       3             1   \n",
      "...      ...  ...   ...  ...        ...     ...           ...   \n",
      "14502      3    1     9   11          0       6             0   \n",
      "8838       1    1     1    2          0       1             1   \n",
      "3890       2    0     6    0          0       4             1   \n",
      "3556       2    0     6    2          0       4             1   \n",
      "11394      2    1     4   23          0       2             1   \n",
      "1267       1    0     2   23          0       5             1   \n",
      "1899       2    0     3   22          0       4             1   \n",
      "3005       2    0     5    3          0       2             1   \n",
      "189        1    0     1    4          0       0             0   \n",
      "2747       2    0     4    9          0       5             1   \n",
      "8666       1    1     1   21          0       0             0   \n",
      "6396       4    0     9    2          0       4             1   \n",
      "6420       4    0     9    2          0       5             1   \n",
      "5051       3    0     8    9          0       3             1   \n",
      "5311       3    0     8    5          0       0             0   \n",
      "2433       2    0     4    7          0       6             0   \n",
      "769        1    0     2   12          0       5             1   \n",
      "1685       1    0     3   20          0       2             1   \n",
      "8322       4    0    12   10          0       0             0   \n",
      "16023      4    1    11    8          0       1             1   \n",
      "11363      2    1     4   16          0       1             1   \n",
      "14423      3    1     8    4          0       3             1   \n",
      "4426       3    0     7    8          0       5             1   \n",
      "16850      4    1    12   21          0       0             0   \n",
      "6265       4    0     9   15          0       5             1   \n",
      "11284      2    1     4    9          0       5             1   \n",
      "11964      2    1     5   17          0       5             1   \n",
      "5390       3    0     8   12          0       3             1   \n",
      "860        1    0     2    7          0       2             1   \n",
      "15795      4    1    10    8          0       4             1   \n",
      "\n",
      "      weather_condition  temp   atemp  humidity  windspeed  \n",
      "5749                  1  0.64  0.6061      0.65     0.1940  \n",
      "1843                  1  0.50  0.4848      0.45     0.2239  \n",
      "13855                 1  0.86  0.8030      0.47     0.5224  \n",
      "9723                  1  0.30  0.3333      0.61     0.0000  \n",
      "10981                 1  0.54  0.5152      0.19     0.4179  \n",
      "1285                  1  0.36  0.3485      0.43     0.2239  \n",
      "16759                 1  0.24  0.2121      0.52     0.2836  \n",
      "4303                  3  0.62  0.5758      0.83     0.1940  \n",
      "6366                  1  0.62  0.5909      0.78     0.0000  \n",
      "1941                  1  0.34  0.3333      0.23     0.1940  \n",
      "16397                 1  0.32  0.3333      0.81     0.1045  \n",
      "1091                  2  0.46  0.4545      0.67     0.1045  \n",
      "6891                  3  0.56  0.5303      1.00     0.1642  \n",
      "73                    1  0.12  0.1515      0.68     0.1045  \n",
      "3397                  1  0.74  0.6970      0.66     0.2239  \n",
      "14067                 2  0.66  0.5909      0.89     0.0896  \n",
      "8604                  1  0.24  0.2576      0.75     0.0896  \n",
      "4192                  1  0.86  0.7879      0.44     0.2239  \n",
      "14875                 1  0.54  0.5152      0.68     0.1642  \n",
      "14488                 1  0.76  0.7121      0.58     0.1940  \n",
      "9149                  2  0.18  0.1667      0.69     0.2836  \n",
      "5064                  3  0.68  0.6364      0.89     0.1045  \n",
      "4387                  1  0.78  0.7424      0.59     0.2239  \n",
      "17126                 2  0.32  0.2727      0.45     0.5522  \n",
      "16539                 1  0.34  0.3636      0.49     0.0000  \n",
      "12560                 3  0.66  0.6061      0.83     0.1940  \n",
      "10269                 2  0.56  0.5303      0.49     0.4478  \n",
      "14106                 1  0.68  0.6364      0.65     0.1045  \n",
      "13139                 1  0.92  0.8182      0.29     0.1045  \n",
      "7882                  1  0.32  0.3182      0.70     0.1642  \n",
      "...                 ...   ...     ...       ...        ...  \n",
      "14502                 2  0.80  0.7576      0.55     0.2239  \n",
      "8838                  1  0.24  0.2424      0.56     0.1343  \n",
      "3890                  1  0.60  0.6212      0.56     0.1045  \n",
      "3556                  1  0.70  0.6364      0.39     0.0000  \n",
      "11394                 1  0.42  0.4242      0.38     0.0896  \n",
      "1267                  1  0.26  0.2273      0.48     0.3284  \n",
      "1899                  1  0.26  0.2576      0.65     0.1642  \n",
      "3005                  1  0.44  0.4394      0.54     0.1940  \n",
      "189                   1  0.08  0.0909      0.53     0.1940  \n",
      "2747                  1  0.54  0.5152      0.39     0.3284  \n",
      "8666                  2  0.44  0.4394      0.67     0.2537  \n",
      "6396                  2  0.60  0.5000      1.00     0.1940  \n",
      "6420                  1  0.52  0.5000      0.83     0.1045  \n",
      "5051                  2  0.74  0.6818      0.55     0.1940  \n",
      "5311                  2  0.64  0.5606      0.94     0.1642  \n",
      "2433                  2  0.40  0.4091      0.82     0.4179  \n",
      "769                   2  0.24  0.2424      0.48     0.1642  \n",
      "1685                  2  0.34  0.3182      0.71     0.2836  \n",
      "8322                  1  0.24  0.2273      0.60     0.2537  \n",
      "16023                 2  0.30  0.2879      0.49     0.2239  \n",
      "11363                 3  0.30  0.2727      0.81     0.3582  \n",
      "14423                 1  0.60  0.5909      0.73     0.2239  \n",
      "4426                  2  0.72  0.6970      0.74     0.2537  \n",
      "16850                 2  0.36  0.3636      1.00     0.1045  \n",
      "6265                  3  0.62  0.5455      0.94     0.1045  \n",
      "11284                 1  0.46  0.4545      0.88     0.0896  \n",
      "11964                 1  0.66  0.6212      0.34     0.1343  \n",
      "5390                  1  0.80  0.7273      0.43     0.2836  \n",
      "860                   1  0.24  0.1970      0.65     0.4179  \n",
      "15795                 2  0.52  0.5000      0.83     0.1642  \n",
      "\n",
      "[11643 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8857883669426379"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default scoring mechanism for any Regression ML model is R2. This metric quantifies the amount of variance in the target variable that is predicted from the feautre variable. I find this score far better than the score I got with Linear Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Cross Validation 5-folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid the prediction of target variable by the split % of train & test data, Cross validation method is introduced to group the data into 5(or K) folds and performing train-test split & prediction on each fold iteratively and we predict the value of R2 5 times. Then from here we may compute Mean, Median or 95% Confidence Interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87212515 0.83738118 0.85254783 0.86757887 0.86173096]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#reg = linear_model.LinearRegression()\n",
    "cv_results = cross_val_score(regressor.fit(X,y), X_test, y_test, cv= 5)\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8582727961896776"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores = cross_val_score(regressor.fit(X,y), X_test, y_test, cv=5)\n",
    "mse_scores = cross_val_score(regressor.fit(X,y), X_test, y_test, cv=5,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1029f310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot([i for i in range(len(r2_scores))],r2_scores,lw=2)\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('R-Squared')\n",
    "ax.title.set_text(\"Cross Validation Scores, Avg:{}\".format(np.average(r2_scores)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared::[0.87212515 0.83738118 0.85254783 0.86757887 0.86173096]\n",
      "MSE::[-3813.68031359 -5214.48496077 -4904.86312119 -4390.91891892\n",
      " -4304.16325196]\n"
     ]
    }
   ],
   "source": [
    "print(\"R-squared::{}\".format(r2_scores))\n",
    "print(\"MSE::{}\".format(mse_scores))\n",
    "# print(\"R-Squared::{}\".format(grid_cv_dtr.best_score_))\n",
    "# print(\"Best Hyperparameters::\\n{}\".format(grid_cv_dtr.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> On applying cross validation R2 average is lowered to 0.86 from 0.885 Decision Tree regressor score. This may be due to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Regularized Ridge Regression in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39024245916347916"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha =0.1, normalize=True)\n",
    "ridge.fit(X, y)\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      season year month hour is_holiday weekday is_workingday  \\\n",
      "5749       3    0     9    0          0       5             1   \n",
      "1843       2    0     3   13          0       2             1   \n",
      "13855      3    1     8   12          0       0             0   \n",
      "9723       1    1     2    2          0       3             1   \n",
      "10981      2    1     4   17          0       6             0   \n",
      "1285       1    0     2   17          0       6             0   \n",
      "16759      4    1    12    2          0       4             1   \n",
      "4303       3    0     7    5          0       0             0   \n",
      "6366       4    0     9   20          0       2             1   \n",
      "1941       2    0     3   16          0       6             0   \n",
      "16397      4    1    11   23          0       2             1   \n",
      "1091       1    0     2    5          0       5             1   \n",
      "6891       4    0    10   18          0       3             1   \n",
      "73         1    0     1    5          0       2             1   \n",
      "3397       2    0     5   11          0       4             1   \n",
      "14067      3    1     8    8          0       2             1   \n",
      "8604       1    0    12    7          0       5             1   \n",
      "4192       3    0     6   14          0       2             1   \n",
      "14875      3    1     9    0          0       1             1   \n",
      "14488      3    1     8   21          0       5             1   \n",
      "9149       1    1     1    3          0       0             0   \n",
      "5064       3    0     8   22          0       3             1   \n",
      "4387       3    0     7   17          0       3             1   \n",
      "17126      1    1    12    9          0       5             1   \n",
      "16539      4    1    11   21          0       1             1   \n",
      "12560      2    1     6   13          0       2             1   \n",
      "10269      1    1     3   23          0       4             1   \n",
      "14106      3    1     8   23          0       3             1   \n",
      "13139      3    1     7   16          0       5             1   \n",
      "7882       4    0    11    2          0       3             1   \n",
      "...      ...  ...   ...  ...        ...     ...           ...   \n",
      "14502      3    1     9   11          0       6             0   \n",
      "8838       1    1     1    2          0       1             1   \n",
      "3890       2    0     6    0          0       4             1   \n",
      "3556       2    0     6    2          0       4             1   \n",
      "11394      2    1     4   23          0       2             1   \n",
      "1267       1    0     2   23          0       5             1   \n",
      "1899       2    0     3   22          0       4             1   \n",
      "3005       2    0     5    3          0       2             1   \n",
      "189        1    0     1    4          0       0             0   \n",
      "2747       2    0     4    9          0       5             1   \n",
      "8666       1    1     1   21          0       0             0   \n",
      "6396       4    0     9    2          0       4             1   \n",
      "6420       4    0     9    2          0       5             1   \n",
      "5051       3    0     8    9          0       3             1   \n",
      "5311       3    0     8    5          0       0             0   \n",
      "2433       2    0     4    7          0       6             0   \n",
      "769        1    0     2   12          0       5             1   \n",
      "1685       1    0     3   20          0       2             1   \n",
      "8322       4    0    12   10          0       0             0   \n",
      "16023      4    1    11    8          0       1             1   \n",
      "11363      2    1     4   16          0       1             1   \n",
      "14423      3    1     8    4          0       3             1   \n",
      "4426       3    0     7    8          0       5             1   \n",
      "16850      4    1    12   21          0       0             0   \n",
      "6265       4    0     9   15          0       5             1   \n",
      "11284      2    1     4    9          0       5             1   \n",
      "11964      2    1     5   17          0       5             1   \n",
      "5390       3    0     8   12          0       3             1   \n",
      "860        1    0     2    7          0       2             1   \n",
      "15795      4    1    10    8          0       4             1   \n",
      "\n",
      "      weather_condition  temp   atemp  humidity  windspeed  \n",
      "5749                  1  0.64  0.6061      0.65     0.1940  \n",
      "1843                  1  0.50  0.4848      0.45     0.2239  \n",
      "13855                 1  0.86  0.8030      0.47     0.5224  \n",
      "9723                  1  0.30  0.3333      0.61     0.0000  \n",
      "10981                 1  0.54  0.5152      0.19     0.4179  \n",
      "1285                  1  0.36  0.3485      0.43     0.2239  \n",
      "16759                 1  0.24  0.2121      0.52     0.2836  \n",
      "4303                  3  0.62  0.5758      0.83     0.1940  \n",
      "6366                  1  0.62  0.5909      0.78     0.0000  \n",
      "1941                  1  0.34  0.3333      0.23     0.1940  \n",
      "16397                 1  0.32  0.3333      0.81     0.1045  \n",
      "1091                  2  0.46  0.4545      0.67     0.1045  \n",
      "6891                  3  0.56  0.5303      1.00     0.1642  \n",
      "73                    1  0.12  0.1515      0.68     0.1045  \n",
      "3397                  1  0.74  0.6970      0.66     0.2239  \n",
      "14067                 2  0.66  0.5909      0.89     0.0896  \n",
      "8604                  1  0.24  0.2576      0.75     0.0896  \n",
      "4192                  1  0.86  0.7879      0.44     0.2239  \n",
      "14875                 1  0.54  0.5152      0.68     0.1642  \n",
      "14488                 1  0.76  0.7121      0.58     0.1940  \n",
      "9149                  2  0.18  0.1667      0.69     0.2836  \n",
      "5064                  3  0.68  0.6364      0.89     0.1045  \n",
      "4387                  1  0.78  0.7424      0.59     0.2239  \n",
      "17126                 2  0.32  0.2727      0.45     0.5522  \n",
      "16539                 1  0.34  0.3636      0.49     0.0000  \n",
      "12560                 3  0.66  0.6061      0.83     0.1940  \n",
      "10269                 2  0.56  0.5303      0.49     0.4478  \n",
      "14106                 1  0.68  0.6364      0.65     0.1045  \n",
      "13139                 1  0.92  0.8182      0.29     0.1045  \n",
      "7882                  1  0.32  0.3182      0.70     0.1642  \n",
      "...                 ...   ...     ...       ...        ...  \n",
      "14502                 2  0.80  0.7576      0.55     0.2239  \n",
      "8838                  1  0.24  0.2424      0.56     0.1343  \n",
      "3890                  1  0.60  0.6212      0.56     0.1045  \n",
      "3556                  1  0.70  0.6364      0.39     0.0000  \n",
      "11394                 1  0.42  0.4242      0.38     0.0896  \n",
      "1267                  1  0.26  0.2273      0.48     0.3284  \n",
      "1899                  1  0.26  0.2576      0.65     0.1642  \n",
      "3005                  1  0.44  0.4394      0.54     0.1940  \n",
      "189                   1  0.08  0.0909      0.53     0.1940  \n",
      "2747                  1  0.54  0.5152      0.39     0.3284  \n",
      "8666                  2  0.44  0.4394      0.67     0.2537  \n",
      "6396                  2  0.60  0.5000      1.00     0.1940  \n",
      "6420                  1  0.52  0.5000      0.83     0.1045  \n",
      "5051                  2  0.74  0.6818      0.55     0.1940  \n",
      "5311                  2  0.64  0.5606      0.94     0.1642  \n",
      "2433                  2  0.40  0.4091      0.82     0.4179  \n",
      "769                   2  0.24  0.2424      0.48     0.1642  \n",
      "1685                  2  0.34  0.3182      0.71     0.2836  \n",
      "8322                  1  0.24  0.2273      0.60     0.2537  \n",
      "16023                 2  0.30  0.2879      0.49     0.2239  \n",
      "11363                 3  0.30  0.2727      0.81     0.3582  \n",
      "14423                 1  0.60  0.5909      0.73     0.2239  \n",
      "4426                  2  0.72  0.6970      0.74     0.2537  \n",
      "16850                 2  0.36  0.3636      1.00     0.1045  \n",
      "6265                  3  0.62  0.5455      0.94     0.1045  \n",
      "11284                 1  0.46  0.4545      0.88     0.0896  \n",
      "11964                 1  0.66  0.6212      0.34     0.1343  \n",
      "5390                  1  0.80  0.7273      0.43     0.2836  \n",
      "860                   1  0.24  0.1970      0.65     0.4179  \n",
      "15795                 2  0.52  0.5000      0.83     0.1642  \n",
      "\n",
      "[11643 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Lasso Regression in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3779824852159332"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha =0.1, normalize=True)\n",
    "lasso.fit(X, y)\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      season year month hour is_holiday weekday is_workingday  \\\n",
      "5749       3    0     9    0          0       5             1   \n",
      "1843       2    0     3   13          0       2             1   \n",
      "13855      3    1     8   12          0       0             0   \n",
      "9723       1    1     2    2          0       3             1   \n",
      "10981      2    1     4   17          0       6             0   \n",
      "1285       1    0     2   17          0       6             0   \n",
      "16759      4    1    12    2          0       4             1   \n",
      "4303       3    0     7    5          0       0             0   \n",
      "6366       4    0     9   20          0       2             1   \n",
      "1941       2    0     3   16          0       6             0   \n",
      "16397      4    1    11   23          0       2             1   \n",
      "1091       1    0     2    5          0       5             1   \n",
      "6891       4    0    10   18          0       3             1   \n",
      "73         1    0     1    5          0       2             1   \n",
      "3397       2    0     5   11          0       4             1   \n",
      "14067      3    1     8    8          0       2             1   \n",
      "8604       1    0    12    7          0       5             1   \n",
      "4192       3    0     6   14          0       2             1   \n",
      "14875      3    1     9    0          0       1             1   \n",
      "14488      3    1     8   21          0       5             1   \n",
      "9149       1    1     1    3          0       0             0   \n",
      "5064       3    0     8   22          0       3             1   \n",
      "4387       3    0     7   17          0       3             1   \n",
      "17126      1    1    12    9          0       5             1   \n",
      "16539      4    1    11   21          0       1             1   \n",
      "12560      2    1     6   13          0       2             1   \n",
      "10269      1    1     3   23          0       4             1   \n",
      "14106      3    1     8   23          0       3             1   \n",
      "13139      3    1     7   16          0       5             1   \n",
      "7882       4    0    11    2          0       3             1   \n",
      "...      ...  ...   ...  ...        ...     ...           ...   \n",
      "14502      3    1     9   11          0       6             0   \n",
      "8838       1    1     1    2          0       1             1   \n",
      "3890       2    0     6    0          0       4             1   \n",
      "3556       2    0     6    2          0       4             1   \n",
      "11394      2    1     4   23          0       2             1   \n",
      "1267       1    0     2   23          0       5             1   \n",
      "1899       2    0     3   22          0       4             1   \n",
      "3005       2    0     5    3          0       2             1   \n",
      "189        1    0     1    4          0       0             0   \n",
      "2747       2    0     4    9          0       5             1   \n",
      "8666       1    1     1   21          0       0             0   \n",
      "6396       4    0     9    2          0       4             1   \n",
      "6420       4    0     9    2          0       5             1   \n",
      "5051       3    0     8    9          0       3             1   \n",
      "5311       3    0     8    5          0       0             0   \n",
      "2433       2    0     4    7          0       6             0   \n",
      "769        1    0     2   12          0       5             1   \n",
      "1685       1    0     3   20          0       2             1   \n",
      "8322       4    0    12   10          0       0             0   \n",
      "16023      4    1    11    8          0       1             1   \n",
      "11363      2    1     4   16          0       1             1   \n",
      "14423      3    1     8    4          0       3             1   \n",
      "4426       3    0     7    8          0       5             1   \n",
      "16850      4    1    12   21          0       0             0   \n",
      "6265       4    0     9   15          0       5             1   \n",
      "11284      2    1     4    9          0       5             1   \n",
      "11964      2    1     5   17          0       5             1   \n",
      "5390       3    0     8   12          0       3             1   \n",
      "860        1    0     2    7          0       2             1   \n",
      "15795      4    1    10    8          0       4             1   \n",
      "\n",
      "      weather_condition  temp   atemp  humidity  windspeed  \n",
      "5749                  1  0.64  0.6061      0.65     0.1940  \n",
      "1843                  1  0.50  0.4848      0.45     0.2239  \n",
      "13855                 1  0.86  0.8030      0.47     0.5224  \n",
      "9723                  1  0.30  0.3333      0.61     0.0000  \n",
      "10981                 1  0.54  0.5152      0.19     0.4179  \n",
      "1285                  1  0.36  0.3485      0.43     0.2239  \n",
      "16759                 1  0.24  0.2121      0.52     0.2836  \n",
      "4303                  3  0.62  0.5758      0.83     0.1940  \n",
      "6366                  1  0.62  0.5909      0.78     0.0000  \n",
      "1941                  1  0.34  0.3333      0.23     0.1940  \n",
      "16397                 1  0.32  0.3333      0.81     0.1045  \n",
      "1091                  2  0.46  0.4545      0.67     0.1045  \n",
      "6891                  3  0.56  0.5303      1.00     0.1642  \n",
      "73                    1  0.12  0.1515      0.68     0.1045  \n",
      "3397                  1  0.74  0.6970      0.66     0.2239  \n",
      "14067                 2  0.66  0.5909      0.89     0.0896  \n",
      "8604                  1  0.24  0.2576      0.75     0.0896  \n",
      "4192                  1  0.86  0.7879      0.44     0.2239  \n",
      "14875                 1  0.54  0.5152      0.68     0.1642  \n",
      "14488                 1  0.76  0.7121      0.58     0.1940  \n",
      "9149                  2  0.18  0.1667      0.69     0.2836  \n",
      "5064                  3  0.68  0.6364      0.89     0.1045  \n",
      "4387                  1  0.78  0.7424      0.59     0.2239  \n",
      "17126                 2  0.32  0.2727      0.45     0.5522  \n",
      "16539                 1  0.34  0.3636      0.49     0.0000  \n",
      "12560                 3  0.66  0.6061      0.83     0.1940  \n",
      "10269                 2  0.56  0.5303      0.49     0.4478  \n",
      "14106                 1  0.68  0.6364      0.65     0.1045  \n",
      "13139                 1  0.92  0.8182      0.29     0.1045  \n",
      "7882                  1  0.32  0.3182      0.70     0.1642  \n",
      "...                 ...   ...     ...       ...        ...  \n",
      "14502                 2  0.80  0.7576      0.55     0.2239  \n",
      "8838                  1  0.24  0.2424      0.56     0.1343  \n",
      "3890                  1  0.60  0.6212      0.56     0.1045  \n",
      "3556                  1  0.70  0.6364      0.39     0.0000  \n",
      "11394                 1  0.42  0.4242      0.38     0.0896  \n",
      "1267                  1  0.26  0.2273      0.48     0.3284  \n",
      "1899                  1  0.26  0.2576      0.65     0.1642  \n",
      "3005                  1  0.44  0.4394      0.54     0.1940  \n",
      "189                   1  0.08  0.0909      0.53     0.1940  \n",
      "2747                  1  0.54  0.5152      0.39     0.3284  \n",
      "8666                  2  0.44  0.4394      0.67     0.2537  \n",
      "6396                  2  0.60  0.5000      1.00     0.1940  \n",
      "6420                  1  0.52  0.5000      0.83     0.1045  \n",
      "5051                  2  0.74  0.6818      0.55     0.1940  \n",
      "5311                  2  0.64  0.5606      0.94     0.1642  \n",
      "2433                  2  0.40  0.4091      0.82     0.4179  \n",
      "769                   2  0.24  0.2424      0.48     0.1642  \n",
      "1685                  2  0.34  0.3182      0.71     0.2836  \n",
      "8322                  1  0.24  0.2273      0.60     0.2537  \n",
      "16023                 2  0.30  0.2879      0.49     0.2239  \n",
      "11363                 3  0.30  0.2727      0.81     0.3582  \n",
      "14423                 1  0.60  0.5909      0.73     0.2239  \n",
      "4426                  2  0.72  0.6970      0.74     0.2537  \n",
      "16850                 2  0.36  0.3636      1.00     0.1045  \n",
      "6265                  3  0.62  0.5455      0.94     0.1045  \n",
      "11284                 1  0.46  0.4545      0.88     0.0896  \n",
      "11964                 1  0.66  0.6212      0.34     0.1343  \n",
      "5390                  1  0.80  0.7273      0.43     0.2836  \n",
      "860                   1  0.24  0.1970      0.65     0.4179  \n",
      "15795                 2  0.52  0.5000      0.83     0.1642  \n",
      "\n",
      "[11643 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print ((X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((min(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1> ONE HOT ENCODING - The Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_ohe(df,col_name):\n",
    "    \"\"\"This function performs one hot encoding for the specified\n",
    "        column.\n",
    "\n",
    "    Args:\n",
    "        df(pandas.DataFrame): the data frame containing the mentioned column name\n",
    "        col_name: the column to be one hot encoded\n",
    "\n",
    "    Returns:\n",
    "        tuple: label_encoder, one_hot_encoder, transformed column as pandas Series\n",
    "\n",
    "    \"\"\"\n",
    "    # label encode the column\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le_labels = le.fit_transform(df[col_name])\n",
    "    df[col_name+'_label'] = le_labels\n",
    "    \n",
    "    # one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
    "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n",
    "    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "    \n",
    "    return le,ohe,features_df\n",
    "\n",
    "# given label encoder and one hot encoder objects, \n",
    "# encode attribute to ohe\n",
    "def transform_ohe(df,le,ohe,col_name):\n",
    "    \"\"\"This function performs one hot encoding for the specified\n",
    "        column using the specified encoder objects.\n",
    "\n",
    "    Args:\n",
    "        df(pandas.DataFrame): the data frame containing the mentioned column name\n",
    "        le(Label Encoder): the label encoder object used to fit label encoding\n",
    "        ohe(One Hot Encoder): the onen hot encoder object used to fit one hot encoding\n",
    "        col_name: the column to be one hot encoded\n",
    "\n",
    "    Returns:\n",
    "        tuple: transformed column as pandas Series\n",
    "\n",
    "    \"\"\"\n",
    "    # label encode\n",
    "    col_labels = le.transform(df[col_name]) \n",
    "    df[col_name+'_label'] = col_labels\n",
    "    \n",
    "    # ohe \n",
    "    feature_arr = ohe.fit_transform(df[[col_name+'_label']]).toarray()\n",
    "    feature_labels = [col_name+'_'+str(cls_label) for cls_label in le.classes_]\n",
    "    features_df = pd.DataFrame(feature_arr, columns=feature_labels)\n",
    "    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set::(11643, 15)(11643, 2)\n",
      "Testing set::(5736, 15)\n"
     ]
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(stats.iloc[:,2:-1], stats.iloc[:,-1], \n",
    "                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "X.reset_index(inplace=True)\n",
    "y = y.reset_index()\n",
    "\n",
    "X_test.reset_index(inplace=True)\n",
    "y_test = y_test.reset_index()\n",
    "\n",
    "print(\"Training set::{}{}\".format(X.shape,y.shape))\n",
    "print(\"Testing set::{}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index season year month hour is_holiday weekday is_workingday  \\\n",
      "0   5749      3    0     9    0          0       5             1   \n",
      "1   1843      2    0     3   13          0       2             1   \n",
      "2  13855      3    1     8   12          0       0             0   \n",
      "3   9723      1    1     2    2          0       3             1   \n",
      "4  10981      2    1     4   17          0       6             0   \n",
      "5   1285      1    0     2   17          0       6             0   \n",
      "6  16759      4    1    12    2          0       4             1   \n",
      "7   4303      3    0     7    5          0       0             0   \n",
      "8   6366      4    0     9   20          0       2             1   \n",
      "9   1941      2    0     3   16          0       6             0   \n",
      "\n",
      "  weather_condition  temp   atemp  humidity  windspeed  casual  registered  \n",
      "0                 1  0.64  0.6061      0.65     0.1940       6          58  \n",
      "1                 1  0.50  0.4848      0.45     0.2239      21          85  \n",
      "2                 1  0.86  0.8030      0.47     0.5224     161         330  \n",
      "3                 1  0.30  0.3333      0.61     0.0000       0           4  \n",
      "4                 1  0.54  0.5152      0.19     0.4179     299         268  \n",
      "5                 1  0.36  0.3485      0.43     0.2239      53         130  \n",
      "6                 1  0.24  0.2121      0.52     0.2836       0           9  \n",
      "7                 3  0.62  0.5758      0.83     0.1940       0           1  \n",
      "8                 1  0.62  0.5909      0.78     0.0000      17         221  \n",
      "9                 1  0.34  0.3333      0.23     0.1940     118         130  \n"
     ]
    }
   ],
   "source": [
    "print (X.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attr_list = ['season','is_holiday',\n",
    "                 'weather_condition','is_workingday',\n",
    "                 'hour','weekday','month','year']\n",
    "numeric_feature_cols = ['temp','humidity','windspeed','hour','weekday','month','year', 'casual', 'registered']\n",
    "subset_cat_features =  ['season','is_holiday','weather_condition','is_workingday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_attr_list = []\n",
    "for col in cat_attr_list:\n",
    "    return_obj = fit_transform_ohe(X,col)\n",
    "    encoded_attr_list.append({'label_enc':return_obj[0],\n",
    "                              'ohe_enc':return_obj[1],\n",
    "                              'feature_df':return_obj[2],\n",
    "                              'col_name':col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape::(11643, 21)\n"
     ]
    }
   ],
   "source": [
    "feature_df_list = [X[numeric_feature_cols]]\n",
    "feature_df_list.extend([enc['feature_df'] \\\n",
    "                        for enc in encoded_attr_list \\\n",
    "                        if enc['col_name'] in subset_cat_features])\n",
    "\n",
    "train_df_new = pd.concat(feature_df_list, axis=1)\n",
    "print(\"Shape::{}\".format(train_df_new.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_df_list = [X_test[numeric_feature_cols]]\n",
    "# feature_df_list.extend([enc['feature_df'] \\\n",
    "#                         for enc in encoded_attr_list \\\n",
    "#                         if enc['col_name'] in subset_cat_features])\n",
    "\n",
    "# train_df_new = pd.concat(feature_df_list, axis=1)\n",
    "# print(\"Shape::{}\".format(train_df_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Decision Tree based Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df_new\n",
    "y= y.total_count.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11643, 21), (11643, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = train_df_new\n",
    "# y_test= y.total_count.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5736, 15), (5736, 2))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Sample Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
       "           max_leaf_nodes=10, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth=4,\n",
    "                            min_samples_split=5,\n",
    "                            max_leaf_nodes=10)\n",
    "dtr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.957862935392204"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the coefficient of determination R^2 of the prediction.\n",
    "The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Grid Search With Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"criterion\": [\"mse\", \"mae\"],\n",
    "              \"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"min_samples_leaf\": [20, 40, 100],\n",
    "              \"max_leaf_nodes\": [5, 20, 100, 500, 800],\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This examples shows how a classifier is optimized by cross-validation, which is done using the sklearn.model_selection.GridSearchCV object on a development set that comprises only half of the available labeled data.\n",
    "The performance of the selected hyper-parameters and trained model is then measured on a dedicated evaluation set that was not used during the model selection step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_dtr = GridSearchCV(dtr, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv_dtr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_cv_dtr.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Cross Validation: Best Model Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_dtr.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_dtr.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=grid_cv_dtr.cv_results_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sn.pointplot(data=df[['mean_test_score',\n",
    "                           'param_max_leaf_nodes',\n",
    "                           'param_max_depth']],\n",
    "             y='mean_test_score',x='param_max_depth',\n",
    "             hue='param_max_leaf_nodes',ax=ax)\n",
    "ax.set(title=\"Effect of Depth and Leaf Nodes on Model Performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Residual Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A residual plot is a graph that shows the residuals on the vertical axis and the independent variable on the horizontal axis. If the points in a residual plot are randomly dispersed around the horizontal axis, a linear regression model is appropriate for the data; otherwise, a non-linear model is more appropriate.\n",
    "A residual is the difference between the observed y-value (from scatter plot) and the predicted y-value (from regression equation line). It is the vertical distance from the actual plotted point to the point on the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = grid_cv_dtr.best_estimator_.predict(X)\n",
    "residuals = y.flatten()-predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y.flatten(), residuals)\n",
    "ax.axhline(lw=2,color='black')\n",
    "ax.set_xlabel('Observed')\n",
    "ax.set_ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default cross_val_score uses the scoring provided in the given estimator, which is usually the simplest appropriate scoring method. E.g. for most classifiers this is accuracy score and for regressors this is r2 score.\n",
    "the score computed at each CV iteration is the score method of the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores = cross_val_score(grid_cv_dtr.best_estimator_, X, y, cv=10)\n",
    "mse_scores = cross_val_score(grid_cv_dtr.best_estimator_, X, y, cv=10,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"avg R-squared::{}\".format(np.mean(r2_scores)))\n",
    "print(\"MSE::{}\".format(np.mean(mse_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Setting the model for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtr_model = grid_cv_dtr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Test Dataset Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_attr_list = []\n",
    "for enc in encoded_attr_list:\n",
    "    col_name = enc['col_name']\n",
    "    le = enc['label_enc']\n",
    "    ohe = enc['ohe_enc']\n",
    "    test_encoded_attr_list.append({'feature_df':transform_ohe(X_test,le,ohe,col_name),\n",
    "                                   'col_name':col_name})\n",
    "    \n",
    "    \n",
    "test_feature_df_list = [X_test[numeric_feature_cols]]\n",
    "test_feature_df_list.extend([enc['feature_df'] for enc in test_encoded_attr_list if enc['col_name'] in subset_cat_features])\n",
    "\n",
    "test_df_new = pd.concat(test_feature_df_list, axis=1) \n",
    "print(\"Shape::{}\".format(test_df_new.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df_new\n",
    "y_test = y_test.total_count.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_dtr_model.predict(X_test)\n",
    "residuals = y_test.flatten() - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score = best_dtr_model.score(X_test,y_test)\n",
    "print(\"R-squared::{}\".format(r2_score))\n",
    "print(\"MSE: %.2f\"\n",
    "      % metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test.flatten(), residuals)\n",
    "ax.axhline(lw=2,color='black')\n",
    "ax.set_xlabel('Observed')\n",
    "ax.set_ylabel('Residual')\n",
    "plt.show()\n",
    "\n",
    "r2_score = grid_cv_dtr.best_estimator_.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
