
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{CSII In-Depth Analysis}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    Introduction: Home Credit Default Risk Competition

    In this notebook, I am analyzing dataset posted on Kaggle 'Home Credit
default Risk' machine learning competition. As part of this competition,
the client of this project 'Home Credit Groups' wants Kagglers to come
up with enhanced, optimized predictive Machine Learning Model that can
more accurately 'Predict how capable each applicant is of repaying
loan'. Client has shared historical loan application data that has
target label signifying if applicant may be able to repay loan. This is
a supervised machine learning classification problem for this is a
labeled data and there is need to identify to which of a set of
categories (sub-populations) a new observation belongs, on the basis of
a training set of data containing observations (or instances) whose
category membership is known.

    Objective

     Predict how capable each applicant is of repaying a loan

    Data

    The data is posted by Home Credit Solutions group on Kaggle s given
here: https://www.kaggle.com/c/home-credit-default-risk

On analysis of all the datasets given, there is one main table
application\_train/application\_test

This contains each applicant record as row with unique id (SK\_ID\_CURR)
and is identified by the feature . The data has the TARGET variable
indicating 0: the loan was repaid or 1: the loan was not repaid.

    Data Wrangling

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{}Importing the libraries}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k+kn}{as} \PY{n+nn}{sns}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k+kn}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{warnings}
        \PY{n}{warnings}\PY{o}{.}\PY{n}{filterwarnings}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ignore}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{color} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{color\PYZus{}palette}\PY{p}{(}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{plotly.offline} \PY{k+kn}{as} \PY{n+nn}{py}
        \PY{n}{py}\PY{o}{.}\PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{(}\PY{n}{connected}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
        \PY{k+kn}{from} \PY{n+nn}{plotly.offline} \PY{k+kn}{import} \PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{,} \PY{n}{iplot}
        \PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{(}\PY{n}{connected}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{plotly.graph\PYZus{}objs} \PY{k+kn}{as} \PY{n+nn}{go}
        \PY{k+kn}{import} \PY{n+nn}{plotly.offline} \PY{k+kn}{as} \PY{n+nn}{offline}
        \PY{n}{offline}\PY{o}{.}\PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    
    
    
    
    
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{}Importing the dataset}
        \PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{application\PYZus{}train.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{df\PYZus{}test}\PY{o}{=}\PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{application\PYZus{}test.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{}Shape of dataset}
        \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}3}]:} (307511, 122)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}4}]:}    SK\_ID\_CURR NAME\_CONTRACT\_TYPE CODE\_GENDER FLAG\_OWN\_CAR FLAG\_OWN\_REALTY  \textbackslash{}
        0      100002         Cash loans           M            N               Y   
        1      100003         Cash loans           F            N               N   
        2      100004    Revolving loans           M            Y               Y   
        3      100006         Cash loans           F            N               Y   
        4      100007         Cash loans           M            N               Y   
        5      100008         Cash loans           M            N               Y   
        6      100009         Cash loans           F            Y               Y   
        7      100010         Cash loans           M            Y               Y   
        
           CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  AMT\_GOODS\_PRICE  \textbackslash{}
        0             0          202500.0    406597.5      24700.5         351000.0   
        1             0          270000.0   1293502.5      35698.5        1129500.0   
        2             0           67500.0    135000.0       6750.0         135000.0   
        3             0          135000.0    312682.5      29686.5         297000.0   
        4             0          121500.0    513000.0      21865.5         513000.0   
        5             0           99000.0    490495.5      27517.5         454500.0   
        6             1          171000.0   1560726.0      41301.0        1395000.0   
        7             0          360000.0   1530000.0      42075.0        1530000.0   
        
            {\ldots}   FLAG\_DOCUMENT\_19 FLAG\_DOCUMENT\_20 FLAG\_DOCUMENT\_21  \textbackslash{}
        0   {\ldots}                  0                0                0   
        1   {\ldots}                  0                0                0   
        2   {\ldots}                  0                0                0   
        3   {\ldots}                  0                0                0   
        4   {\ldots}                  0                0                0   
        5   {\ldots}                  0                0                0   
        6   {\ldots}                  0                0                0   
        7   {\ldots}                  0                0                0   
        
          AMT\_REQ\_CREDIT\_BUREAU\_HOUR AMT\_REQ\_CREDIT\_BUREAU\_DAY  \textbackslash{}
        0                        0.0                       0.0   
        1                        0.0                       0.0   
        2                        0.0                       0.0   
        3                        NaN                       NaN   
        4                        0.0                       0.0   
        5                        0.0                       0.0   
        6                        0.0                       0.0   
        7                        0.0                       0.0   
        
           AMT\_REQ\_CREDIT\_BUREAU\_WEEK  AMT\_REQ\_CREDIT\_BUREAU\_MON  \textbackslash{}
        0                         0.0                        0.0   
        1                         0.0                        0.0   
        2                         0.0                        0.0   
        3                         NaN                        NaN   
        4                         0.0                        0.0   
        5                         0.0                        0.0   
        6                         0.0                        1.0   
        7                         0.0                        0.0   
        
           AMT\_REQ\_CREDIT\_BUREAU\_QRT  AMT\_REQ\_CREDIT\_BUREAU\_YEAR  TARGET  
        0                        0.0                         1.0       1  
        1                        0.0                         0.0       0  
        2                        0.0                         0.0       0  
        3                        NaN                         NaN       0  
        4                        0.0                         0.0       0  
        5                        1.0                         1.0       0  
        6                        1.0                         2.0       0  
        7                        0.0                         0.0       0  
        
        [8 rows x 122 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}5}]:}           SK\_ID\_CURR   CNT\_CHILDREN  AMT\_INCOME\_TOTAL    AMT\_CREDIT  \textbackslash{}
        count  307511.000000  307511.000000      3.075110e+05  3.075110e+05   
        mean   278180.518577       0.417052      1.687979e+05  5.990260e+05   
        std    102790.175348       0.722121      2.371231e+05  4.024908e+05   
        min    100002.000000       0.000000      2.565000e+04  4.500000e+04   
        25\%    189145.500000       0.000000      1.125000e+05  2.700000e+05   
        50\%    278202.000000       0.000000      1.471500e+05  5.135310e+05   
        75\%    367142.500000       1.000000      2.025000e+05  8.086500e+05   
        max    456255.000000      19.000000      1.170000e+08  4.050000e+06   
        
                 AMT\_ANNUITY  AMT\_GOODS\_PRICE  REGION\_POPULATION\_RELATIVE  \textbackslash{}
        count  307499.000000     3.072330e+05               307511.000000   
        mean    27108.573909     5.383962e+05                    0.020868   
        std     14493.737315     3.694465e+05                    0.013831   
        min      1615.500000     4.050000e+04                    0.000290   
        25\%     16524.000000     2.385000e+05                    0.010006   
        50\%     24903.000000     4.500000e+05                    0.018850   
        75\%     34596.000000     6.795000e+05                    0.028663   
        max    258025.500000     4.050000e+06                    0.072508   
        
                  DAYS\_BIRTH  DAYS\_EMPLOYED  DAYS\_REGISTRATION      {\ldots}        \textbackslash{}
        count  307511.000000  307511.000000      307511.000000      {\ldots}         
        mean   -16036.995067   63815.045904       -4986.120328      {\ldots}         
        std      4363.988632  141275.766519        3522.886321      {\ldots}         
        min    -25229.000000  -17912.000000      -24672.000000      {\ldots}         
        25\%    -19682.000000   -2760.000000       -7479.500000      {\ldots}         
        50\%    -15750.000000   -1213.000000       -4504.000000      {\ldots}         
        75\%    -12413.000000    -289.000000       -2010.000000      {\ldots}         
        max     -7489.000000  365243.000000           0.000000      {\ldots}         
        
               FLAG\_DOCUMENT\_19  FLAG\_DOCUMENT\_20  FLAG\_DOCUMENT\_21  \textbackslash{}
        count     307511.000000     307511.000000     307511.000000   
        mean           0.000595          0.000507          0.000335   
        std            0.024387          0.022518          0.018299   
        min            0.000000          0.000000          0.000000   
        25\%            0.000000          0.000000          0.000000   
        50\%            0.000000          0.000000          0.000000   
        75\%            0.000000          0.000000          0.000000   
        max            1.000000          1.000000          1.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_HOUR  AMT\_REQ\_CREDIT\_BUREAU\_DAY  \textbackslash{}
        count               265992.000000              265992.000000   
        mean                     0.006402                   0.007000   
        std                      0.083849                   0.110757   
        min                      0.000000                   0.000000   
        25\%                      0.000000                   0.000000   
        50\%                      0.000000                   0.000000   
        75\%                      0.000000                   0.000000   
        max                      4.000000                   9.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_WEEK  AMT\_REQ\_CREDIT\_BUREAU\_MON  \textbackslash{}
        count               265992.000000              265992.000000   
        mean                     0.034362                   0.267395   
        std                      0.204685                   0.916002   
        min                      0.000000                   0.000000   
        25\%                      0.000000                   0.000000   
        50\%                      0.000000                   0.000000   
        75\%                      0.000000                   0.000000   
        max                      8.000000                  27.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_QRT  AMT\_REQ\_CREDIT\_BUREAU\_YEAR         TARGET  
        count              265992.000000               265992.000000  307511.000000  
        mean                    0.265474                    1.899974       0.080729  
        std                     0.794056                    1.869295       0.272419  
        min                     0.000000                    0.000000       0.000000  
        25\%                     0.000000                    0.000000       0.000000  
        50\%                     0.000000                    1.000000       0.000000  
        75\%                     0.000000                    3.000000       0.000000  
        max                   261.000000                   25.000000       1.000000  
        
        [8 rows x 106 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NAME\PYZus{}FAMILY\PYZus{}STATUS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}6}]:} Married                 196432
        Single / not married     45444
        Civil marriage           29775
        Separated                19770
        Widow                    16088
        Unknown                      2
        Name: NAME\_FAMILY\_STATUS, dtype: int64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:}    SK\_ID\_CURR NAME\_CONTRACT\_TYPE CODE\_GENDER FLAG\_OWN\_CAR FLAG\_OWN\_REALTY  \textbackslash{}
        0      100001         Cash loans           F            N               Y   
        1      100005         Cash loans           M            N               Y   
        2      100013         Cash loans           M            Y               Y   
        3      100028         Cash loans           F            N               Y   
        4      100038         Cash loans           M            Y               N   
        
           CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  AMT\_GOODS\_PRICE  \textbackslash{}
        0             0          135000.0    568800.0      20560.5         450000.0   
        1             0           99000.0    222768.0      17370.0         180000.0   
        2             0          202500.0    663264.0      69777.0         630000.0   
        3             2          315000.0   1575000.0      49018.5        1575000.0   
        4             1          180000.0    625500.0      32067.0         625500.0   
        
                      {\ldots}             FLAG\_DOCUMENT\_18 FLAG\_DOCUMENT\_19  \textbackslash{}
        0             {\ldots}                            0                0   
        1             {\ldots}                            0                0   
        2             {\ldots}                            0                0   
        3             {\ldots}                            0                0   
        4             {\ldots}                            0                0   
        
          FLAG\_DOCUMENT\_20 FLAG\_DOCUMENT\_21 AMT\_REQ\_CREDIT\_BUREAU\_HOUR  \textbackslash{}
        0                0                0                        0.0   
        1                0                0                        0.0   
        2                0                0                        0.0   
        3                0                0                        0.0   
        4                0                0                        NaN   
        
           AMT\_REQ\_CREDIT\_BUREAU\_DAY  AMT\_REQ\_CREDIT\_BUREAU\_WEEK  \textbackslash{}
        0                        0.0                         0.0   
        1                        0.0                         0.0   
        2                        0.0                         0.0   
        3                        0.0                         0.0   
        4                        NaN                         NaN   
        
           AMT\_REQ\_CREDIT\_BUREAU\_MON  AMT\_REQ\_CREDIT\_BUREAU\_QRT  \textbackslash{}
        0                        0.0                        0.0   
        1                        0.0                        0.0   
        2                        0.0                        1.0   
        3                        0.0                        0.0   
        4                        NaN                        NaN   
        
           AMT\_REQ\_CREDIT\_BUREAU\_YEAR  
        0                         0.0  
        1                         3.0  
        2                         4.0  
        3                         3.0  
        4                         NaN  
        
        [5 rows x 121 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}8}]:}           SK\_ID\_CURR  CNT\_CHILDREN  AMT\_INCOME\_TOTAL    AMT\_CREDIT  \textbackslash{}
        count   48744.000000  48744.000000      4.874400e+04  4.874400e+04   
        mean   277796.676350      0.397054      1.784318e+05  5.167404e+05   
        std    103169.547296      0.709047      1.015226e+05  3.653970e+05   
        min    100001.000000      0.000000      2.694150e+04  4.500000e+04   
        25\%    188557.750000      0.000000      1.125000e+05  2.606400e+05   
        50\%    277549.000000      0.000000      1.575000e+05  4.500000e+05   
        75\%    367555.500000      1.000000      2.250000e+05  6.750000e+05   
        max    456250.000000     20.000000      4.410000e+06  2.245500e+06   
        
                 AMT\_ANNUITY  AMT\_GOODS\_PRICE  REGION\_POPULATION\_RELATIVE  \textbackslash{}
        count   48720.000000     4.874400e+04                48744.000000   
        mean    29426.240209     4.626188e+05                    0.021226   
        std     16016.368315     3.367102e+05                    0.014428   
        min      2295.000000     4.500000e+04                    0.000253   
        25\%     17973.000000     2.250000e+05                    0.010006   
        50\%     26199.000000     3.960000e+05                    0.018850   
        75\%     37390.500000     6.300000e+05                    0.028663   
        max    180576.000000     2.245500e+06                    0.072508   
        
                 DAYS\_BIRTH  DAYS\_EMPLOYED  DAYS\_REGISTRATION  \textbackslash{}
        count  48744.000000   48744.000000       48744.000000   
        mean  -16068.084605   67485.366322       -4967.652716   
        std     4325.900393  144348.507136        3552.612035   
        min   -25195.000000  -17463.000000      -23722.000000   
        25\%   -19637.000000   -2910.000000       -7459.250000   
        50\%   -15785.000000   -1293.000000       -4490.000000   
        75\%   -12496.000000    -296.000000       -1901.000000   
        max    -7338.000000  365243.000000           0.000000   
        
                          {\ldots}              FLAG\_DOCUMENT\_18  FLAG\_DOCUMENT\_19  \textbackslash{}
        count             {\ldots}                  48744.000000           48744.0   
        mean              {\ldots}                      0.001559               0.0   
        std               {\ldots}                      0.039456               0.0   
        min               {\ldots}                      0.000000               0.0   
        25\%               {\ldots}                      0.000000               0.0   
        50\%               {\ldots}                      0.000000               0.0   
        75\%               {\ldots}                      0.000000               0.0   
        max               {\ldots}                      1.000000               0.0   
        
               FLAG\_DOCUMENT\_20  FLAG\_DOCUMENT\_21  AMT\_REQ\_CREDIT\_BUREAU\_HOUR  \textbackslash{}
        count           48744.0           48744.0                42695.000000   
        mean                0.0               0.0                    0.002108   
        std                 0.0               0.0                    0.046373   
        min                 0.0               0.0                    0.000000   
        25\%                 0.0               0.0                    0.000000   
        50\%                 0.0               0.0                    0.000000   
        75\%                 0.0               0.0                    0.000000   
        max                 0.0               0.0                    2.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_DAY  AMT\_REQ\_CREDIT\_BUREAU\_WEEK  \textbackslash{}
        count               42695.000000                42695.000000   
        mean                    0.001803                    0.002787   
        std                     0.046132                    0.054037   
        min                     0.000000                    0.000000   
        25\%                     0.000000                    0.000000   
        50\%                     0.000000                    0.000000   
        75\%                     0.000000                    0.000000   
        max                     2.000000                    2.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_MON  AMT\_REQ\_CREDIT\_BUREAU\_QRT  \textbackslash{}
        count               42695.000000               42695.000000   
        mean                    0.009299                   0.546902   
        std                     0.110924                   0.693305   
        min                     0.000000                   0.000000   
        25\%                     0.000000                   0.000000   
        50\%                     0.000000                   0.000000   
        75\%                     0.000000                   1.000000   
        max                     6.000000                   7.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_YEAR  
        count                42695.000000  
        mean                     1.983769  
        std                      1.838873  
        min                      0.000000  
        25\%                      0.000000  
        50\%                      2.000000  
        75\%                      3.000000  
        max                     17.000000  
        
        [8 rows x 105 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}9}]:} 0    282686
        1     24825
        Name: TARGET, dtype: int64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{int}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Per this graph, I do see Class Imbalance problem for majority of class
is indicating '0' risk while very few applicants or records under '1'
risk. I will work to resolve this problem during in-depth machine
learning engineering phase as now I proceed to further Data Munging
steps: 1. Missing Value Identification 2. Data Type Conversions 3.
Feature Engineering Categorical Variables 4. Removing Rows with Missing
Values \& Baselining Model 5. Replacing Missing Values with NaN followed
by Imputation and Baselining Model 

    Missing Value Identification

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{} Function to calculate missing values by column\PYZsh{} Funct }
         \PY{k}{def} \PY{n+nf}{missing\PYZus{}values\PYZus{}table}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} Total missing values}
                 \PY{n}{mis\PYZus{}val} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Percentage of missing values}
                 \PY{n}{mis\PYZus{}val\PYZus{}percent} \PY{o}{=} \PY{l+m+mi}{100} \PY{o}{*} \PY{n}{df}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{df}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Make a table with the results}
                 \PY{n}{mis\PYZus{}val\PYZus{}table} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{mis\PYZus{}val}\PY{p}{,} \PY{n}{mis\PYZus{}val\PYZus{}percent}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Rename the columns}
                 \PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns} \PY{o}{=} \PY{n}{mis\PYZus{}val\PYZus{}table}\PY{o}{.}\PY{n}{rename}\PY{p}{(}
                 \PY{n}{columns} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{0} \PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Missing Values}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1} \PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{} o}\PY{l+s+s1}{f Total Values}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Sort the table by percentage of missing descending}
                 \PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns} \PY{o}{=} \PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns}\PY{p}{[}
                     \PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{!=} \PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{} o}\PY{l+s+s1}{f Total Values}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Print some summary information}
                 \PY{k}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Your selected dataframe has }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ columns.}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}      
                     \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{There are }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{o}{+}
                       \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ columns that have missing values.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Return the dataframe with missing information}
                 \PY{k}{return} \PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{missing\PYZus{}values} \PY{o}{=} \PY{n}{missing\PYZus{}values\PYZus{}table}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{n}{missing\PYZus{}values}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Your selected dataframe has 122 columns.
There are 67 columns that have missing values.

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}12}]:}                           Missing Values  \% of Total Values
         COMMONAREA\_MEDI                   214865               69.9
         COMMONAREA\_AVG                    214865               69.9
         COMMONAREA\_MODE                   214865               69.9
         NONLIVINGAPARTMENTS\_MEDI          213514               69.4
         NONLIVINGAPARTMENTS\_MODE          213514               69.4
         NONLIVINGAPARTMENTS\_AVG           213514               69.4
         FONDKAPREMONT\_MODE                210295               68.4
         LIVINGAPARTMENTS\_MODE             210199               68.4
         LIVINGAPARTMENTS\_MEDI             210199               68.4
         LIVINGAPARTMENTS\_AVG              210199               68.4
         FLOORSMIN\_MODE                    208642               67.8
         FLOORSMIN\_MEDI                    208642               67.8
         FLOORSMIN\_AVG                     208642               67.8
         YEARS\_BUILD\_MODE                  204488               66.5
         YEARS\_BUILD\_MEDI                  204488               66.5
         YEARS\_BUILD\_AVG                   204488               66.5
         OWN\_CAR\_AGE                       202929               66.0
         LANDAREA\_AVG                      182590               59.4
         LANDAREA\_MEDI                     182590               59.4
         LANDAREA\_MODE                     182590               59.4
\end{Verbatim}
            
    Based on the numerous missing value records as guessed during
preliminary Data Munging steps, I will approach this problem using
either 'Removing Rows with Missing Value' strategy or 'Replacing Nulls
with NaN and Running Imputation Machine Learning' strategy.

    Data Types Conversions (if any)

    Analysing the features next for their data types and possibly data:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{c+c1}{\PYZsh{} Number of each type of column}
         \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{dtypes}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}13}]:} float64    65
         int64      41
         object     16
         dtype: int64
\end{Verbatim}
            
    Examining unique entries for Categorical variables:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} Number of unique classes in each object column}
         \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{select\PYZus{}dtypes}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{object}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{o}{.}\PY{n}{nunique}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}14}]:} NAME\_CONTRACT\_TYPE             2
         CODE\_GENDER                    3
         FLAG\_OWN\_CAR                   2
         FLAG\_OWN\_REALTY                2
         NAME\_TYPE\_SUITE                7
         NAME\_INCOME\_TYPE               8
         NAME\_EDUCATION\_TYPE            5
         NAME\_FAMILY\_STATUS             6
         NAME\_HOUSING\_TYPE              6
         OCCUPATION\_TYPE               18
         WEEKDAY\_APPR\_PROCESS\_START     7
         ORGANIZATION\_TYPE             58
         FONDKAPREMONT\_MODE             4
         HOUSETYPE\_MODE                 3
         WALLSMATERIAL\_MODE             7
         EMERGENCYSTATE\_MODE            2
         dtype: int64
\end{Verbatim}
            
    The categorical variables with less number of classes (\textless{}=2)
may be label encoded while remaining I may use One Hot encoding
technique. The reason why we have to feature engineer Categorical
variables is because many Machine Learning Model do not perform well
with Categorical variables since categorical variable may have too many
levels and pulls down performance level of the model. Also it is not
necessary that all the levels always occur in the records, only few may
occur and make any impact on model fit.

    Feature Engineering Categorical Variables

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.preprocessing} \PY{k+kn}{import} \PY{n}{LabelEncoder}
         \PY{c+c1}{\PYZsh{} Create a label encoder object}
         \PY{n}{le} \PY{o}{=} \PY{n}{LabelEncoder}\PY{p}{(}\PY{p}{)}
         \PY{n}{le\PYZus{}count} \PY{o}{=} \PY{l+m+mi}{0}
         
         \PY{c+c1}{\PYZsh{} Iterate through the columns}
         \PY{k}{for} \PY{n}{col} \PY{o+ow}{in} \PY{n}{df\PYZus{}train}\PY{p}{:}
             \PY{k}{if} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{dtype} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{object}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} If 2 or fewer unique categories}
                 \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{2}\PY{p}{:}
                     \PY{c+c1}{\PYZsh{} Train on the training data}
                     \PY{n}{le}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{} Transform both training and testing data}
                     \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]} \PY{o}{=} \PY{n}{le}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{p}{)}
                     \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{n}{col}\PY{p}{]} \PY{o}{=} \PY{n}{le}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{p}{)}
                     
                     \PY{c+c1}{\PYZsh{} Keep track of how many columns were label encoded}
                     \PY{n}{le\PYZus{}count} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
                     
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{ columns were label encoded.}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{le\PYZus{}count}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
3 columns were label encoded.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{} one\PYZhy{}hot encoding of categorical variables}
         \PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{n}{df\PYZus{}test} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{)}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Testing Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Training Features shape: ', (307511, 243))
('Testing Features shape: ', (48744, 239))

    \end{Verbatim}

    Missing Value Handling

    After feature engineering categorical variables in the dataset now we
have more columns in the traning (primary) dataset and test dataset
since does not have target label so at this point I align the feature
set in the two datasets before we take further steps on baselining
model.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{train\PYZus{}labels} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} Align the training and testing data, keep only columns present in both dataframes}
         \PY{n}{df\PYZus{}train}\PY{p}{,} \PY{n}{df\PYZus{}test} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{align}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{,} \PY{n}{join} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inner}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Add the target back in}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{train\PYZus{}labels}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Testing Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Training Features shape: ', (307511, 240))
('Testing Features shape: ', (48744, 239))

    \end{Verbatim}

    The training and testing datasets now have the same features which is
required for machine learning

    Exploring Data a Bit Prior Missing Value

    Anomalies/Outliers

Here may check for if any outliers or anomalies in data by the features
given:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{o}{\PYZhy{}}\PY{l+m+mi}{365}\PY{p}{)}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}18}]:} count    307511.000000
         mean         43.936973
         std          11.956133
         min          20.517808
         25\%          34.008219
         50\%          43.150685
         75\%          53.923288
         max          69.120548
         Name: DAYS\_BIRTH, dtype: float64
\end{Verbatim}
            
    Those ages look reasonable. There are no outliers for the age on either
the high or low end. How about the days of employment?

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}19}]:} count    307511.000000
         mean      63815.045904
         std      141275.766519
         min      -17912.000000
         25\%       -2760.000000
         50\%       -1213.000000
         75\%        -289.000000
         max      365243.000000
         Name: DAYS\_EMPLOYED, dtype: float64
\end{Verbatim}
            
    This may not be correct since maximum value (besides being positive) is
about 1000 years!

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{title} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days Employment Histogram}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days Employment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_41_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Missing Values Strategy \# 1 - Identify Features with Missing Values
-\textgreater{} Replace with NaN -\textgreater{} Remove all Features
with Missing Value -\textgreater{} Assess Model using Logistic
Regression

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{c+c1}{\PYZsh{} Missing values statistics}
         \PY{n}{missing\PYZus{}values} \PY{o}{=} \PY{n}{missing\PYZus{}values\PYZus{}table}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{n}{missing\PYZus{}values}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Your selected dataframe has 240 columns.
There are 61 columns that have missing values.

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}21}]:}                           Missing Values  \% of Total Values
         COMMONAREA\_MODE                   214865               69.9
         COMMONAREA\_MEDI                   214865               69.9
         COMMONAREA\_AVG                    214865               69.9
         NONLIVINGAPARTMENTS\_MODE          213514               69.4
         NONLIVINGAPARTMENTS\_AVG           213514               69.4
         NONLIVINGAPARTMENTS\_MEDI          213514               69.4
         LIVINGAPARTMENTS\_MEDI             210199               68.4
         LIVINGAPARTMENTS\_AVG              210199               68.4
         LIVINGAPARTMENTS\_MODE             210199               68.4
         FLOORSMIN\_MEDI                    208642               67.8
         FLOORSMIN\_MODE                    208642               67.8
         FLOORSMIN\_AVG                     208642               67.8
         YEARS\_BUILD\_AVG                   204488               66.5
         YEARS\_BUILD\_MODE                  204488               66.5
         YEARS\_BUILD\_MEDI                  204488               66.5
         OWN\_CAR\_AGE                       202929               66.0
         LANDAREA\_MEDI                     182590               59.4
         LANDAREA\_MODE                     182590               59.4
         LANDAREA\_AVG                      182590               59.4
         BASEMENTAREA\_MODE                 179943               58.5
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{c+c1}{\PYZsh{}Omitting TARGET from Column list}
         \PY{n}{train}\PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Replace Nulls with NaN}
         \PY{c+c1}{\PYZsh{} mark zero values as missing or NaN}
         \PY{n}{train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{p}{]} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}} \PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{NaN}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} count the number of NaN values in each column}
         \PY{k}{print}\PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
SK\_ID\_CURR                                       0
NAME\_CONTRACT\_TYPE                               0
FLAG\_OWN\_CAR                                     0
FLAG\_OWN\_REALTY                                  0
CNT\_CHILDREN                                     0
AMT\_INCOME\_TOTAL                                 0
AMT\_CREDIT                                       0
AMT\_ANNUITY                                     12
AMT\_GOODS\_PRICE                                278
REGION\_POPULATION\_RELATIVE                       0
DAYS\_BIRTH                                       0
DAYS\_EMPLOYED                                    0
DAYS\_REGISTRATION                                0
DAYS\_ID\_PUBLISH                                  0
OWN\_CAR\_AGE                                 202929
FLAG\_MOBIL                                       0
FLAG\_EMP\_PHONE                                   0
FLAG\_WORK\_PHONE                                  0
FLAG\_CONT\_MOBILE                                 0
FLAG\_PHONE                                       0
FLAG\_EMAIL                                       0
CNT\_FAM\_MEMBERS                                  2
REGION\_RATING\_CLIENT                             0
REGION\_RATING\_CLIENT\_W\_CITY                      0
HOUR\_APPR\_PROCESS\_START                          0
REG\_REGION\_NOT\_LIVE\_REGION                       0
REG\_REGION\_NOT\_WORK\_REGION                       0
LIVE\_REGION\_NOT\_WORK\_REGION                      0
REG\_CITY\_NOT\_LIVE\_CITY                           0
REG\_CITY\_NOT\_WORK\_CITY                           0
                                             {\ldots}  
ORGANIZATION\_TYPE\_Telecom                        0
ORGANIZATION\_TYPE\_Trade: type 1                  0
ORGANIZATION\_TYPE\_Trade: type 2                  0
ORGANIZATION\_TYPE\_Trade: type 3                  0
ORGANIZATION\_TYPE\_Trade: type 4                  0
ORGANIZATION\_TYPE\_Trade: type 5                  0
ORGANIZATION\_TYPE\_Trade: type 6                  0
ORGANIZATION\_TYPE\_Trade: type 7                  0
ORGANIZATION\_TYPE\_Transport: type 1              0
ORGANIZATION\_TYPE\_Transport: type 2              0
ORGANIZATION\_TYPE\_Transport: type 3              0
ORGANIZATION\_TYPE\_Transport: type 4              0
ORGANIZATION\_TYPE\_University                     0
ORGANIZATION\_TYPE\_XNA                            0
FONDKAPREMONT\_MODE\_not specified                 0
FONDKAPREMONT\_MODE\_org spec account              0
FONDKAPREMONT\_MODE\_reg oper account              0
FONDKAPREMONT\_MODE\_reg oper spec account         0
HOUSETYPE\_MODE\_block of flats                    0
HOUSETYPE\_MODE\_specific housing                  0
HOUSETYPE\_MODE\_terraced house                    0
WALLSMATERIAL\_MODE\_Block                         0
WALLSMATERIAL\_MODE\_Mixed                         0
WALLSMATERIAL\_MODE\_Monolithic                    0
WALLSMATERIAL\_MODE\_Others                        0
WALLSMATERIAL\_MODE\_Panel                         0
WALLSMATERIAL\_MODE\_Stone, brick                  0
WALLSMATERIAL\_MODE\_Wooden                        0
EMERGENCYSTATE\_MODE\_No                           0
EMERGENCYSTATE\_MODE\_Yes                          0
Length: 239, dtype: int64

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{c+c1}{\PYZsh{} print the first 20 rows of data}
         \PY{k}{print}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
    SK\_ID\_CURR  NAME\_CONTRACT\_TYPE  FLAG\_OWN\_CAR  FLAG\_OWN\_REALTY  \textbackslash{}
0       100002                   0             0                1   
1       100003                   0             0                0   
2       100004                   1             1                1   
3       100006                   0             0                1   
4       100007                   0             0                1   
5       100008                   0             0                1   
6       100009                   0             1                1   
7       100010                   0             1                1   
8       100011                   0             0                1   
9       100012                   1             0                1   
10      100014                   0             0                1   
11      100015                   0             0                1   
12      100016                   0             0                1   
13      100017                   0             1                0   
14      100018                   0             0                1   
15      100019                   0             1                1   
16      100020                   0             0                0   
17      100021                   1             0                1   
18      100022                   1             0                1   
19      100023                   0             0                1   

    CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  AMT\_GOODS\_PRICE  \textbackslash{}
0              0        202500.000    406597.5      24700.5         351000.0   
1              0        270000.000   1293502.5      35698.5        1129500.0   
2              0         67500.000    135000.0       6750.0         135000.0   
3              0        135000.000    312682.5      29686.5         297000.0   
4              0        121500.000    513000.0      21865.5         513000.0   
5              0         99000.000    490495.5      27517.5         454500.0   
6              1        171000.000   1560726.0      41301.0        1395000.0   
7              0        360000.000   1530000.0      42075.0        1530000.0   
8              0        112500.000   1019610.0      33826.5         913500.0   
9              0        135000.000    405000.0      20250.0         405000.0   
10             1        112500.000    652500.0      21177.0         652500.0   
11             0         38419.155    148365.0      10678.5         135000.0   
12             0         67500.000     80865.0       5881.5          67500.0   
13             1        225000.000    918468.0      28966.5         697500.0   
14             0        189000.000    773680.5      32778.0         679500.0   
15             0        157500.000    299772.0      20160.0         247500.0   
16             0        108000.000    509602.5      26149.5         387000.0   
17             1         81000.000    270000.0      13500.0         270000.0   
18             0        112500.000    157500.0       7875.0         157500.0   
19             1         90000.000    544491.0      17563.5         454500.0   

    REGION\_POPULATION\_RELATIVE   {\ldots}    WALLSMATERIAL\_MODE\_Block  \textbackslash{}
0                     0.018801   {\ldots}                           0   
1                     0.003541   {\ldots}                           1   
2                     0.010032   {\ldots}                           0   
3                     0.008019   {\ldots}                           0   
4                     0.028663   {\ldots}                           0   
5                     0.035792   {\ldots}                           0   
6                     0.035792   {\ldots}                           0   
7                     0.003122   {\ldots}                           0   
8                     0.018634   {\ldots}                           0   
9                     0.019689   {\ldots}                           0   
10                    0.022800   {\ldots}                           0   
11                    0.015221   {\ldots}                           0   
12                    0.031329   {\ldots}                           0   
13                    0.016612   {\ldots}                           0   
14                    0.010006   {\ldots}                           0   
15                    0.020713   {\ldots}                           0   
16                    0.018634   {\ldots}                           0   
17                    0.010966   {\ldots}                           0   
18                    0.046220   {\ldots}                           0   
19                    0.015221   {\ldots}                           0   

    WALLSMATERIAL\_MODE\_Mixed  WALLSMATERIAL\_MODE\_Monolithic  \textbackslash{}
0                          0                              0   
1                          0                              0   
2                          0                              0   
3                          0                              0   
4                          0                              0   
5                          0                              0   
6                          0                              0   
7                          0                              0   
8                          0                              0   
9                          0                              0   
10                         0                              0   
11                         0                              0   
12                         0                              0   
13                         0                              0   
14                         0                              0   
15                         0                              0   
16                         0                              0   
17                         0                              0   
18                         0                              0   
19                         0                              0   

    WALLSMATERIAL\_MODE\_Others  WALLSMATERIAL\_MODE\_Panel  \textbackslash{}
0                           0                         0   
1                           0                         0   
2                           0                         0   
3                           0                         0   
4                           0                         0   
5                           0                         0   
6                           0                         0   
7                           0                         0   
8                           0                         0   
9                           0                         0   
10                          0                         0   
11                          0                         0   
12                          0                         0   
13                          0                         1   
14                          0                         1   
15                          0                         0   
16                          0                         0   
17                          0                         0   
18                          0                         0   
19                          0                         0   

    WALLSMATERIAL\_MODE\_Stone, brick  WALLSMATERIAL\_MODE\_Wooden  \textbackslash{}
0                                 1                          0   
1                                 0                          0   
2                                 0                          0   
3                                 0                          0   
4                                 0                          0   
5                                 0                          0   
6                                 0                          0   
7                                 0                          0   
8                                 0                          0   
9                                 0                          0   
10                                0                          0   
11                                0                          0   
12                                0                          0   
13                                0                          0   
14                                0                          0   
15                                0                          0   
16                                0                          0   
17                                0                          0   
18                                1                          0   
19                                0                          0   

    EMERGENCYSTATE\_MODE\_No  EMERGENCYSTATE\_MODE\_Yes  TARGET  
0                        1                        0       1  
1                        1                        0       0  
2                        0                        0       0  
3                        0                        0       0  
4                        0                        0       0  
5                        0                        0       0  
6                        0                        0       0  
7                        0                        0       0  
8                        0                        0       0  
9                        0                        0       0  
10                       0                        0       0  
11                       0                        0       0  
12                       1                        0       0  
13                       1                        0       0  
14                       1                        0       0  
15                       0                        0       0  
16                       0                        0       0  
17                       0                        0       0  
18                       1                        0       0  
19                       0                        0       0  

[20 rows x 240 columns]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{k}{print} \PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
   SK\_ID\_CURR  NAME\_CONTRACT\_TYPE  FLAG\_OWN\_CAR  FLAG\_OWN\_REALTY  \textbackslash{}
0      100002                   0             0                1   
1      100003                   0             0                0   
2      100004                   1             1                1   
3      100006                   0             0                1   
4      100007                   0             0                1   
5      100008                   0             0                1   
6      100009                   0             1                1   
7      100010                   0             1                1   
8      100011                   0             0                1   
9      100012                   1             0                1   

   CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  AMT\_GOODS\_PRICE  \textbackslash{}
0             0          202500.0    406597.5      24700.5         351000.0   
1             0          270000.0   1293502.5      35698.5        1129500.0   
2             0           67500.0    135000.0       6750.0         135000.0   
3             0          135000.0    312682.5      29686.5         297000.0   
4             0          121500.0    513000.0      21865.5         513000.0   
5             0           99000.0    490495.5      27517.5         454500.0   
6             1          171000.0   1560726.0      41301.0        1395000.0   
7             0          360000.0   1530000.0      42075.0        1530000.0   
8             0          112500.0   1019610.0      33826.5         913500.0   
9             0          135000.0    405000.0      20250.0         405000.0   

   REGION\_POPULATION\_RELATIVE           {\ldots}             \textbackslash{}
0                    0.018801           {\ldots}              
1                    0.003541           {\ldots}              
2                    0.010032           {\ldots}              
3                    0.008019           {\ldots}              
4                    0.028663           {\ldots}              
5                    0.035792           {\ldots}              
6                    0.035792           {\ldots}              
7                    0.003122           {\ldots}              
8                    0.018634           {\ldots}              
9                    0.019689           {\ldots}              

   HOUSETYPE\_MODE\_terraced house  WALLSMATERIAL\_MODE\_Block  \textbackslash{}
0                              0                         0   
1                              0                         1   
2                              0                         0   
3                              0                         0   
4                              0                         0   
5                              0                         0   
6                              0                         0   
7                              0                         0   
8                              0                         0   
9                              0                         0   

   WALLSMATERIAL\_MODE\_Mixed  WALLSMATERIAL\_MODE\_Monolithic  \textbackslash{}
0                         0                              0   
1                         0                              0   
2                         0                              0   
3                         0                              0   
4                         0                              0   
5                         0                              0   
6                         0                              0   
7                         0                              0   
8                         0                              0   
9                         0                              0   

   WALLSMATERIAL\_MODE\_Others  WALLSMATERIAL\_MODE\_Panel  \textbackslash{}
0                          0                         0   
1                          0                         0   
2                          0                         0   
3                          0                         0   
4                          0                         0   
5                          0                         0   
6                          0                         0   
7                          0                         0   
8                          0                         0   
9                          0                         0   

   WALLSMATERIAL\_MODE\_Stone, brick  WALLSMATERIAL\_MODE\_Wooden  \textbackslash{}
0                                1                          0   
1                                0                          0   
2                                0                          0   
3                                0                          0   
4                                0                          0   
5                                0                          0   
6                                0                          0   
7                                0                          0   
8                                0                          0   
9                                0                          0   

   EMERGENCYSTATE\_MODE\_No  EMERGENCYSTATE\_MODE\_Yes  
0                       1                        0  
1                       1                        0  
2                       0                        0  
3                       0                        0  
4                       0                        0  
5                       0                        0  
6                       0                        0  
7                       0                        0  
8                       0                        0  
9                       0                        0  

[10 rows x 239 columns]

    \end{Verbatim}

    Baseline Model

    Dropping Rows with Missing Values -\textgreater{}Baselining model with
Logistic Regression

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{c+c1}{\PYZsh{} drop rows with missing values}
         \PY{n}{train}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} summarize the number of rows and columns in the dataset}
         \PY{c+c1}{\PYZsh{}Add in the TARGET}
         \PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{=}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{k}{print}\PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(11351, 240)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{n}{train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}26}]:}      SK\_ID\_CURR  NAME\_CONTRACT\_TYPE  FLAG\_OWN\_CAR  FLAG\_OWN\_REALTY  \textbackslash{}
         71       100083                   0             1                1   
         124      100145                   0             1                1   
         143      100165                   0             1                1   
         152      100179                   0             1                0   
         161      100190                   0             1                0   
         164      100193                   0             1                0   
         249      100289                   0             1                0   
         255      100295                   0             1                0   
         296      100341                   0             1                1   
         298      100343                   0             1                1   
         
              CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  AMT\_GOODS\_PRICE  \textbackslash{}
         71              0          103500.0    573628.5      24435.0         463500.0   
         124             1          202500.0    260725.5      16789.5         198000.0   
         143             0          175500.0   1293502.5      35568.0        1129500.0   
         152             0          202500.0    675000.0      53329.5         675000.0   
         161             0          162000.0    263686.5      24781.5         238500.0   
         164             0          225000.0    296280.0      15124.5         225000.0   
         249             0          202500.0    526491.0      26878.5         454500.0   
         255             1          225000.0   1019205.0      31032.0         774000.0   
         296             0           76500.0    545040.0      20677.5         450000.0   
         298             0          315000.0     90000.0       4504.5          90000.0   
         
              REGION\_POPULATION\_RELATIVE   {\ldots}    WALLSMATERIAL\_MODE\_Block  \textbackslash{}
         71                     0.009657   {\ldots}                           0   
         124                    0.018850   {\ldots}                           0   
         143                    0.018850   {\ldots}                           0   
         152                    0.031329   {\ldots}                           0   
         161                    0.022625   {\ldots}                           0   
         164                    0.020246   {\ldots}                           0   
         249                    0.022625   {\ldots}                           0   
         255                    0.072508   {\ldots}                           0   
         296                    0.031329   {\ldots}                           0   
         298                    0.022800   {\ldots}                           0   
         
              WALLSMATERIAL\_MODE\_Mixed  WALLSMATERIAL\_MODE\_Monolithic  \textbackslash{}
         71                          0                              0   
         124                         0                              0   
         143                         0                              0   
         152                         0                              1   
         161                         0                              0   
         164                         0                              0   
         249                         0                              0   
         255                         0                              0   
         296                         0                              0   
         298                         0                              0   
         
              WALLSMATERIAL\_MODE\_Others  WALLSMATERIAL\_MODE\_Panel  \textbackslash{}
         71                           0                         0   
         124                          0                         1   
         143                          0                         1   
         152                          0                         0   
         161                          0                         1   
         164                          0                         0   
         249                          0                         1   
         255                          0                         1   
         296                          0                         0   
         298                          0                         1   
         
              WALLSMATERIAL\_MODE\_Stone, brick  WALLSMATERIAL\_MODE\_Wooden  \textbackslash{}
         71                                 1                          0   
         124                                0                          0   
         143                                0                          0   
         152                                0                          0   
         161                                0                          0   
         164                                1                          0   
         249                                0                          0   
         255                                0                          0   
         296                                1                          0   
         298                                0                          0   
         
              EMERGENCYSTATE\_MODE\_No  EMERGENCYSTATE\_MODE\_Yes  TARGET  
         71                        1                        0       0  
         124                       1                        0       0  
         143                       1                        0       0  
         152                       1                        0       0  
         161                       1                        0       0  
         164                       1                        0       0  
         249                       1                        0       0  
         255                       1                        0       1  
         296                       1                        0       0  
         298                       1                        0       0  
         
         [10 rows x 240 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{c+c1}{\PYZsh{}Deploying Logistic Regression}
         \PY{c+c1}{\PYZsh{}Splitting the dataset}
         
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{preprocessing}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{rc}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{font}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LogisticRegression}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.cross\PYZus{}validation} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
         
         \PY{n}{X} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{y} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{metrics}
         \PY{n}{logreg} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
         \PY{n}{logreg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
/anaconda2/lib/python2.7/site-packages/sklearn/cross\_validation.py:41: DeprecationWarning:

This module was deprecated in version 0.18 in favor of the model\_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.


    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}27}]:} LogisticRegression(C=1.0, class\_weight=None, dual=False, fit\_intercept=True,
                   intercept\_scaling=1, max\_iter=100, multi\_class='ovr', n\_jobs=1,
                   penalty='l2', random\_state=None, solver='liblinear', tol=0.0001,
                   verbose=0, warm\_start=False)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{logreg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy of logistic regression classifier on test set: \PYZob{}:.2f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{logreg}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy of logistic regression classifier on test set: 0.93

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.metrics} \PY{k+kn}{import} \PY{n}{classification\PYZus{}report}\PY{p}{,}\PY{n}{accuracy\PYZus{}score}
         \PY{k}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
             precision    recall  f1-score   support

          0       0.93      1.00      0.97      2122
          1       0.00      0.00      0.00       149

avg / total       0.87      0.93      0.90      2271

0.9343901365037428

    \end{Verbatim}

    The precision is the ratio tp / (tp + fp) where tp is the number of true
positives and fp the number of false positives. The precision is
intuitively the ability of the classifier not to label as positive a
sample that is negative. The recall is the ratio tp / (tp + fn) where tp
is the number of true positives and fn the number of false negatives.
The recall is intuitively the ability of the classifier to find all the
positive samples. The F-beta score can be interpreted as a weighted
harmonic mean of the precision and recall, where an F-beta score reaches
its best value at 1 and worst score at 0. The F-beta score weights
recall more than precision by a factor of beta. beta == 1.0 means recall
and precision are equally important. The support is the number of
occurrences of each class in y\_true.

\begin{verbatim}
courtesy: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html
\end{verbatim}

    Another Approach: Identify Features with Missing Values -\textgreater{}
Replace with NaN -\textgreater{} Impute all Features with Missing Value
-\textgreater{} Assess Model using Logistic Regression

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}30}]:} \PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{application\PYZus{}train.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{n}{missing\PYZus{}values} \PY{o}{=} \PY{n}{missing\PYZus{}values\PYZus{}table}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Your selected dataframe has 122 columns.
There are 67 columns that have missing values.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}32}]:} \PY{k}{print} \PY{p}{(}\PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(48744, 239)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}33}]:} \PY{c+c1}{\PYZsh{} Number of unique classes in each object column}
         \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{select\PYZus{}dtypes}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{object}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{o}{.}\PY{n}{nunique}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}33}]:} NAME\_CONTRACT\_TYPE             2
         CODE\_GENDER                    3
         FLAG\_OWN\_CAR                   2
         FLAG\_OWN\_REALTY                2
         NAME\_TYPE\_SUITE                7
         NAME\_INCOME\_TYPE               8
         NAME\_EDUCATION\_TYPE            5
         NAME\_FAMILY\_STATUS             6
         NAME\_HOUSING\_TYPE              6
         OCCUPATION\_TYPE               18
         WEEKDAY\_APPR\_PROCESS\_START     7
         ORGANIZATION\_TYPE             58
         FONDKAPREMONT\_MODE             4
         HOUSETYPE\_MODE                 3
         WALLSMATERIAL\_MODE             7
         EMERGENCYSTATE\_MODE            2
         dtype: int64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}34}]:} \PY{k}{print} \PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[1, 0]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Training Features shape: ', (307511, 246))

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{n}{train\PYZus{}labels} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} Align the training and testing data, keep only columns present in both dataframes}
         \PY{n}{df\PYZus{}train}\PY{p}{,} \PY{n}{df\PYZus{}test} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{align}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{,} \PY{n}{join} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inner}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Add the target back in}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{train\PYZus{}labels}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Testing Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Training Features shape: ', (307511, 237))
('Testing Features shape: ', (48744, 236))

    \end{Verbatim}

    Missing Values Strategy \# 2 - Identify Features with Missing Values
-\textgreater{} Replace with NaN -\textgreater{} Impute all Features
with Missing Value -\textgreater{} Assess Model using Logistic
Regression

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}37}]:} \PY{c+c1}{\PYZsh{} Missing values statistics}
         \PY{n}{missing\PYZus{}values} \PY{o}{=} \PY{n}{missing\PYZus{}values\PYZus{}table}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{n}{missing\PYZus{}values}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Your selected dataframe has 237 columns.
There are 61 columns that have missing values.

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}37}]:}                           Missing Values  \% of Total Values
         COMMONAREA\_MODE                   214865               69.9
         COMMONAREA\_MEDI                   214865               69.9
         COMMONAREA\_AVG                    214865               69.9
         NONLIVINGAPARTMENTS\_MODE          213514               69.4
         NONLIVINGAPARTMENTS\_AVG           213514               69.4
         NONLIVINGAPARTMENTS\_MEDI          213514               69.4
         LIVINGAPARTMENTS\_MEDI             210199               68.4
         LIVINGAPARTMENTS\_AVG              210199               68.4
         LIVINGAPARTMENTS\_MODE             210199               68.4
         FLOORSMIN\_MEDI                    208642               67.8
         FLOORSMIN\_MODE                    208642               67.8
         FLOORSMIN\_AVG                     208642               67.8
         YEARS\_BUILD\_AVG                   204488               66.5
         YEARS\_BUILD\_MODE                  204488               66.5
         YEARS\_BUILD\_MEDI                  204488               66.5
         OWN\_CAR\_AGE                       202929               66.0
         LANDAREA\_MEDI                     182590               59.4
         LANDAREA\_MODE                     182590               59.4
         LANDAREA\_AVG                      182590               59.4
         BASEMENTAREA\_MODE                 179943               58.5
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}38}]:}    SK\_ID\_CURR  CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  \textbackslash{}
         0      100002             0          202500.0    406597.5      24700.5   
         1      100003             0          270000.0   1293502.5      35698.5   
         2      100004             0           67500.0    135000.0       6750.0   
         3      100006             0          135000.0    312682.5      29686.5   
         4      100007             0          121500.0    513000.0      21865.5   
         5      100008             0           99000.0    490495.5      27517.5   
         6      100009             1          171000.0   1560726.0      41301.0   
         7      100010             0          360000.0   1530000.0      42075.0   
         8      100011             0          112500.0   1019610.0      33826.5   
         9      100012             0          135000.0    405000.0      20250.0   
         
            AMT\_GOODS\_PRICE  REGION\_POPULATION\_RELATIVE  DAYS\_BIRTH  DAYS\_EMPLOYED  \textbackslash{}
         0         351000.0                    0.018801       -9461           -637   
         1        1129500.0                    0.003541      -16765          -1188   
         2         135000.0                    0.010032      -19046           -225   
         3         297000.0                    0.008019      -19005          -3039   
         4         513000.0                    0.028663      -19932          -3038   
         5         454500.0                    0.035792      -16941          -1588   
         6        1395000.0                    0.035792      -13778          -3130   
         7        1530000.0                    0.003122      -18850           -449   
         8         913500.0                    0.018634      -20099         365243   
         9         405000.0                    0.019689      -14469          -2019   
         
            DAYS\_REGISTRATION   {\ldots}    WALLSMATERIAL\_MODE\_Block  \textbackslash{}
         0            -3648.0   {\ldots}                           0   
         1            -1186.0   {\ldots}                           1   
         2            -4260.0   {\ldots}                           0   
         3            -9833.0   {\ldots}                           0   
         4            -4311.0   {\ldots}                           0   
         5            -4970.0   {\ldots}                           0   
         6            -1213.0   {\ldots}                           0   
         7            -4597.0   {\ldots}                           0   
         8            -7427.0   {\ldots}                           0   
         9           -14437.0   {\ldots}                           0   
         
            WALLSMATERIAL\_MODE\_Mixed  WALLSMATERIAL\_MODE\_Monolithic  \textbackslash{}
         0                         0                              0   
         1                         0                              0   
         2                         0                              0   
         3                         0                              0   
         4                         0                              0   
         5                         0                              0   
         6                         0                              0   
         7                         0                              0   
         8                         0                              0   
         9                         0                              0   
         
            WALLSMATERIAL\_MODE\_Others  WALLSMATERIAL\_MODE\_Panel  \textbackslash{}
         0                          0                         0   
         1                          0                         0   
         2                          0                         0   
         3                          0                         0   
         4                          0                         0   
         5                          0                         0   
         6                          0                         0   
         7                          0                         0   
         8                          0                         0   
         9                          0                         0   
         
            WALLSMATERIAL\_MODE\_Stone, brick  WALLSMATERIAL\_MODE\_Wooden  \textbackslash{}
         0                                1                          0   
         1                                0                          0   
         2                                0                          0   
         3                                0                          0   
         4                                0                          0   
         5                                0                          0   
         6                                0                          0   
         7                                0                          0   
         8                                0                          0   
         9                                0                          0   
         
            EMERGENCYSTATE\_MODE\_No  EMERGENCYSTATE\_MODE\_Yes  TARGET  
         0                       1                        0       1  
         1                       1                        0       0  
         2                       0                        0       0  
         3                       0                        0       0  
         4                       0                        0       0  
         5                       0                        0       0  
         6                       0                        0       0  
         7                       0                        0       0  
         8                       0                        0       0  
         9                       0                        0       0  
         
         [10 rows x 237 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{c+c1}{\PYZsh{} Replace Nulls with NaN}
         \PY{c+c1}{\PYZsh{} mark zero values as missing or NaN}
         
         \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{NaN}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} count the number of NaN values in each column}
         \PY{k}{print}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} fill missing values with mean column values}
         \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} count the number of NaN values in each column}
         \PY{k}{print}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
SK\_ID\_CURR                                       0
CNT\_CHILDREN                                     0
AMT\_INCOME\_TOTAL                                 0
AMT\_CREDIT                                       0
AMT\_ANNUITY                                     12
AMT\_GOODS\_PRICE                                278
REGION\_POPULATION\_RELATIVE                       0
DAYS\_BIRTH                                       0
DAYS\_EMPLOYED                                    0
DAYS\_REGISTRATION                                0
DAYS\_ID\_PUBLISH                                  0
OWN\_CAR\_AGE                                 202929
FLAG\_MOBIL                                       0
FLAG\_EMP\_PHONE                                   0
FLAG\_WORK\_PHONE                                  0
FLAG\_CONT\_MOBILE                                 0
FLAG\_PHONE                                       0
FLAG\_EMAIL                                       0
CNT\_FAM\_MEMBERS                                  2
REGION\_RATING\_CLIENT                             0
REGION\_RATING\_CLIENT\_W\_CITY                      0
HOUR\_APPR\_PROCESS\_START                          0
REG\_REGION\_NOT\_LIVE\_REGION                       0
REG\_REGION\_NOT\_WORK\_REGION                       0
LIVE\_REGION\_NOT\_WORK\_REGION                      0
REG\_CITY\_NOT\_LIVE\_CITY                           0
REG\_CITY\_NOT\_WORK\_CITY                           0
LIVE\_CITY\_NOT\_WORK\_CITY                          0
EXT\_SOURCE\_1                                173378
EXT\_SOURCE\_2                                   660
                                             {\ldots}  
ORGANIZATION\_TYPE\_Trade: type 1                  0
ORGANIZATION\_TYPE\_Trade: type 2                  0
ORGANIZATION\_TYPE\_Trade: type 3                  0
ORGANIZATION\_TYPE\_Trade: type 4                  0
ORGANIZATION\_TYPE\_Trade: type 5                  0
ORGANIZATION\_TYPE\_Trade: type 6                  0
ORGANIZATION\_TYPE\_Trade: type 7                  0
ORGANIZATION\_TYPE\_Transport: type 1              0
ORGANIZATION\_TYPE\_Transport: type 2              0
ORGANIZATION\_TYPE\_Transport: type 3              0
ORGANIZATION\_TYPE\_Transport: type 4              0
ORGANIZATION\_TYPE\_University                     0
ORGANIZATION\_TYPE\_XNA                            0
FONDKAPREMONT\_MODE\_not specified                 0
FONDKAPREMONT\_MODE\_org spec account              0
FONDKAPREMONT\_MODE\_reg oper account              0
FONDKAPREMONT\_MODE\_reg oper spec account         0
HOUSETYPE\_MODE\_block of flats                    0
HOUSETYPE\_MODE\_specific housing                  0
HOUSETYPE\_MODE\_terraced house                    0
WALLSMATERIAL\_MODE\_Block                         0
WALLSMATERIAL\_MODE\_Mixed                         0
WALLSMATERIAL\_MODE\_Monolithic                    0
WALLSMATERIAL\_MODE\_Others                        0
WALLSMATERIAL\_MODE\_Panel                         0
WALLSMATERIAL\_MODE\_Stone, brick                  0
WALLSMATERIAL\_MODE\_Wooden                        0
EMERGENCYSTATE\_MODE\_No                           0
EMERGENCYSTATE\_MODE\_Yes                          0
TARGET                                           0
Length: 237, dtype: int64
SK\_ID\_CURR                                  0
CNT\_CHILDREN                                0
AMT\_INCOME\_TOTAL                            0
AMT\_CREDIT                                  0
AMT\_ANNUITY                                 0
AMT\_GOODS\_PRICE                             0
REGION\_POPULATION\_RELATIVE                  0
DAYS\_BIRTH                                  0
DAYS\_EMPLOYED                               0
DAYS\_REGISTRATION                           0
DAYS\_ID\_PUBLISH                             0
OWN\_CAR\_AGE                                 0
FLAG\_MOBIL                                  0
FLAG\_EMP\_PHONE                              0
FLAG\_WORK\_PHONE                             0
FLAG\_CONT\_MOBILE                            0
FLAG\_PHONE                                  0
FLAG\_EMAIL                                  0
CNT\_FAM\_MEMBERS                             0
REGION\_RATING\_CLIENT                        0
REGION\_RATING\_CLIENT\_W\_CITY                 0
HOUR\_APPR\_PROCESS\_START                     0
REG\_REGION\_NOT\_LIVE\_REGION                  0
REG\_REGION\_NOT\_WORK\_REGION                  0
LIVE\_REGION\_NOT\_WORK\_REGION                 0
REG\_CITY\_NOT\_LIVE\_CITY                      0
REG\_CITY\_NOT\_WORK\_CITY                      0
LIVE\_CITY\_NOT\_WORK\_CITY                     0
EXT\_SOURCE\_1                                0
EXT\_SOURCE\_2                                0
                                           ..
ORGANIZATION\_TYPE\_Trade: type 1             0
ORGANIZATION\_TYPE\_Trade: type 2             0
ORGANIZATION\_TYPE\_Trade: type 3             0
ORGANIZATION\_TYPE\_Trade: type 4             0
ORGANIZATION\_TYPE\_Trade: type 5             0
ORGANIZATION\_TYPE\_Trade: type 6             0
ORGANIZATION\_TYPE\_Trade: type 7             0
ORGANIZATION\_TYPE\_Transport: type 1         0
ORGANIZATION\_TYPE\_Transport: type 2         0
ORGANIZATION\_TYPE\_Transport: type 3         0
ORGANIZATION\_TYPE\_Transport: type 4         0
ORGANIZATION\_TYPE\_University                0
ORGANIZATION\_TYPE\_XNA                       0
FONDKAPREMONT\_MODE\_not specified            0
FONDKAPREMONT\_MODE\_org spec account         0
FONDKAPREMONT\_MODE\_reg oper account         0
FONDKAPREMONT\_MODE\_reg oper spec account    0
HOUSETYPE\_MODE\_block of flats               0
HOUSETYPE\_MODE\_specific housing             0
HOUSETYPE\_MODE\_terraced house               0
WALLSMATERIAL\_MODE\_Block                    0
WALLSMATERIAL\_MODE\_Mixed                    0
WALLSMATERIAL\_MODE\_Monolithic               0
WALLSMATERIAL\_MODE\_Others                   0
WALLSMATERIAL\_MODE\_Panel                    0
WALLSMATERIAL\_MODE\_Stone, brick             0
WALLSMATERIAL\_MODE\_Wooden                   0
EMERGENCYSTATE\_MODE\_No                      0
EMERGENCYSTATE\_MODE\_Yes                     0
TARGET                                      0
Length: 237, dtype: int64

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}40}]:} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}40}]:}    SK\_ID\_CURR  CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  \textbackslash{}
         0      100002             0          202500.0    406597.5      24700.5   
         1      100003             0          270000.0   1293502.5      35698.5   
         2      100004             0           67500.0    135000.0       6750.0   
         3      100006             0          135000.0    312682.5      29686.5   
         4      100007             0          121500.0    513000.0      21865.5   
         5      100008             0           99000.0    490495.5      27517.5   
         6      100009             1          171000.0   1560726.0      41301.0   
         7      100010             0          360000.0   1530000.0      42075.0   
         8      100011             0          112500.0   1019610.0      33826.5   
         9      100012             0          135000.0    405000.0      20250.0   
         
            AMT\_GOODS\_PRICE  REGION\_POPULATION\_RELATIVE  DAYS\_BIRTH  DAYS\_EMPLOYED  \textbackslash{}
         0         351000.0                    0.018801       -9461           -637   
         1        1129500.0                    0.003541      -16765          -1188   
         2         135000.0                    0.010032      -19046           -225   
         3         297000.0                    0.008019      -19005          -3039   
         4         513000.0                    0.028663      -19932          -3038   
         5         454500.0                    0.035792      -16941          -1588   
         6        1395000.0                    0.035792      -13778          -3130   
         7        1530000.0                    0.003122      -18850           -449   
         8         913500.0                    0.018634      -20099         365243   
         9         405000.0                    0.019689      -14469          -2019   
         
            DAYS\_REGISTRATION   {\ldots}    WALLSMATERIAL\_MODE\_Block  \textbackslash{}
         0            -3648.0   {\ldots}                           0   
         1            -1186.0   {\ldots}                           1   
         2            -4260.0   {\ldots}                           0   
         3            -9833.0   {\ldots}                           0   
         4            -4311.0   {\ldots}                           0   
         5            -4970.0   {\ldots}                           0   
         6            -1213.0   {\ldots}                           0   
         7            -4597.0   {\ldots}                           0   
         8            -7427.0   {\ldots}                           0   
         9           -14437.0   {\ldots}                           0   
         
            WALLSMATERIAL\_MODE\_Mixed  WALLSMATERIAL\_MODE\_Monolithic  \textbackslash{}
         0                         0                              0   
         1                         0                              0   
         2                         0                              0   
         3                         0                              0   
         4                         0                              0   
         5                         0                              0   
         6                         0                              0   
         7                         0                              0   
         8                         0                              0   
         9                         0                              0   
         
            WALLSMATERIAL\_MODE\_Others  WALLSMATERIAL\_MODE\_Panel  \textbackslash{}
         0                          0                         0   
         1                          0                         0   
         2                          0                         0   
         3                          0                         0   
         4                          0                         0   
         5                          0                         0   
         6                          0                         0   
         7                          0                         0   
         8                          0                         0   
         9                          0                         0   
         
            WALLSMATERIAL\_MODE\_Stone, brick  WALLSMATERIAL\_MODE\_Wooden  \textbackslash{}
         0                                1                          0   
         1                                0                          0   
         2                                0                          0   
         3                                0                          0   
         4                                0                          0   
         5                                0                          0   
         6                                0                          0   
         7                                0                          0   
         8                                0                          0   
         9                                0                          0   
         
            EMERGENCYSTATE\_MODE\_No  EMERGENCYSTATE\_MODE\_Yes  TARGET  
         0                       1                        0       1  
         1                       1                        0       0  
         2                       0                        0       0  
         3                       0                        0       0  
         4                       0                        0       0  
         5                       0                        0       0  
         6                       0                        0       0  
         7                       0                        0       0  
         8                       0                        0       0  
         9                       0                        0       0  
         
         [10 rows x 237 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}41}]:} \PY{c+c1}{\PYZsh{} \PYZsh{}Impute all features with Missing values}
         
         \PY{c+c1}{\PYZsh{} from sklearn.preprocessing import Imputer}
         \PY{c+c1}{\PYZsh{} \PYZsh{} fill missing values with mean column values}
         \PY{c+c1}{\PYZsh{} values = df\PYZus{}train.values}
         \PY{c+c1}{\PYZsh{} imputer = Imputer()}
         \PY{c+c1}{\PYZsh{} transformed\PYZus{}values = imputer.fit\PYZus{}transform(values)}
         \PY{c+c1}{\PYZsh{} \PYZsh{} count the number of NaN values in each column}
         \PY{c+c1}{\PYZsh{} print(np.isnan(transformed\PYZus{}values).sum())}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}42}]:} \PY{c+c1}{\PYZsh{}df\PYZus{}train.head(df\PYZus{}train.iloc[:,\PYZhy{}1]==0)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{c+c1}{\PYZsh{}LDA}
         
         \PY{k+kn}{from} \PY{n+nn}{sklearn.preprocessing} \PY{k+kn}{import} \PY{n}{Imputer}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.discriminant\PYZus{}analysis} \PY{k+kn}{import} \PY{n}{LinearDiscriminantAnalysis}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{KFold}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}
         
         \PY{c+c1}{\PYZsh{} split dataset into inputs and outputs}
         \PY{c+c1}{\PYZsh{}values = dataset.values}
         \PY{n}{X} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{y} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{c+c1}{\PYZsh{} fill missing values with mean column values}
         \PY{n}{imputer} \PY{o}{=} \PY{n}{Imputer}\PY{p}{(}\PY{p}{)}
         \PY{n}{transformed\PYZus{}X} \PY{o}{=} \PY{n}{imputer}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} evaluate an LDA model on the dataset using k\PYZhy{}fold cross validation}
         \PY{n}{model} \PY{o}{=} \PY{n}{LinearDiscriminantAnalysis}\PY{p}{(}\PY{p}{)}
         \PY{n}{kfold} \PY{o}{=} \PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{7}\PY{p}{)}
         \PY{n}{result} \PY{o}{=} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{transformed\PYZus{}X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{kfold}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
0.9189199767969486

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{c+c1}{\PYZsh{} Deploying Logistic Regression}
         \PY{c+c1}{\PYZsh{}Splitting the dataset}
         \PY{c+c1}{\PYZsh{}Keep the following 6 features (variables) which are important}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{preprocessing}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{rc}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{font}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LogisticRegression}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.cross\PYZus{}validation} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
         
         \PY{n}{X} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{y} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{metrics}
         \PY{n}{logreg} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
         \PY{n}{logreg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}44}]:} LogisticRegression(C=1.0, class\_weight=None, dual=False, fit\_intercept=True,
                   intercept\_scaling=1, max\_iter=100, multi\_class='ovr', n\_jobs=1,
                   penalty='l2', random\_state=None, solver='liblinear', tol=0.0001,
                   verbose=0, warm\_start=False)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{logreg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy of logistic regression classifier on test set: \PYZob{}:.2f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{logreg}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy of logistic regression classifier on test set: 0.92

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}46}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.metrics} \PY{k+kn}{import} \PY{n}{classification\PYZus{}report}\PY{p}{,}\PY{n}{accuracy\PYZus{}score}
         \PY{k}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
             precision    recall  f1-score   support

          0       0.92      1.00      0.96     56648
          1       0.00      0.00      0.00      4855

avg / total       0.85      0.92      0.88     61503

0.9210607612636782

    \end{Verbatim}

    The precision is the ratio tp / (tp + fp) where tp is the number of true
positives and fp the number of false positives. The precision is
intuitively the ability of the classifier not to label as positive a
sample that is negative. The recall is the ratio tp / (tp + fn) where tp
is the number of true positives and fn the number of false negatives.
The recall is intuitively the ability of the classifier to find all the
positive samples. The F-beta score can be interpreted as a weighted
harmonic mean of the precision and recall, where an F-beta score reaches
its best value at 1 and worst score at 0. The F-beta score weights
recall more than precision by a factor of beta. beta == 1.0 means recall
and precision are equally important. The support is the number of
occurrences of each class in y\_true.

courtesy:
http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision\_recall\_fscore\_support.html

    Baseline with Feature Scaling

     Here we perform imputation and normalizing the range of entire feature
set in order to get baseline model:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}47}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.preprocessing} \PY{k+kn}{import} \PY{n}{MinMaxScaler}\PY{p}{,} \PY{n}{Imputer}
         
         \PY{c+c1}{\PYZsh{} Drop the target from the training data}
         \PY{k}{if} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}} \PY{o+ow}{in} \PY{n}{df\PYZus{}train}\PY{p}{:}
             \PY{n}{train} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{k}{else}\PY{p}{:}
             \PY{n}{train} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
             
         \PY{c+c1}{\PYZsh{} Feature names}
         \PY{n}{features} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{columns}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Copy of the testing data}
         \PY{n}{test} \PY{o}{=} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Median imputation of missing values}
         \PY{n}{imputer} \PY{o}{=} \PY{n}{Imputer}\PY{p}{(}\PY{n}{strategy} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{median}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Scale each feature to 0\PYZhy{}1}
         \PY{n}{scaler} \PY{o}{=} \PY{n}{MinMaxScaler}\PY{p}{(}\PY{n}{feature\PYZus{}range} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Fit on the training data}
         \PY{n}{imputer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Transform both training and testing data}
         \PY{n}{train} \PY{o}{=} \PY{n}{imputer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{train}\PY{p}{)}
         \PY{n}{test} \PY{o}{=} \PY{n}{imputer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Repeat with the scaler}
         \PY{n}{scaler}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train}\PY{p}{)}
         \PY{n}{train} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{train}\PY{p}{)}
         \PY{n}{test} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{test}\PY{p}{)}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training data shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Testing data shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Training data shape: ', (307511, 236))
('Testing data shape: ', (48744, 236))

    \end{Verbatim}

    Deploying LogisticRegressionfrom Scikit-Learn for our first model. Steps
will be: Scikit-Learn modeling syntax to create the model train the
model using .fit predictions on the testing data using .predict\_proba 

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}48}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LogisticRegression}
         
         \PY{c+c1}{\PYZsh{} Make the model with the specified regularization parameter}
         \PY{n}{log\PYZus{}reg} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{n}{C} \PY{o}{=} \PY{l+m+mf}{0.0001}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Train on the training data}
         \PY{n}{log\PYZus{}reg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train}\PY{p}{,} \PY{n}{train\PYZus{}labels}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}48}]:} LogisticRegression(C=0.0001, class\_weight=None, dual=False,
                   fit\_intercept=True, intercept\_scaling=1, max\_iter=100,
                   multi\_class='ovr', n\_jobs=1, penalty='l2', random\_state=None,
                   solver='liblinear', tol=0.0001, verbose=0, warm\_start=False)
\end{Verbatim}
            
    Next step is predictions and selects the correct column:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}49}]:} \PY{c+c1}{\PYZsh{} Make predictions}
         \PY{c+c1}{\PYZsh{} Make sure to select the last column only}
         \PY{n}{log\PYZus{}reg\PYZus{}pred} \PY{o}{=} \PY{n}{log\PYZus{}reg}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{test}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
\end{Verbatim}


    The format for predictions file is as specified by Kaggle given in the
sample\_submission.csv file, where there are two columns: SK\_ID\_CURR
and TARGET:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}50}]:} \PY{c+c1}{\PYZsh{} Submission dataframe}
         \PY{n}{submit} \PY{o}{=} \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SK\PYZus{}ID\PYZus{}CURR}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
         \PY{n}{submit}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{log\PYZus{}reg\PYZus{}pred}
         
         \PY{n}{submit}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}50}]:}    SK\_ID\_CURR    TARGET
         0      100001  0.065186
         1      100005  0.123897
         2      100013  0.088657
         3      100028  0.058601
         4      100038  0.130668
\end{Verbatim}
            
    The predictions as given in Target variable should be assessed by the
Client and may decide to classify applicant whether can repay loan or
can not.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}51}]:} \PY{c+c1}{\PYZsh{} Save the submission to a csv file}
         \PY{n}{submit}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log\PYZus{}reg\PYZus{}baseline.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{index} \PY{o}{=} \PY{n+nb+bp}{False}\PY{p}{)}
\end{Verbatim}


     This is Data Wrangling complete with Baseline Model determined with
Logistic Regresssion; next we may proceed with EDA \& Inferential
Statistics,

    Inferential Statistics

    Function to Explore Numeric Data

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}52}]:} \PY{k}{def} \PY{n+nf}{numeric}\PY{p}{(}\PY{n}{col}\PY{p}{)}\PY{p}{:}
             \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Distribution of }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+}\PY{n}{col}\PY{p}{)}
             \PY{n}{ax} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}53}]:} \PY{n}{numeric}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AMT\PYZus{}CREDIT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_90_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}54}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AMT\PYZus{}INCOME\PYZus{}TOTAL}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{dtype}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}54}]:} dtype('float64')
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}55}]:} \PY{n}{numeric}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AMT\PYZus{}INCOME\PYZus{}TOTAL}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_92_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}56}]:} \PY{n}{numeric}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AMT\PYZus{}ANNUITY}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_93_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}57}]:} \PY{n}{numeric}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AMT\PYZus{}GOODS\PYZus{}PRICE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_94_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}58}]:} \PY{n}{anom} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{365243}\PY{p}{]}
         \PY{n}{non\PYZus{}anom} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{!=} \PY{l+m+mi}{365243}\PY{p}{]}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The non\PYZhy{}anomalies default on }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+si}{\PYZpc{}\PYZpc{}}\PY{l+s+s1}{ of loans}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{100} \PY{o}{*} \PY{n}{non\PYZus{}anom}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The anomalies default on }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+si}{\PYZpc{}\PYZpc{}}\PY{l+s+s1}{ of loans}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{100} \PY{o}{*} \PY{n}{anom}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{There are }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{ anomalous days of employment}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n+nb}{len}\PY{p}{(}\PY{n}{anom}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The non-anomalies default on 8.66\% of loans
The anomalies default on 5.40\% of loans
There are 55374 anomalous days of employment

    \end{Verbatim}

    Considering the anomalies I replace them with not a number (np.nan) and
create another boolean column to represent if value was anomalous.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}59}]:} \PY{c+c1}{\PYZsh{} Create an anomalous flag column}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED\PYZus{}ANOM}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{365243}
         
         \PY{c+c1}{\PYZsh{} Replace the anomalous values with nan}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+m+mi}{365243}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{nan}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{inplace} \PY{o}{=} \PY{n+nb+bp}{True}\PY{p}{)}
         
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{title} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days Employment Histogram}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days Employment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_97_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The distribution looks to be much more in line with what we would
expect, and we also have created a new column to tell the model that
these values were originally anomalous (becuase we will have to fill in
the nans with some value, probably the median of the column). The other
columns with DAYS in the dataframe look to be about what we expect with
no obvious outliers. As an extremely important note, anything we do to
the training data we also have to do to the testing data. Let's make
sure to create the new column and fill in the existing column with
np.nan in the testing data. The distribution looks to be much more in
line with what we would expect, and we also have created a new column to
tell the model that these values were originally anomalous (becuase we
will have to fill in the nans with some value, probably the median of
the column). The other columns with DAYS in the dataframe look to be
about what we expect with no obvious outliers.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}60}]:} \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED\PYZus{}ANOM}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{365243}
         \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+m+mi}{365243}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{nan}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{inplace} \PY{o}{=} \PY{n+nb+bp}{True}\PY{p}{)}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{There are }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{ anomalies in the test data out of }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{ entries}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DAYS\PYZus{}EMPLOYED\PYZus{}ANOM}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
There are 9274 anomalies in the test data out of 48744 entries

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}61}]:} \PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{l+m+mf}{365.0}\PY{p}{)}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}61}]:} count    307511.000000
         mean        -43.936973
         std          11.956133
         min         -69.120548
         25\%         -53.923288
         50\%         -43.150685
         75\%         -34.008219
         max         -20.517808
         Name: DAYS\_BIRTH, dtype: float64
\end{Verbatim}
            
    Dataset Prep for Another set of EDA

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}62}]:} \PY{k+kn}{from} \PY{n+nn}{plotly.offline} \PY{k+kn}{import} \PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{,} \PY{n}{iplot}
         \PY{k+kn}{from} \PY{n+nn}{wordcloud} \PY{k+kn}{import} \PY{n}{WordCloud}
         \PY{k+kn}{import} \PY{n+nn}{plotly.graph\PYZus{}objs} \PY{k+kn}{as} \PY{n+nn}{go}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt}
         \PY{k+kn}{import} \PY{n+nn}{plotly.plotly} \PY{k+kn}{as} \PY{n+nn}{py}
         \PY{k+kn}{from} \PY{n+nn}{plotly} \PY{k+kn}{import} \PY{n}{tools}
         \PY{k+kn}{from} \PY{n+nn}{datetime} \PY{k+kn}{import} \PY{n}{date}
         \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k+kn}{as} \PY{n+nn}{pd}
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np} 
         \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k+kn}{as} \PY{n+nn}{sns}
         \PY{k+kn}{import} \PY{n+nn}{random} 
         \PY{k+kn}{import} \PY{n+nn}{warnings}
         \PY{n}{warnings}\PY{o}{.}\PY{n}{filterwarnings}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ignore}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{(}\PY{n}{connected}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
         
         \PY{n}{path} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{../input/}\PY{l+s+s2}{\PYZdq{}}
         
         \PY{k}{def} \PY{n+nf}{bar\PYZus{}hor}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PY{n}{col}\PY{p}{,} \PY{n}{title}\PY{p}{,} \PY{n}{color}\PY{p}{,} \PY{n}{w}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{h}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{lm}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{limit}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{return\PYZus{}trace}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{,} \PY{n}{rev}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{,} \PY{n}{xlb} \PY{o}{=} \PY{n+nb+bp}{False}\PY{p}{)}\PY{p}{:}
             \PY{n}{cnt\PYZus{}srs} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
             \PY{n}{yy} \PY{o}{=} \PY{n}{cnt\PYZus{}srs}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{limit}\PY{p}{)}\PY{o}{.}\PY{n}{index}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} 
             \PY{n}{xx} \PY{o}{=} \PY{n}{cnt\PYZus{}srs}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{limit}\PY{p}{)}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} 
             \PY{k}{if} \PY{n}{rev}\PY{p}{:}
                 \PY{n}{yy} \PY{o}{=} \PY{n}{cnt\PYZus{}srs}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{n}{limit}\PY{p}{)}\PY{o}{.}\PY{n}{index}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} 
                 \PY{n}{xx} \PY{o}{=} \PY{n}{cnt\PYZus{}srs}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{n}{limit}\PY{p}{)}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} 
             \PY{k}{if} \PY{n}{xlb}\PY{p}{:}
                 \PY{n}{trace} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{n}{xlb}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{xx}\PY{p}{,} \PY{n}{orientation} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{h}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{n}{color}\PY{p}{)}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                 \PY{n}{trace} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{n}{yy}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{xx}\PY{p}{,} \PY{n}{orientation} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{h}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{n}{color}\PY{p}{)}\PY{p}{)}
             \PY{k}{if} \PY{n}{return\PYZus{}trace}\PY{p}{:}
                 \PY{k}{return} \PY{n}{trace} 
             \PY{n}{layout} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{title}\PY{o}{=}\PY{n}{title}\PY{p}{,} \PY{n}{margin}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{l}\PY{o}{=}\PY{n}{lm}\PY{p}{)}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{n}{w}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{n}{h}\PY{p}{)}
             \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{n}{trace}\PY{p}{]}
             \PY{n}{fig} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Figure}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,} \PY{n}{layout}\PY{o}{=}\PY{n}{layout}\PY{p}{)}
             \PY{n}{iplot}\PY{p}{(}\PY{n}{fig}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{bar\PYZus{}hor\PYZus{}noagg}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{title}\PY{p}{,} \PY{n}{color}\PY{p}{,} \PY{n}{w}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{h}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{lm}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{limit}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{rt}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}\PY{p}{:}
             \PY{n}{trace} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{n}{x}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{y}\PY{p}{,} \PY{n}{orientation} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{h}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{n}{color}\PY{p}{)}\PY{p}{)}
             \PY{k}{if} \PY{n}{rt}\PY{p}{:}
                 \PY{k}{return} \PY{n}{trace}
             \PY{n}{layout} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{title}\PY{o}{=}\PY{n}{title}\PY{p}{,} \PY{n}{margin}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{l}\PY{o}{=}\PY{n}{lm}\PY{p}{)}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{n}{w}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{n}{h}\PY{p}{)}
             \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{n}{trace}\PY{p}{]}
             \PY{n}{fig} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Figure}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,} \PY{n}{layout}\PY{o}{=}\PY{n}{layout}\PY{p}{)}
             \PY{n}{iplot}\PY{p}{(}\PY{n}{fig}\PY{p}{)}
         
         
         \PY{k}{def} \PY{n+nf}{bar\PYZus{}ver\PYZus{}noagg}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{title}\PY{p}{,} \PY{n}{color}\PY{p}{,} \PY{n}{w}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{h}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{lm}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{rt} \PY{o}{=} \PY{n+nb+bp}{False}\PY{p}{)}\PY{p}{:}
             \PY{n}{trace} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{n}{y}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{x}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{n}{color}\PY{p}{)}\PY{p}{)}
             \PY{k}{if} \PY{n}{rt}\PY{p}{:}
                 \PY{k}{return} \PY{n}{trace}
             \PY{n}{layout} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{title}\PY{o}{=}\PY{n}{title}\PY{p}{,} \PY{n}{margin}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{l}\PY{o}{=}\PY{n}{lm}\PY{p}{)}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{n}{w}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{n}{h}\PY{p}{)}
             \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{n}{trace}\PY{p}{]}
             \PY{n}{fig} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Figure}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,} \PY{n}{layout}\PY{o}{=}\PY{n}{layout}\PY{p}{)}
             \PY{n}{iplot}\PY{p}{(}\PY{n}{fig}\PY{p}{)}
             
         \PY{k}{def} \PY{n+nf}{gp}\PY{p}{(}\PY{n}{col}\PY{p}{,} \PY{n}{title}\PY{p}{)}\PY{p}{:}
             \PY{n}{df1} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TARGET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{]}
             \PY{n}{df0} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TARGET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{]}
             \PY{n}{a1} \PY{o}{=} \PY{n}{df1}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
             \PY{n}{b1} \PY{o}{=} \PY{n}{df0}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
             
             \PY{n}{total} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{x0} \PY{o}{=} \PY{n}{a1}\PY{o}{.}\PY{n}{index}
             \PY{n}{x1} \PY{o}{=} \PY{n}{b1}\PY{o}{.}\PY{n}{index}
             
             \PY{n}{y0} \PY{o}{=} \PY{p}{[}\PY{n+nb}{float}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100} \PY{o}{/} \PY{n}{total}\PY{p}{[}\PY{n}{x0}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{]} \PY{k}{for} \PY{n}{i}\PY{p}{,}\PY{n}{x} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{a1}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{]}
             \PY{n}{y1} \PY{o}{=} \PY{p}{[}\PY{n+nb}{float}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100} \PY{o}{/} \PY{n}{total}\PY{p}{[}\PY{n}{x1}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{]} \PY{k}{for} \PY{n}{i}\PY{p}{,}\PY{n}{x} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{b1}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{]}
         
             \PY{n}{trace1} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{a1}\PY{o}{.}\PY{n}{index}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{y0}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Target : 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}96D38C}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{trace2} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{b1}\PY{o}{.}\PY{n}{index}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{y1}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Target : 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}FEBFB3}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
             \PY{k}{return} \PY{n}{trace1}\PY{p}{,} \PY{n}{trace2} 
\end{Verbatim}


    
    
    Imbalance of Data

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}63}]:} \PY{n}{target\PYZus{}distribution} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
         \PY{n}{target\PYZus{}distribution}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{pie}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{,}
                                      \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Target Distribution}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                      \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{,} 
                                      \PY{n}{legend}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} 
                                      \PY{n}{autopct}\PY{o}{=}\PY{k}{lambda} \PY{n}{v}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZob{}:0.1f\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{v}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}63}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x1a118feb10>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_104_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Correlations

    Correlation analysis measures the statistical relationship between two
different variables. The result will show how the change in one
parameter would impact the other parameter. Correlation analysis is a
very important concept, popular in the field of predictive analytics.
Also, it is mandatory to complete the correlations analysis before
building the model and before arriving at a conclusion about variable
relationships. courtesy:
https://www.packtpub.com/mapt/book/big\_data\_and\_business\_intelligence/9781784396312/5/ch05lvl1sec55/eda-\/-correlation-analysis
(http://www.statstutor.ac.uk/resources/uploaded/pearsons.pdf) :

\begin{itemize}
\tightlist
\item
  .00-.19 ``very weak''
\item
  .20-.39 ``weak''
\item
  .40-.59 ``moderate''
\item
  .60-.79 ``strong''
\item
  .80-1.0 ``very strong''
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}64}]:} \PY{c+c1}{\PYZsh{} Find correlations with the target and sort}
         \PY{n}{correlations} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Display correlations}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Most Positive Correlations:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{correlations}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{)}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Most Negative Correlations:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{correlations}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Most Positive Correlations:\textbackslash{}n', OCCUPATION\_TYPE\_Laborers                             0.043019
FLAG\_DOCUMENT\_3                                      0.044346
REG\_CITY\_NOT\_LIVE\_CITY                               0.044395
FLAG\_EMP\_PHONE                                       0.045982
NAME\_EDUCATION\_TYPE\_Secondary / secondary special    0.049824
REG\_CITY\_NOT\_WORK\_CITY                               0.050994
DAYS\_ID\_PUBLISH                                      0.051457
CODE\_GENDER\_M                                        0.054713
DAYS\_LAST\_PHONE\_CHANGE                               0.055218
NAME\_INCOME\_TYPE\_Working                             0.057481
REGION\_RATING\_CLIENT                                 0.058899
REGION\_RATING\_CLIENT\_W\_CITY                          0.060893
DAYS\_EMPLOYED                                        0.074958
DAYS\_BIRTH                                           0.078239
TARGET                                               1.000000
Name: TARGET, dtype: float64)
('\textbackslash{}nMost Negative Correlations:\textbackslash{}n', EXT\_SOURCE\_2                           -0.160303
EXT\_SOURCE\_3                           -0.157397
EXT\_SOURCE\_1                           -0.099152
NAME\_EDUCATION\_TYPE\_Higher education   -0.056593
CODE\_GENDER\_F                          -0.054704
NAME\_INCOME\_TYPE\_Pensioner             -0.046209
DAYS\_EMPLOYED\_ANOM                     -0.045987
ORGANIZATION\_TYPE\_XNA                  -0.045987
EMERGENCYSTATE\_MODE\_No                 -0.042201
HOUSETYPE\_MODE\_block of flats          -0.040594
AMT\_GOODS\_PRICE                        -0.039628
REGION\_POPULATION\_RELATIVE             -0.037227
WALLSMATERIAL\_MODE\_Panel               -0.033119
AMT\_CREDIT                             -0.030369
FLOORSMAX\_AVG                          -0.029145
Name: TARGET, dtype: float64)

    \end{Verbatim}

    Let's take a look at some of more significant correlations: the
DAYS\_BIRTH is the most positive correlation. (except for TARGET because
the correlation of a variable with itself is always 1!) Looking at the
documentation, DAYS\_BIRTH is the age in days of the client at the time
of the loan in negative days (for whatever reason!). The correlation is
positive, but the value of this feature is actually negative, meaning
that as the client gets older, they are less likely to default on their
loan (ie the target == 0). That's a little confusing, so we will take
the absolute value of the feature and then the correlation will be
negative.

    Loan Repayment CRedibility by Age

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}65}]:} \PY{c+c1}{\PYZsh{} Find the correlation of the positive days since birth and target}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n+nb}{abs}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}65}]:} -0.07823930830982706
\end{Verbatim}
            
    Above finding shows more the age of the applicant lesser the risk in
client repayment of loan.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}66}]:} \PY{c+c1}{\PYZsh{} Set the style of plots}
         \PY{n}{plt}\PY{o}{.}\PY{n}{style}\PY{o}{.}\PY{n}{use}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fivethirtyeight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Plot the distribution of ages in years}
         \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{365}\PY{p}{,} \PY{n}{edgecolor} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bins} \PY{o}{=} \PY{l+m+mi}{25}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age of Client}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age (years)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_112_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}67}]:} \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k+kn}{as} \PY{n+nn}{sns}
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} KDE plot of loans that were repaid on time}
         \PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{365}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target == 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} KDE plot of loans which were not repaid on time}
         \PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{365}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target == 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Labeling of plot}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age (years)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Density}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Distribution of Ages}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_113_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    From the above graph we can see the applicants who showed risk in loan
repayment are mostly skewing towards left where the age of applicants
are lower than 40.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}68}]:} \PY{c+c1}{\PYZsh{} Age information into a separate dataframe}
         \PY{n}{age\PYZus{}data} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
         \PY{n}{age\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{age\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{365}
         
         \PY{c+c1}{\PYZsh{} Bin the age data}
         \PY{n}{age\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BINNED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{age\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{bins} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{70}\PY{p}{,} \PY{n}{num} \PY{o}{=} \PY{l+m+mi}{11}\PY{p}{)}\PY{p}{)}
         \PY{n}{age\PYZus{}data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}68}]:}    TARGET  DAYS\_BIRTH  YEARS\_BIRTH  YEARS\_BINNED
         0       1        9461    25.920548  (25.0, 30.0]
         1       0       16765    45.931507  (45.0, 50.0]
         2       0       19046    52.180822  (50.0, 55.0]
         3       0       19005    52.068493  (50.0, 55.0]
         4       0       19932    54.608219  (50.0, 55.0]
         5       0       16941    46.413699  (45.0, 50.0]
         6       0       13778    37.747945  (35.0, 40.0]
         7       0       18850    51.643836  (50.0, 55.0]
         8       0       20099    55.065753  (55.0, 60.0]
         9       0       14469    39.641096  (35.0, 40.0]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}69}]:} \PY{c+c1}{\PYZsh{} Group by the bin and calculate averages}
         \PY{n}{age\PYZus{}groups}  \PY{o}{=} \PY{n}{age\PYZus{}data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BINNED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
         \PY{n}{age\PYZus{}groups}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}69}]:}                 TARGET    DAYS\_BIRTH  YEARS\_BIRTH
         YEARS\_BINNED                                     
         (20.0, 25.0]  0.123036   8532.795625    23.377522
         (25.0, 30.0]  0.111436  10155.219250    27.822518
         (30.0, 35.0]  0.102814  11854.848377    32.479037
         (35.0, 40.0]  0.089414  13707.908253    37.555913
         (40.0, 45.0]  0.078491  15497.661233    42.459346
         (45.0, 50.0]  0.074171  17323.900441    47.462741
         (50.0, 55.0]  0.066968  19196.494791    52.593136
         (55.0, 60.0]  0.055314  20984.262742    57.491131
         (60.0, 65.0]  0.052737  22780.547460    62.412459
         (65.0, 70.0]  0.037270  24292.614340    66.555108
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}70}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Graph the age bins and the average of the target as a bar plot}
         \PY{n}{plt}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{n}{age\PYZus{}groups}\PY{o}{.}\PY{n}{index}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{str}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{100} \PY{o}{*} \PY{n}{age\PYZus{}groups}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Plot labeling}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{rotation} \PY{o}{=} \PY{l+m+mi}{75}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age Group (years)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Failure to Repay (}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Loan Repayment by Age Group}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_117_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Exterior Sources

    Exterior Sources The 3 variables with the strongest negative
correlations with the target are EXT\_SOURCE\_1, EXT\_SOURCE\_2, and
EXT\_SOURCE\_3. According to the documentation, these features represent
a "normalized score from external data source". I'm not sure what this
exactly means, but it may be a cumulative sort of credit rating made
using numerous sources of data.

Let's take a look at these variables.

First, we can show the correlations of the EXT\_SOURCE features with the
target and with each other.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}71}]:} \PY{c+c1}{\PYZsh{} Extract the EXT\PYZus{}SOURCE variables and show correlations}
         \PY{n}{ext\PYZus{}data} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NAME\PYZus{}EDUCATION\PYZus{}TYPE\PYZus{}Higher education}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CODE\PYZus{}GENDER\PYZus{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
         \PY{n}{ext\PYZus{}data\PYZus{}corrs} \PY{o}{=} \PY{n}{ext\PYZus{}data}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{p}{)}
         \PY{n}{ext\PYZus{}data\PYZus{}corrs}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{25}\PY{p}{,} \PY{l+m+mi}{36}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}71}]:} <matplotlib.figure.Figure at 0x1a127d8410>
\end{Verbatim}
            
    
    \begin{verbatim}
<matplotlib.figure.Figure at 0x1a127d8410>
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}72}]:} \PY{c+c1}{\PYZsh{} Heatmap of correlations}
         \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{ext\PYZus{}data\PYZus{}corrs}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{RdYlBu\PYZus{}r}\PY{p}{,} \PY{n}{vmin} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mf}{0.02}\PY{p}{,} \PY{n}{annot} \PY{o}{=} \PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{vmax} \PY{o}{=} \PY{l+m+mf}{0.5}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Correlation Heatmap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_121_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    EXT\_SOURCE\_1, EXT\_SOURCE\_2 and EXT\_SOURCE\_3 show inverse influence
on risk repayment ability of the applicant based on above correlation
heatmap.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}73}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{12}\PY{p}{)}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} iterate through the sources}
         \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{source} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
             
             \PY{c+c1}{\PYZsh{} create a new subplot for each source}
             \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{i} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} plot repaid loans}
             \PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{,} \PY{n}{source}\PY{p}{]}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target == 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} plot loans that were not repaid}
             \PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{source}\PY{p}{]}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target == 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Label the plots}
             \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Distribution of }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s1}{ by Target Value}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{source}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{source}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Density}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
             
         \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{n}{h\PYZus{}pad} \PY{o}{=} \PY{l+m+mf}{2.5}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_123_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Visualizing Data with Pairs Plot

    Pair plot is used to understand the best set of features to explain a
relationship between two variables or to form the most separated
clusters. It also helps to form some simple classification models by
drawing some simple lines or make linear separation in our dataset.
Courtesy: https://www.quora.com/What-are-pair-plots

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}74}]:} \PY{c+c1}{\PYZsh{} Copy the data for plotting}
         \PY{n}{plot\PYZus{}data} \PY{o}{=} \PY{n}{ext\PYZus{}data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Add in the age of the client in years}
         \PY{n}{plot\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{age\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} Drop na values and limit to first 100000 rows}
         \PY{n}{plot\PYZus{}data} \PY{o}{=} \PY{n}{plot\PYZus{}data}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{100000}\PY{p}{,} \PY{p}{:}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} Function to calculate correlation coefficient between two columns}
         \PY{k}{def} \PY{n+nf}{corr\PYZus{}func}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
             \PY{n}{r} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{corrcoef}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
             \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{gca}\PY{p}{(}\PY{p}{)}
             \PY{n}{ax}\PY{o}{.}\PY{n}{annotate}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r = \PYZob{}:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{r}\PY{p}{)}\PY{p}{,}
                         \PY{n}{xy}\PY{o}{=}\PY{p}{(}\PY{o}{.}\PY{l+m+mi}{2}\PY{p}{,} \PY{o}{.}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{,} \PY{n}{xycoords}\PY{o}{=}\PY{n}{ax}\PY{o}{.}\PY{n}{transAxes}\PY{p}{,}
                         \PY{n}{size} \PY{o}{=} \PY{l+m+mi}{20}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Create the pairgrid object}
         \PY{n}{grid} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{PairGrid}\PY{p}{(}\PY{n}{data} \PY{o}{=} \PY{n}{plot\PYZus{}data}\PY{p}{,} \PY{n}{size} \PY{o}{=} \PY{l+m+mi}{3}\PY{p}{,} \PY{n}{diag\PYZus{}sharey}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{,}
                             \PY{n}{hue} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                             \PY{n+nb}{vars} \PY{o}{=} \PY{p}{[}\PY{n}{x} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n+nb}{list}\PY{p}{(}\PY{n}{plot\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)} \PY{k}{if} \PY{n}{x} \PY{o}{!=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Upper is a scatter plot}
         \PY{n}{grid}\PY{o}{.}\PY{n}{map\PYZus{}upper}\PY{p}{(}\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{,} \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.2}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Diagonal is a histogram}
         \PY{n}{grid}\PY{o}{.}\PY{n}{map\PYZus{}diag}\PY{p}{(}\PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Bottom is density plot}
         \PY{n}{grid}\PY{o}{.}\PY{n}{map\PYZus{}lower}\PY{p}{(}\PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{OrRd\PYZus{}r}\PY{p}{)}\PY{p}{;}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ext Source and Age Features Pairs Plot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{size} \PY{o}{=} \PY{l+m+mi}{32}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+m+mf}{1.05}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

        ---------------------------------------------------------------------------

        KeyboardInterrupt                         Traceback (most recent call last)

        <ipython-input-74-152b87e43dbb> in <module>()
         29 
         30 \# Bottom is density plot
    ---> 31 grid.map\_lower(sns.kdeplot, cmap = plt.cm.OrRd\_r);
         32 
         33 plt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);


        /anaconda2/lib/python2.7/site-packages/seaborn/axisgrid.pyc in map\_lower(self, func, **kwargs)
       1423                 color = self.palette[k] if kw\_color is None else kw\_color
       1424                 func(data\_k[x\_var], data\_k[y\_var], label=label\_k,
    -> 1425                      color=color, **kwargs)
       1426 
       1427             self.\_clean\_axis(ax)


        /anaconda2/lib/python2.7/site-packages/seaborn/distributions.pyc in kdeplot(data, data2, shade, vertical, kernel, bw, gridsize, cut, clip, legend, cumulative, shade\_lowest, cbar, cbar\_ax, cbar\_kws, ax, **kwargs)
        651         ax = \_bivariate\_kdeplot(x, y, shade, shade\_lowest,
        652                                 kernel, bw, gridsize, cut, clip, legend,
    --> 653                                 cbar, cbar\_ax, cbar\_kws, ax, **kwargs)
        654     else:
        655         ax = \_univariate\_kdeplot(data, shade, vertical, kernel, bw,


        /anaconda2/lib/python2.7/site-packages/seaborn/distributions.pyc in \_bivariate\_kdeplot(x, y, filled, fill\_lowest, kernel, bw, gridsize, cut, clip, axlabel, cbar, cbar\_ax, cbar\_kws, ax, **kwargs)
        381     \# Calculate the KDE
        382     if \_has\_statsmodels:
    --> 383         xx, yy, z = \_statsmodels\_bivariate\_kde(x, y, bw, gridsize, cut, clip)
        384     else:
        385         xx, yy, z = \_scipy\_bivariate\_kde(x, y, bw, gridsize, cut, clip)


        /anaconda2/lib/python2.7/site-packages/seaborn/distributions.pyc in \_statsmodels\_bivariate\_kde(x, y, bw, gridsize, cut, clip)
        435     y\_support = \_kde\_support(y, kde.bw[1], gridsize, cut, clip[1])
        436     xx, yy = np.meshgrid(x\_support, y\_support)
    --> 437     z = kde.pdf([xx.ravel(), yy.ravel()]).reshape(xx.shape)
        438     return xx, yy, z
        439 


        /anaconda2/lib/python2.7/site-packages/statsmodels/nonparametric/kernel\_density.pyc in pdf(self, data\_predict)
        194             pdf\_est.append(gpke(self.bw, data=self.data,
        195                                 data\_predict=data\_predict[i, :],
    --> 196                                 var\_type=self.var\_type) / self.nobs)
        197 
        198         pdf\_est = np.squeeze(pdf\_est)


        /anaconda2/lib/python2.7/site-packages/statsmodels/nonparametric/\_kernel\_base.pyc in gpke(bw, data, data\_predict, var\_type, ckertype, okertype, ukertype, tosum)
        509     for ii, vtype in enumerate(var\_type):
        510         func = kernel\_func[kertypes[vtype]]
    --> 511         Kval[:, ii] = func(bw[ii], data[:, ii], data\_predict[ii])
        512 
        513     iscontinuous = np.array([c == 'c' for c in var\_type])


        /anaconda2/lib/python2.7/site-packages/statsmodels/nonparametric/kernels.pyc in gaussian(h, Xi, x)
        126 
        127     """
    --> 128     return (1. / np.sqrt(2 * np.pi)) * np.exp(-(Xi - x)**2 / (h**2 * 2.))
        129 
        130 


        KeyboardInterrupt: 

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_126_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    In this plot, the red indicates loans that were not repaid and the blue
are loans that are paid. We can see the different relationships within
the data. There does appear to be a moderate positive linear
relationship between the \texttt{EXT\_SOURCE\_1} and the
\texttt{DAYS\_BIRTH} (or equivalently \texttt{YEARS\_BIRTH}), indicating
that this feature may take into account the age of the client.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{n}\PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{n}{n}\PY{p}{)}
        \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
        \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)} 
        \PY{k}{print} \PY{p}{(}\PY{n}{y}\PY{p}{)}
        
        \PY{n}{\PYZus{}}\PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{\PYZus{}}\PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Customer Credibility to Repay Loan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{\PYZus{}}\PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ECDF}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{\PYZus{}}\PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{margins}\PY{p}{(}\PY{o}{.}\PY{l+m+mo}{02}\PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{} Checking ECDF Distribution of Ability to Repay Loan across the real data and theoretical samples of data}
        \PY{k}{def} \PY{n+nf}{ecdf}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{:}
            \PY{n}{x}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{data}\PY{p}{)}
            \PY{n}{n}\PY{o}{=} \PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{)}
            \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{n}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n}{n}
            \PY{k}{return} \PY{n}{x}\PY{p}{,}\PY{n}{y}
        
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{25}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Seed the random number generator:}
        \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{)}
        \PY{c+c1}{\PYZsh{}Sample data for theortical normal dist}
        \PY{n}{samples} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{TARGET}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{TARGET}\PY{p}{)}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{10000}\PY{p}{)}
        \PY{n}{samples}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}find ecdf of data}
        \PY{n}{x\PYZus{}count}\PY{p}{,} \PY{n}{y\PYZus{}count} \PY{o}{=} \PY{n}{ecdf}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{TARGET}\PY{p}{)}
        \PY{n}{x\PYZus{}theor}\PY{p}{,} \PY{n}{y\PYZus{}theor} \PY{o}{=} \PY{n}{ecdf}\PY{p}{(}\PY{n}{samples}\PY{p}{)}
        
        \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x\PYZus{}count}\PY{p}{,} \PY{n}{y\PYZus{}count}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x\PYZus{}theor}\PY{p}{,} \PY{n}{y\PYZus{}theor}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Label axes and add legend and a title:}
        \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Customer Credibility to Repay Loan VS Theoretical Normal Dist}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Customer to Repay Loan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ECDF}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Save and display the plots:}
        \PY{c+c1}{\PYZsh{}plt.savefig(\PYZsq{}reports/figures/cdf\PYZus{}body\PYZus{}temps.png\PYZsq{})}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    Compare the distribution of the data to the theoretical distribution of
the data. This is done by comparing the ecdf First define a function for
computing the ecdf from a data set. Next use np.random.normal to sample
the theoretical normal distribution and overlay the ecdf of both data
sets to compare distribution. Since theoretical ECDF is continuous curve
while real data set is contiguous bar for 0 \& 1 since it's
classification problem but we may consider any data points closer to
value '0' indicates 'will repay loan on time', 1 (will have difficulty
repaying loan)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{25}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{75}\PY{p}{,} \PY{l+m+mi}{90}\PY{p}{,} \PY{l+m+mi}{98}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{,} \PY{n}{column}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


     Variance

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


     Standard Deviation

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


     Covariance

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{np}\PY{o}{.}\PY{n}{cov}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{np}\PY{o}{.}\PY{n}{cov}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


     Pearson Correlation Coeffient

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{np}\PY{o}{.}\PY{n}{corrcoef}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}\PYZlt{}b\PYZgt{} Is the sample size large? Are the observations independent?}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{} print(\PYZsq{}We have\PYZsq{}, len(df\PYZus{}train), \PYZsq{}samples across\PYZsq{}, len(list(df\PYZus{}train.columns)), \PYZsq{}features.\PYZsq{})}
        \PY{c+c1}{\PYZsh{} \PYZsh{} confirmed here: https://ww2.amstat.org/publications/jse/datasets/normtemp.txt}
        
        \PY{c+c1}{\PYZsh{} print(df\PYZus{}train.groupby([\PYZsq{}CODE\PYZus{}GENDER\PYZsq{}]).count(), df\PYZus{}train.info())}
\end{Verbatim}


    Confidence Interval

     Step 1: Build a function to create a bootstrap replicate

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{def} \PY{n+nf}{bootstrap\PYZus{}replicate\PYZus{}1d}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{func}\PY{p}{)}\PY{p}{:}
            \PY{k}{return} \PY{n}{func}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}
        \PY{c+c1}{\PYZsh{}np.random.choice() works on linear model}
\end{Verbatim}


     Step 2: Another function to generate multiple such bootstrap samples

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{def} \PY{n+nf}{draw\PYZus{}bs\PYZus{}reps}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{func}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Draw bootstrap replicates.\PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} Initialize array of replicates: bs\PYZus{}replicates}
            \PY{n}{bs\PYZus{}replicates} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{empty}\PY{p}{(}\PY{n}{size}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Generate replicates}
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{size}\PY{p}{)}\PY{p}{:}
                \PY{n}{bs\PYZus{}replicates}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{bootstrap\PYZus{}replicate\PYZus{}1d}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{func}\PY{p}{)}
        
            \PY{k}{return} \PY{n}{bs\PYZus{}replicates}
\end{Verbatim}


     Step 3: Plot the histogram for bootstrap replicates

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{} Take 10,000 bootstrap replicates of the mean: bs\PYZus{}replicates}
        \PY{n}{bs\PYZus{}replicates} \PY{o}{=} \PY{n}{draw\PYZus{}bs\PYZus{}reps}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{,} \PY{l+m+mi}{10000}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Compute and print SEM Standard Error of the Mean}
        \PY{n}{sem} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{n}{sem}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Compute and print standard deviation of bootstrap replicates}
        \PY{n}{bs\PYZus{}std} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{bs\PYZus{}replicates}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{n}{bs\PYZus{}std}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Make a histogram of the results}
        \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{bs\PYZus{}replicates}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{normed}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
        \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Credit Loan Default Risk}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ECDF}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Show the plot}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


     This is bootstrap estimate of the probability distribution function of
the mean of 'Credit Loan Default Risk'at the Home Credit Group.
Remember, we are estimating the mean 'Credit Loan Default Risk' we would
get if the Home Credit Group could repeat all of the measurements over
and over again. This is a probabilistic estimate of the mean. I plot the
PDF as a histogram, and I see that it is not Normal as it has slightly
longer right tail.

In fact, it can be shown theoretically that under not-too-restrictive
conditions, the value of the mean will always be Normally distributed.
(This does not hold in general, just for the mean and a few other
statistics.) The standard deviation of this distribution, called the
standard error of the mean, or SEM, is given by the standard deviation
of the data divided by the square root of the number of data points.
I.e., for a data set. Notice that the SEM we got from the known
expression and the bootstrap replicates is the same and the distribution
of the bootstrap replicates of the mean is Normal.

     Assuming 95\% Confidence interval i.e. give the 2.5th and 97.5th
percentile of bootstrap replicates is stored as bs\_replicates

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{bs\PYZus{}replicates}\PY{p}{,} \PY{p}{[}\PY{l+m+mf}{2.5}\PY{p}{,} \PY{l+m+mf}{97.5}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


     The above steps may be repeated to show for Variance function as well

     Extending Confidence Interval Concept to Pairs Bootstrap

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}Finding pairs bootstrap for slope \PYZam{} intercept of a linear function between Bike REntal Count and Registered User Type}
        \PY{k}{def} \PY{n+nf}{draw\PYZus{}bs\PYZus{}pairs\PYZus{}linreg}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Perform pairs bootstrap for linear regression.\PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} Set up array of indices to sample from: inds}
            \PY{n}{inds} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Initialize replicates: bs\PYZus{}slope\PYZus{}reps, bs\PYZus{}intercept\PYZus{}reps}
            \PY{n}{bs\PYZus{}slope\PYZus{}reps} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{empty}\PY{p}{(}\PY{n}{size}\PY{p}{)}
            \PY{n}{bs\PYZus{}intercept\PYZus{}reps} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{empty}\PY{p}{(}\PY{n}{size}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Generate replicates}
            \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{size}\PY{p}{)}\PY{p}{:}
                \PY{n}{bs\PYZus{}inds} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{inds}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{inds}\PY{p}{)}\PY{p}{)}
                \PY{n}{bs\PYZus{}x}\PY{p}{,} \PY{n}{bs\PYZus{}y} \PY{o}{=} \PY{n}{x}\PY{p}{[}\PY{n}{bs\PYZus{}inds}\PY{p}{]}\PY{p}{,} \PY{n}{y}\PY{p}{[}\PY{n}{bs\PYZus{}inds}\PY{p}{]}
                \PY{n}{bs\PYZus{}slope\PYZus{}reps}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{bs\PYZus{}intercept\PYZus{}reps}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{polyfit}\PY{p}{(}\PY{n}{bs\PYZus{}x}\PY{p}{,} \PY{n}{bs\PYZus{}y}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
        
            \PY{k}{return} \PY{n}{bs\PYZus{}slope\PYZus{}reps}\PY{p}{,} \PY{n}{bs\PYZus{}intercept\PYZus{}reps}
        
        \PY{c+c1}{\PYZsh{} Generate replicates of slope and intercept using pairs bootstrap}
        \PY{n}{bs\PYZus{}slope\PYZus{}reps}\PY{p}{,} \PY{n}{bs\PYZus{}intercept\PYZus{}reps} \PY{o}{=} \PY{n}{draw\PYZus{}bs\PYZus{}pairs\PYZus{}linreg}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Compute and print 95\PYZpc{} CI for slope}
        \PY{k}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{bs\PYZus{}slope\PYZus{}reps}\PY{p}{,} \PY{p}{[}\PY{l+m+mf}{2.5}\PY{p}{,} \PY{l+m+mf}{97.5}\PY{p}{]}\PY{p}{)}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Plot the histogram}
        \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{bs\PYZus{}slope\PYZus{}reps}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{normed}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
        \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{slope}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PDF}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    Hypothesis Testing

     Null Hypothesis- There is no significant difference between
EXT\_SOURCE\_1 and EXT\_SOURCE\_2 mean on 'Ability to Repay Loan' H0:
EXT\_SOURCE\_1EXT\_SOURCE\_2=0 Significance Level: 95\% Confidence
=0.05 Alternate Hypothesis - There is significant difference between
EXT\_SOURCE\_1 and EXT\_SOURCE\_2 mean on 'Ability to Repay Loan' HA :
EXT\_SOURCE\_1EXT\_SOURCE\_2 != 0

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{def} \PY{n+nf}{permutation\PYZus{}sample}\PY{p}{(}\PY{n}{data1}\PY{p}{,} \PY{n}{data2}\PY{p}{)}\PY{p}{:}
            \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Generate a permutation sample from two data sets.\PYZdq{}\PYZdq{}\PYZdq{}}
        
            \PY{c+c1}{\PYZsh{} Concatenate the data sets: data}
            \PY{n}{data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{data1}\PY{p}{,} \PY{n}{data2}\PY{p}{)}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Permute the concatenated array: permuted\PYZus{}data}
            \PY{n}{permuted\PYZus{}data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{permutation}\PY{p}{(}\PY{n}{data}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Split the permuted array into two: perm\PYZus{}sample\PYZus{}1, perm\PYZus{}sample\PYZus{}2}
            \PY{n}{perm\PYZus{}sample\PYZus{}1} \PY{o}{=} \PY{n}{permuted\PYZus{}data}\PY{p}{[}\PY{p}{:}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data1}\PY{p}{)}\PY{p}{]}
            \PY{n}{perm\PYZus{}sample\PYZus{}2} \PY{o}{=} \PY{n}{permuted\PYZus{}data}\PY{p}{[}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data1}\PY{p}{)}\PY{p}{:}\PY{p}{]}
        
            \PY{k}{return} \PY{n}{perm\PYZus{}sample\PYZus{}1}\PY{p}{,} \PY{n}{perm\PYZus{}sample\PYZus{}2}
        
        \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{50}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} Generate permutation samples}
            \PY{n}{perm\PYZus{}sample\PYZus{}1}\PY{p}{,} \PY{n}{perm\PYZus{}sample\PYZus{}2} \PY{o}{=} \PY{n}{permutation\PYZus{}sample}\PY{p}{(}
                                            \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Compute and plot ECDF from permutation sample 1 }
            \PY{n}{x1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{perm\PYZus{}sample\PYZus{}1}\PY{p}{)}
            \PY{n}{y1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{p}{)} 
            
            \PY{c+c1}{\PYZsh{} Compute and plot ECDF from permutation sample 2}
            \PY{n}{x2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{perm\PYZus{}sample\PYZus{}2}\PY{p}{)}
            \PY{n}{y2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)}
        
        
            \PY{c+c1}{\PYZsh{} Plot ECDFs of permutation sample}
            \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{y1}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                         \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.02}\PY{p}{)}
            \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x2}\PY{p}{,} \PY{n}{y2}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                         \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.02}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Compute and plot ECDF from original \PYZsq{}registered\PYZsq{}}
        \PY{n}{x11} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
        \PY{n}{y11} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x11}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x11}\PY{p}{)}\PY{p}{)} 
        
        \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x11}\PY{p}{,} \PY{n}{y11}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Compute and plot ECDF from original \PYZsq{}casual\PYZsq{}}
        \PY{n}{x22} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
        \PY{n}{y22} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x22}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x22}\PY{p}{)}\PY{p}{)} 
        
        \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x22}\PY{p}{,} \PY{n}{y22}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{c+c1}{\PYZsh{} Make margins and label axes}
        \PY{n}{plt}\PY{o}{.}\PY{n}{margins}\PY{p}{(}\PY{l+m+mf}{0.02}\PY{p}{)}
        \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{External Data Source Influence}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ECDF}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Show the plot}
        \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


     Permutation samples ECDFs overlap and give a purple haze. Few of the
ECDFs from the permutation samples overlap with the observed External
Source Data1 data towards right of the graph \& even fewer overlap
towards left, suggesting that the hypothesis is not commensurate with
the data. External Source Data1 \& External Source Data2 are not
identically distributed and do not influence data in similar way. So
Null Hypothesis is rejected.

    In Depth Analysis

    Imbalanced datasets

    Here I will work on some techniques to handle highly unbalanced
datasets, with a focus on resampling. The Home Credit Risk Prediction
competition, is a classic problem of unbalanced classes, since Credit
Loan in risk can be considered unusual cases when considering all
clients. Other classic examples of unbalanced classes are the detection
of financial fraud and attacks on computer networks.

Let's see how unbalanced the dataset is:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k+kn}{as} \PY{n+nn}{pd}
        
        \PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{application\PYZus{}train.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{target\PYZus{}count} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{TARGET}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Class 0:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{target\PYZus{}count}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Class 1:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{target\PYZus{}count}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Proportion:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n+nb}{round}\PY{p}{(}\PY{n}{target\PYZus{}count}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{/} \PY{n}{target\PYZus{}count}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{: 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{n}{target\PYZus{}count}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kind}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bar}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Count (target)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


    Resampling

    Resampling

Resampling is the method that consists of drawing repeated samples from
the original data samples. The method of Resampling is a nonparametric
method of statistical inference. In other words, the method of
resampling does not involve the utilization of the generic distribution
tables (for example, normal distribution tables) in order to compute
approximate p probability values.

Resampling involves the selection of randomized cases with replacement
from the original data sample in such a manner that each number of the
sample drawn has a number of cases that are similar to the original data
sample. Due to replacement, the drawn number of samples that are used by
the method of resampling consists of repetitive cases. Courtesy:
http://www.statisticssolutions.com/sample-size-calculation-and-sample-size-justification-resampling/

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{} Class count}
        \PY{n}{count\PYZus{}class\PYZus{}0}\PY{p}{,} \PY{n}{count\PYZus{}class\PYZus{}1} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{TARGET}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
        
        \PY{c+c1}{\PYZsh{} Divide by class}
        \PY{n}{df\PYZus{}class\PYZus{}0} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{]}
        \PY{n}{df\PYZus{}class\PYZus{}1} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{]}
\end{Verbatim}


    Random under-sampling

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{df\PYZus{}class\PYZus{}0\PYZus{}under} \PY{o}{=} \PY{n}{df\PYZus{}class\PYZus{}0}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n}{count\PYZus{}class\PYZus{}1}\PY{p}{)}
        \PY{n}{df\PYZus{}test\PYZus{}under} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{df\PYZus{}class\PYZus{}0\PYZus{}under}\PY{p}{,} \PY{n}{df\PYZus{}class\PYZus{}1}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
        
        \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Random under\PYZhy{}sampling:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{n}{df\PYZus{}test\PYZus{}under}\PY{o}{.}\PY{n}{TARGET}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{df\PYZus{}test\PYZus{}under}\PY{o}{.}\PY{n}{TARGET}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kind}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bar}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Count (TARGET)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    Random over-sampling

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{df\PYZus{}class\PYZus{}1\PYZus{}over} \PY{o}{=} \PY{n}{df\PYZus{}class\PYZus{}1}\PY{o}{.}\PY{n}{sample}\PY{p}{(}\PY{n}{count\PYZus{}class\PYZus{}0}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
        \PY{n}{df\PYZus{}test\PYZus{}over} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{df\PYZus{}class\PYZus{}0}\PY{p}{,} \PY{n}{df\PYZus{}class\PYZus{}1\PYZus{}over}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
        
        \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Random over\PYZhy{}sampling:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{n}{df\PYZus{}test\PYZus{}over}\PY{o}{.}\PY{n}{TARGET}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{df\PYZus{}test\PYZus{}over}\PY{o}{.}\PY{n}{TARGET}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kind}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bar}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Count (TARGET)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    Python imbalanced-learn module

    This is the Python package to deal with Imbalance Class Problem.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{import} \PY{n+nn}{imblearn}
\end{Verbatim}


    For ease of visualization, let's create a small unbalanced sample
dataset using the make\_classification method:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.datasets} \PY{k+kn}{import} \PY{n}{make\PYZus{}classification}
        
        \PY{n}{X}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{n}{make\PYZus{}classification}\PY{p}{(}
            \PY{n}{n\PYZus{}classes}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{class\PYZus{}sep}\PY{o}{=}\PY{l+m+mf}{1.5}\PY{p}{,} \PY{n}{weights}\PY{o}{=}\PY{p}{[}\PY{l+m+mf}{0.9}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{]}\PY{p}{,}
            \PY{n}{n\PYZus{}informative}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{n\PYZus{}redundant}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{flip\PYZus{}y}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,}
            \PY{n}{n\PYZus{}features}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{n\PYZus{}clusters\PYZus{}per\PYZus{}class}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,}
            \PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{10}
        \PY{p}{)}
        
        \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{X}\PY{p}{)}
        \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{y}
        \PY{n}{df}\PY{o}{.}\PY{n}{TARGET}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{kind}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bar}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Count (TARGET)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    We will also create a 2-dimensional plot function, plot\_2d\_space, to
see the data distribution:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}2d\PYZus{}space}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Classes}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}   
            \PY{n}{colors} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{}1F77B4}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsh{}FF7F0E}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
            \PY{n}{markers} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
            \PY{k}{for} \PY{n}{l}\PY{p}{,} \PY{n}{c}\PY{p}{,} \PY{n}{m} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{p}{,} \PY{n}{colors}\PY{p}{,} \PY{n}{markers}\PY{p}{)}\PY{p}{:}
                \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}
                    \PY{n}{X}\PY{p}{[}\PY{n}{y}\PY{o}{==}\PY{n}{l}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,}
                    \PY{n}{X}\PY{p}{[}\PY{n}{y}\PY{o}{==}\PY{n}{l}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,}
                    \PY{n}{c}\PY{o}{=}\PY{n}{c}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{n}{l}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n}{m}
                \PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{n}{label}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{upper right}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    Because the dataset has many dimensions (features) and our graphs will
be 2D, we will reduce the size of the dataset using Principal Component
Analysis (PCA):

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.decomposition} \PY{k+kn}{import} \PY{n}{PCA}
        
        \PY{n}{pca} \PY{o}{=} \PY{n}{PCA}\PY{p}{(}\PY{n}{n\PYZus{}components}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{)}
        \PY{n}{X} \PY{o}{=} \PY{n}{pca}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X}\PY{p}{)}
        
        \PY{n}{plot\PYZus{}2d\PYZus{}space}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Imbalanced dataset (2 PCA components)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    Random under-sampling and over-sampling with imbalanced-learn

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{imblearn.under\PYZus{}sampling} \PY{k+kn}{import} \PY{n}{RandomUnderSampler}
        
        \PY{n}{rus} \PY{o}{=} \PY{n}{RandomUnderSampler}\PY{p}{(}\PY{n}{return\PYZus{}indices}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
        \PY{n}{X\PYZus{}rus}\PY{p}{,} \PY{n}{y\PYZus{}rus}\PY{p}{,} \PY{n}{id\PYZus{}rus} \PY{o}{=} \PY{n}{rus}\PY{o}{.}\PY{n}{fit\PYZus{}sample}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}
        
        \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Removed indexes:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{id\PYZus{}rus}\PY{p}{)}
        
        \PY{n}{plot\PYZus{}2d\PYZus{}space}\PY{p}{(}\PY{n}{X\PYZus{}rus}\PY{p}{,} \PY{n}{y\PYZus{}rus}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Random under\PYZhy{}sampling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{imblearn.over\PYZus{}sampling} \PY{k+kn}{import} \PY{n}{RandomOverSampler}
        
        \PY{n}{ros} \PY{o}{=} \PY{n}{RandomOverSampler}\PY{p}{(}\PY{p}{)}
        \PY{n}{X\PYZus{}ros}\PY{p}{,} \PY{n}{y\PYZus{}ros} \PY{o}{=} \PY{n}{ros}\PY{o}{.}\PY{n}{fit\PYZus{}sample}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}
        
        \PY{k}{print}\PY{p}{(}\PY{n}{X\PYZus{}ros}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{X}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{new random picked points}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        
        \PY{n}{plot\PYZus{}2d\PYZus{}space}\PY{p}{(}\PY{n}{X\PYZus{}ros}\PY{p}{,} \PY{n}{y\PYZus{}ros}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Random over\PYZhy{}sampling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    Under-sampling: Tomek links

    Tomek links remove unwanted overlap between classes where majority class
links are removed until all minimally distanced nearest neighbor pairs
are of the same class. courtesy:
https://en.wikipedia.org/wiki/Oversampling\_and\_undersampling\_in\_data\_analysis

    In the code below, we'll use ratio='majority' to resample the majority
class.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{imblearn.under\PYZus{}sampling} \PY{k+kn}{import} \PY{n}{TomekLinks}
        
        \PY{n}{tl} \PY{o}{=} \PY{n}{TomekLinks}\PY{p}{(}\PY{n}{return\PYZus{}indices}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{ratio}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{majority}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{X\PYZus{}tl}\PY{p}{,} \PY{n}{y\PYZus{}tl}\PY{p}{,} \PY{n}{id\PYZus{}tl} \PY{o}{=} \PY{n}{tl}\PY{o}{.}\PY{n}{fit\PYZus{}sample}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}
        
        \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Removed indexes:}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{id\PYZus{}tl}\PY{p}{)}
        
        \PY{n}{plot\PYZus{}2d\PYZus{}space}\PY{p}{(}\PY{n}{X\PYZus{}tl}\PY{p}{,} \PY{n}{y\PYZus{}tl}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Tomek links under\PYZhy{}sampling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    Under-sampling: Cluster Centroids

    Cluster centroids is a method that replaces cluster of samples by the
cluster centroid of a K-means algorithm, where the number of clusters is
set by the level of undersampling. courtesy:
https://en.wikipedia.org/wiki/Oversampling\_and\_undersampling\_in\_data\_analysis

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{imblearn.under\PYZus{}sampling} \PY{k+kn}{import} \PY{n}{ClusterCentroids}
        
        \PY{n}{cc} \PY{o}{=} \PY{n}{ClusterCentroids}\PY{p}{(}\PY{n}{ratio}\PY{o}{=}\PY{p}{\PYZob{}}\PY{l+m+mi}{0}\PY{p}{:} \PY{l+m+mi}{10}\PY{p}{\PYZcb{}}\PY{p}{)}
        \PY{n}{X\PYZus{}cc}\PY{p}{,} \PY{n}{y\PYZus{}cc} \PY{o}{=} \PY{n}{cc}\PY{o}{.}\PY{n}{fit\PYZus{}sample}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}
        
        \PY{n}{plot\PYZus{}2d\PYZus{}space}\PY{p}{(}\PY{n}{X\PYZus{}cc}\PY{p}{,} \PY{n}{y\PYZus{}cc}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Cluster Centroids under\PYZhy{}sampling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    Over-sampling: SMOTE

    There are a number of methods available to oversample a dataset used in
a typical classification problem (using a classification algorithm to
classify a set of images, given a labelled training set of images). The
most common technique is known as SMOTE: Synthetic Minority
Over-sampling Technique.

    We'll use ratio='minority' to resample the minority class.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{imblearn.over\PYZus{}sampling} \PY{k+kn}{import} \PY{n}{SMOTE}
        
        \PY{n}{smote} \PY{o}{=} \PY{n}{SMOTE}\PY{p}{(}\PY{n}{ratio}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{minority}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{X\PYZus{}sm}\PY{p}{,} \PY{n}{y\PYZus{}sm} \PY{o}{=} \PY{n}{smote}\PY{o}{.}\PY{n}{fit\PYZus{}sample}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}
        
        \PY{n}{plot\PYZus{}2d\PYZus{}space}\PY{p}{(}\PY{n}{X\PYZus{}sm}\PY{p}{,} \PY{n}{y\PYZus{}sm}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SMOTE over\PYZhy{}sampling}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    Over-sampling followed by under-sampling

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{imblearn.combine} \PY{k+kn}{import} \PY{n}{SMOTETomek}
        
        \PY{n}{smt} \PY{o}{=} \PY{n}{SMOTETomek}\PY{p}{(}\PY{n}{ratio}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auto}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{X\PYZus{}smt}\PY{p}{,} \PY{n}{y\PYZus{}smt} \PY{o}{=} \PY{n}{smt}\PY{o}{.}\PY{n}{fit\PYZus{}sample}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}
        
        \PY{n}{plot\PYZus{}2d\PYZus{}space}\PY{p}{(}\PY{n}{X\PYZus{}smt}\PY{p}{,} \PY{n}{y\PYZus{}smt}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SMOTE + Tomek links}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    Deploying Machine Learning Model over Resampled Dataset

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{} Deploying Logistic Regression}
        \PY{c+c1}{\PYZsh{}Splitting the dataset}
        \PY{c+c1}{\PYZsh{}Keep the following 6 features (variables) which are important}
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{preprocessing}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt} 
        \PY{n}{plt}\PY{o}{.}\PY{n}{rc}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{font}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LogisticRegression}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.cross\PYZus{}validation} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
        
        \PY{c+c1}{\PYZsh{} X = df\PYZus{}train.iloc[:, :\PYZhy{}1]}
        \PY{c+c1}{\PYZsh{} y = df\PYZus{}train.iloc[:,\PYZhy{}1]}
        \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X\PYZus{}smt}\PY{p}{,} \PY{n}{y\PYZus{}smt}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{metrics}
        \PY{n}{logreg} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
        \PY{n}{logreg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{logreg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy of logistic regression classifier on test set: \PYZob{}:.2f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{logreg}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.metrics} \PY{k+kn}{import} \PY{n}{classification\PYZus{}report}\PY{p}{,}\PY{n}{accuracy\PYZus{}score}
        \PY{k}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.metrics} \PY{k+kn}{import} \PY{n}{confusion\PYZus{}matrix}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k+kn}{as} \PY{n+nn}{sns}
        \PY{n}{mat} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
        \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{mat}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n}{square}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{d}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cbar}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{true label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predicted label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    Random Forest Classifier

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k}{def} \PY{n+nf}{visualize\PYZus{}classifier}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{ax}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{rainbow}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
            \PY{n}{ax} \PY{o}{=} \PY{n}{ax} \PY{o+ow}{or} \PY{n}{plt}\PY{o}{.}\PY{n}{gca}\PY{p}{(}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} Plot the training points}
            \PY{n}{ax}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{X}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{c}\PY{o}{=}\PY{n}{y}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{,} \PY{n}{cmap}\PY{o}{=}\PY{n}{cmap}\PY{p}{,}
                       \PY{n}{clim}\PY{o}{=}\PY{p}{(}\PY{n}{y}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{y}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,} \PY{n}{zorder}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}
            \PY{n}{ax}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{tight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{ax}\PY{o}{.}\PY{n}{axis}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{off}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{xlim} \PY{o}{=} \PY{n}{ax}\PY{o}{.}\PY{n}{get\PYZus{}xlim}\PY{p}{(}\PY{p}{)}
            \PY{n}{ylim} \PY{o}{=} \PY{n}{ax}\PY{o}{.}\PY{n}{get\PYZus{}ylim}\PY{p}{(}\PY{p}{)}
            
            \PY{c+c1}{\PYZsh{} fit the estimator}
            \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}
            \PY{n}{xx}\PY{p}{,} \PY{n}{yy} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{meshgrid}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{o}{*}\PY{n}{xlim}\PY{p}{,} \PY{n}{num}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{)}\PY{p}{,}
                                 \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{o}{*}\PY{n}{ylim}\PY{p}{,} \PY{n}{num}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{)}\PY{p}{)}
            \PY{n}{Z} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{c\PYZus{}}\PY{p}{[}\PY{n}{xx}\PY{o}{.}\PY{n}{ravel}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{yy}\PY{o}{.}\PY{n}{ravel}\PY{p}{(}\PY{p}{)}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{reshape}\PY{p}{(}\PY{n}{xx}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
        
            \PY{c+c1}{\PYZsh{} Create a color plot with the results}
            \PY{n}{n\PYZus{}classes} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{n}{y}\PY{p}{)}\PY{p}{)}
            \PY{n}{contours} \PY{o}{=} \PY{n}{ax}\PY{o}{.}\PY{n}{contourf}\PY{p}{(}\PY{n}{xx}\PY{p}{,} \PY{n}{yy}\PY{p}{,} \PY{n}{Z}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.3}\PY{p}{,}
                                   \PY{n}{levels}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{n}{n\PYZus{}classes} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.5}\PY{p}{,}
                                   \PY{n}{cmap}\PY{o}{=}\PY{n}{cmap}\PY{p}{,} \PY{n}{clim}\PY{o}{=}\PY{p}{(}\PY{n}{y}\PY{o}{.}\PY{n}{min}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{y}\PY{o}{.}\PY{n}{max}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{,}
                                   \PY{n}{zorder}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
        
            \PY{n}{ax}\PY{o}{.}\PY{n}{set}\PY{p}{(}\PY{n}{xlim}\PY{o}{=}\PY{n}{xlim}\PY{p}{,} \PY{n}{ylim}\PY{o}{=}\PY{n}{ylim}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.ensemble} \PY{k+kn}{import} \PY{n}{RandomForestClassifier}
        
        \PY{n}{model} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{n}{visualize\PYZus{}classifier}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{X\PYZus{}smt}\PY{p}{,} \PY{n}{y\PYZus{}smt}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.cross\PYZus{}validation} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
        
        \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X\PYZus{}smt}\PY{p}{,} \PY{n}{y\PYZus{}smt}\PY{p}{,}
                                                        \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
        \PY{n}{model} \PY{o}{=} \PY{n}{RandomForestClassifier}\PY{p}{(}\PY{n}{n\PYZus{}estimators}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
        \PY{n}{model}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
        \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{model}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.metrics} \PY{k+kn}{import} \PY{n}{classification\PYZus{}report}\PY{p}{,}\PY{n}{accuracy\PYZus{}score}
        \PY{k}{print}\PY{p}{(}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{p}{)}
        \PY{k}{print}\PY{p}{(}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{metrics}
        \PY{k}{print}\PY{p}{(}\PY{n}{metrics}\PY{o}{.}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.metrics} \PY{k+kn}{import} \PY{n}{confusion\PYZus{}matrix}
        \PY{n}{mat} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
        \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{mat}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n}{square}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{d}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cbar}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{true label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predicted label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    Decision Tree Classification

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k+kn}{as} \PY{n+nn}{pd}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.cross\PYZus{}validation} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.tree} \PY{k+kn}{import} \PY{n}{DecisionTreeClassifier}
        \PY{k+kn}{from} \PY{n+nn}{sklearn.metrics} \PY{k+kn}{import} \PY{n}{accuracy\PYZus{}score}
        \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{tree}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(} \PY{n}{X\PYZus{}smt}\PY{p}{,} \PY{n}{y\PYZus{}smt}\PY{p}{,} \PY{n}{test\PYZus{}size} \PY{o}{=} \PY{l+m+mf}{0.3}\PY{p}{,} \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{100}\PY{p}{)}
        \PY{n}{clf} \PY{o}{=} \PY{n}{tree}\PY{o}{.}\PY{n}{DecisionTreeClassifier}\PY{p}{(}\PY{p}{)}
        \PY{n}{clf}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X}\PY{o}{=}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{y\PYZus{}train}\PY{p}{)}
        \PY{n}{clf}\PY{o}{.}\PY{n}{feature\PYZus{}importances\PYZus{}} \PY{c+c1}{\PYZsh{} [ 1.,  0.,  0.]}
        \PY{n}{clf}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X}\PY{o}{=}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{y\PYZus{}test}\PY{p}{)} \PY{c+c1}{\PYZsh{} 1.0}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{clf}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{c+c1}{\PYZsh{}Accuracy Score}
        \PY{k}{print} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Accuracy is }\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,}\PY{n}{y\PYZus{}pred}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{metrics}
        \PY{k}{print}\PY{p}{(}\PY{n}{metrics}\PY{o}{.}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}pred}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.metrics} \PY{k+kn}{import} \PY{n}{confusion\PYZus{}matrix}
        \PY{n}{mat} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}pred}\PY{p}{)}
        \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{mat}\PY{o}{.}\PY{n}{T}\PY{p}{,} \PY{n}{square}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{annot}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{d}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{cbar}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{true label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{predicted label}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}



    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
