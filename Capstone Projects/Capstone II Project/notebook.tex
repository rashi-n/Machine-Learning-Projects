
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{EDA \& Inferential Statistics II}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    Introduction: Home Credit Default Risk Competition

    In this notebook, we will take an initial look at the Home Credit
default risk machine learning competition currently hosted on Kaggle.
The objective of this competition is to use historical loan application
data to predict whether or not an applicant will be able to repay a
loan. This is a standard supervised classification task:

Supervised: The labels are included in the training data and the goal is
to train a model to learn to predict the labels from the features
Classification: The label is a binary variable, 0 (will repay loan on
time), 1 (will have difficulty repaying loan)

    Objective

     Predict how capable each applicant is of repaying a loan

    Data

    The data is provided by Home Credit, a service dedicated to provided
lines of credit (loans) to the unbanked population. Predicting whether
or not a client will repay a loan or have difficulty is a critical
business need, and Home Credit is hosting this competition on Kaggle to
see what sort of models the machine learning community can develop to
help them in this task.

application\_train/application\_test: the main training and testing data
with information about each loan application at Home Credit. Every loan
has its own row and is identified by the feature SK\_ID\_CURR. The
training application data comes with the TARGET indicating 0: the loan
was repaid or 1: the loan was not repaid.

    Data Wrangling

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{c+c1}{\PYZsh{}Importing the libraries}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k+kn}{as} \PY{n+nn}{sns}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k+kn}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{warnings}
        \PY{n}{warnings}\PY{o}{.}\PY{n}{filterwarnings}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ignore}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{color} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{color\PYZus{}palette}\PY{p}{(}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{plotly.offline} \PY{k+kn}{as} \PY{n+nn}{py}
        \PY{n}{py}\PY{o}{.}\PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{(}\PY{n}{connected}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
        \PY{k+kn}{from} \PY{n+nn}{plotly.offline} \PY{k+kn}{import} \PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{,} \PY{n}{iplot}
        \PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{(}\PY{n}{connected}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
        \PY{k+kn}{import} \PY{n+nn}{plotly.graph\PYZus{}objs} \PY{k+kn}{as} \PY{n+nn}{go}
        \PY{k+kn}{import} \PY{n+nn}{plotly.offline} \PY{k+kn}{as} \PY{n+nn}{offline}
        \PY{n}{offline}\PY{o}{.}\PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    
    
    
    
    
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{c+c1}{\PYZsh{}Importing the dataset}
        \PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{application\PYZus{}train.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{df\PYZus{}test}\PY{o}{=}\PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{application\PYZus{}test.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{}Shape of dataset}
        \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}3}]:} (307511, 122)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}4}]:}    SK\_ID\_CURR NAME\_CONTRACT\_TYPE CODE\_GENDER FLAG\_OWN\_CAR FLAG\_OWN\_REALTY  \textbackslash{}
        0      100002         Cash loans           M            N               Y   
        1      100003         Cash loans           F            N               N   
        2      100004    Revolving loans           M            Y               Y   
        3      100006         Cash loans           F            N               Y   
        4      100007         Cash loans           M            N               Y   
        5      100008         Cash loans           M            N               Y   
        6      100009         Cash loans           F            Y               Y   
        7      100010         Cash loans           M            Y               Y   
        
           CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  AMT\_GOODS\_PRICE  \textbackslash{}
        0             0          202500.0    406597.5      24700.5         351000.0   
        1             0          270000.0   1293502.5      35698.5        1129500.0   
        2             0           67500.0    135000.0       6750.0         135000.0   
        3             0          135000.0    312682.5      29686.5         297000.0   
        4             0          121500.0    513000.0      21865.5         513000.0   
        5             0           99000.0    490495.5      27517.5         454500.0   
        6             1          171000.0   1560726.0      41301.0        1395000.0   
        7             0          360000.0   1530000.0      42075.0        1530000.0   
        
            {\ldots}   FLAG\_DOCUMENT\_19 FLAG\_DOCUMENT\_20 FLAG\_DOCUMENT\_21  \textbackslash{}
        0   {\ldots}                  0                0                0   
        1   {\ldots}                  0                0                0   
        2   {\ldots}                  0                0                0   
        3   {\ldots}                  0                0                0   
        4   {\ldots}                  0                0                0   
        5   {\ldots}                  0                0                0   
        6   {\ldots}                  0                0                0   
        7   {\ldots}                  0                0                0   
        
          AMT\_REQ\_CREDIT\_BUREAU\_HOUR AMT\_REQ\_CREDIT\_BUREAU\_DAY  \textbackslash{}
        0                        0.0                       0.0   
        1                        0.0                       0.0   
        2                        0.0                       0.0   
        3                        NaN                       NaN   
        4                        0.0                       0.0   
        5                        0.0                       0.0   
        6                        0.0                       0.0   
        7                        0.0                       0.0   
        
           AMT\_REQ\_CREDIT\_BUREAU\_WEEK  AMT\_REQ\_CREDIT\_BUREAU\_MON  \textbackslash{}
        0                         0.0                        0.0   
        1                         0.0                        0.0   
        2                         0.0                        0.0   
        3                         NaN                        NaN   
        4                         0.0                        0.0   
        5                         0.0                        0.0   
        6                         0.0                        1.0   
        7                         0.0                        0.0   
        
           AMT\_REQ\_CREDIT\_BUREAU\_QRT  AMT\_REQ\_CREDIT\_BUREAU\_YEAR  TARGET  
        0                        0.0                         1.0       1  
        1                        0.0                         0.0       0  
        2                        0.0                         0.0       0  
        3                        NaN                         NaN       0  
        4                        0.0                         0.0       0  
        5                        1.0                         1.0       0  
        6                        1.0                         2.0       0  
        7                        0.0                         0.0       0  
        
        [8 rows x 122 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}5}]:}           SK\_ID\_CURR   CNT\_CHILDREN  AMT\_INCOME\_TOTAL    AMT\_CREDIT  \textbackslash{}
        count  307511.000000  307511.000000      3.075110e+05  3.075110e+05   
        mean   278180.518577       0.417052      1.687979e+05  5.990260e+05   
        std    102790.175348       0.722121      2.371231e+05  4.024908e+05   
        min    100002.000000       0.000000      2.565000e+04  4.500000e+04   
        25\%    189145.500000       0.000000      1.125000e+05  2.700000e+05   
        50\%    278202.000000       0.000000      1.471500e+05  5.135310e+05   
        75\%    367142.500000       1.000000      2.025000e+05  8.086500e+05   
        max    456255.000000      19.000000      1.170000e+08  4.050000e+06   
        
                 AMT\_ANNUITY  AMT\_GOODS\_PRICE  REGION\_POPULATION\_RELATIVE  \textbackslash{}
        count  307499.000000     3.072330e+05               307511.000000   
        mean    27108.573909     5.383962e+05                    0.020868   
        std     14493.737315     3.694465e+05                    0.013831   
        min      1615.500000     4.050000e+04                    0.000290   
        25\%     16524.000000     2.385000e+05                    0.010006   
        50\%     24903.000000     4.500000e+05                    0.018850   
        75\%     34596.000000     6.795000e+05                    0.028663   
        max    258025.500000     4.050000e+06                    0.072508   
        
                  DAYS\_BIRTH  DAYS\_EMPLOYED  DAYS\_REGISTRATION      {\ldots}        \textbackslash{}
        count  307511.000000  307511.000000      307511.000000      {\ldots}         
        mean   -16036.995067   63815.045904       -4986.120328      {\ldots}         
        std      4363.988632  141275.766519        3522.886321      {\ldots}         
        min    -25229.000000  -17912.000000      -24672.000000      {\ldots}         
        25\%    -19682.000000   -2760.000000       -7479.500000      {\ldots}         
        50\%    -15750.000000   -1213.000000       -4504.000000      {\ldots}         
        75\%    -12413.000000    -289.000000       -2010.000000      {\ldots}         
        max     -7489.000000  365243.000000           0.000000      {\ldots}         
        
               FLAG\_DOCUMENT\_19  FLAG\_DOCUMENT\_20  FLAG\_DOCUMENT\_21  \textbackslash{}
        count     307511.000000     307511.000000     307511.000000   
        mean           0.000595          0.000507          0.000335   
        std            0.024387          0.022518          0.018299   
        min            0.000000          0.000000          0.000000   
        25\%            0.000000          0.000000          0.000000   
        50\%            0.000000          0.000000          0.000000   
        75\%            0.000000          0.000000          0.000000   
        max            1.000000          1.000000          1.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_HOUR  AMT\_REQ\_CREDIT\_BUREAU\_DAY  \textbackslash{}
        count               265992.000000              265992.000000   
        mean                     0.006402                   0.007000   
        std                      0.083849                   0.110757   
        min                      0.000000                   0.000000   
        25\%                      0.000000                   0.000000   
        50\%                      0.000000                   0.000000   
        75\%                      0.000000                   0.000000   
        max                      4.000000                   9.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_WEEK  AMT\_REQ\_CREDIT\_BUREAU\_MON  \textbackslash{}
        count               265992.000000              265992.000000   
        mean                     0.034362                   0.267395   
        std                      0.204685                   0.916002   
        min                      0.000000                   0.000000   
        25\%                      0.000000                   0.000000   
        50\%                      0.000000                   0.000000   
        75\%                      0.000000                   0.000000   
        max                      8.000000                  27.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_QRT  AMT\_REQ\_CREDIT\_BUREAU\_YEAR         TARGET  
        count              265992.000000               265992.000000  307511.000000  
        mean                    0.265474                    1.899974       0.080729  
        std                     0.794056                    1.869295       0.272419  
        min                     0.000000                    0.000000       0.000000  
        25\%                     0.000000                    0.000000       0.000000  
        50\%                     0.000000                    1.000000       0.000000  
        75\%                     0.000000                    3.000000       0.000000  
        max                   261.000000                   25.000000       1.000000  
        
        [8 rows x 106 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NAME\PYZus{}FAMILY\PYZus{}STATUS}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}6}]:} Married                 196432
        Single / not married     45444
        Civil marriage           29775
        Separated                19770
        Widow                    16088
        Unknown                      2
        Name: NAME\_FAMILY\_STATUS, dtype: int64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:}    SK\_ID\_CURR NAME\_CONTRACT\_TYPE CODE\_GENDER FLAG\_OWN\_CAR FLAG\_OWN\_REALTY  \textbackslash{}
        0      100001         Cash loans           F            N               Y   
        1      100005         Cash loans           M            N               Y   
        2      100013         Cash loans           M            Y               Y   
        3      100028         Cash loans           F            N               Y   
        4      100038         Cash loans           M            Y               N   
        
           CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  AMT\_GOODS\_PRICE  \textbackslash{}
        0             0          135000.0    568800.0      20560.5         450000.0   
        1             0           99000.0    222768.0      17370.0         180000.0   
        2             0          202500.0    663264.0      69777.0         630000.0   
        3             2          315000.0   1575000.0      49018.5        1575000.0   
        4             1          180000.0    625500.0      32067.0         625500.0   
        
                      {\ldots}             FLAG\_DOCUMENT\_18 FLAG\_DOCUMENT\_19  \textbackslash{}
        0             {\ldots}                            0                0   
        1             {\ldots}                            0                0   
        2             {\ldots}                            0                0   
        3             {\ldots}                            0                0   
        4             {\ldots}                            0                0   
        
          FLAG\_DOCUMENT\_20 FLAG\_DOCUMENT\_21 AMT\_REQ\_CREDIT\_BUREAU\_HOUR  \textbackslash{}
        0                0                0                        0.0   
        1                0                0                        0.0   
        2                0                0                        0.0   
        3                0                0                        0.0   
        4                0                0                        NaN   
        
           AMT\_REQ\_CREDIT\_BUREAU\_DAY  AMT\_REQ\_CREDIT\_BUREAU\_WEEK  \textbackslash{}
        0                        0.0                         0.0   
        1                        0.0                         0.0   
        2                        0.0                         0.0   
        3                        0.0                         0.0   
        4                        NaN                         NaN   
        
           AMT\_REQ\_CREDIT\_BUREAU\_MON  AMT\_REQ\_CREDIT\_BUREAU\_QRT  \textbackslash{}
        0                        0.0                        0.0   
        1                        0.0                        0.0   
        2                        0.0                        1.0   
        3                        0.0                        0.0   
        4                        NaN                        NaN   
        
           AMT\_REQ\_CREDIT\_BUREAU\_YEAR  
        0                         0.0  
        1                         3.0  
        2                         4.0  
        3                         3.0  
        4                         NaN  
        
        [5 rows x 121 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}8}]:}           SK\_ID\_CURR  CNT\_CHILDREN  AMT\_INCOME\_TOTAL    AMT\_CREDIT  \textbackslash{}
        count   48744.000000  48744.000000      4.874400e+04  4.874400e+04   
        mean   277796.676350      0.397054      1.784318e+05  5.167404e+05   
        std    103169.547296      0.709047      1.015226e+05  3.653970e+05   
        min    100001.000000      0.000000      2.694150e+04  4.500000e+04   
        25\%    188557.750000      0.000000      1.125000e+05  2.606400e+05   
        50\%    277549.000000      0.000000      1.575000e+05  4.500000e+05   
        75\%    367555.500000      1.000000      2.250000e+05  6.750000e+05   
        max    456250.000000     20.000000      4.410000e+06  2.245500e+06   
        
                 AMT\_ANNUITY  AMT\_GOODS\_PRICE  REGION\_POPULATION\_RELATIVE  \textbackslash{}
        count   48720.000000     4.874400e+04                48744.000000   
        mean    29426.240209     4.626188e+05                    0.021226   
        std     16016.368315     3.367102e+05                    0.014428   
        min      2295.000000     4.500000e+04                    0.000253   
        25\%     17973.000000     2.250000e+05                    0.010006   
        50\%     26199.000000     3.960000e+05                    0.018850   
        75\%     37390.500000     6.300000e+05                    0.028663   
        max    180576.000000     2.245500e+06                    0.072508   
        
                 DAYS\_BIRTH  DAYS\_EMPLOYED  DAYS\_REGISTRATION  \textbackslash{}
        count  48744.000000   48744.000000       48744.000000   
        mean  -16068.084605   67485.366322       -4967.652716   
        std     4325.900393  144348.507136        3552.612035   
        min   -25195.000000  -17463.000000      -23722.000000   
        25\%   -19637.000000   -2910.000000       -7459.250000   
        50\%   -15785.000000   -1293.000000       -4490.000000   
        75\%   -12496.000000    -296.000000       -1901.000000   
        max    -7338.000000  365243.000000           0.000000   
        
                          {\ldots}              FLAG\_DOCUMENT\_18  FLAG\_DOCUMENT\_19  \textbackslash{}
        count             {\ldots}                  48744.000000           48744.0   
        mean              {\ldots}                      0.001559               0.0   
        std               {\ldots}                      0.039456               0.0   
        min               {\ldots}                      0.000000               0.0   
        25\%               {\ldots}                      0.000000               0.0   
        50\%               {\ldots}                      0.000000               0.0   
        75\%               {\ldots}                      0.000000               0.0   
        max               {\ldots}                      1.000000               0.0   
        
               FLAG\_DOCUMENT\_20  FLAG\_DOCUMENT\_21  AMT\_REQ\_CREDIT\_BUREAU\_HOUR  \textbackslash{}
        count           48744.0           48744.0                42695.000000   
        mean                0.0               0.0                    0.002108   
        std                 0.0               0.0                    0.046373   
        min                 0.0               0.0                    0.000000   
        25\%                 0.0               0.0                    0.000000   
        50\%                 0.0               0.0                    0.000000   
        75\%                 0.0               0.0                    0.000000   
        max                 0.0               0.0                    2.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_DAY  AMT\_REQ\_CREDIT\_BUREAU\_WEEK  \textbackslash{}
        count               42695.000000                42695.000000   
        mean                    0.001803                    0.002787   
        std                     0.046132                    0.054037   
        min                     0.000000                    0.000000   
        25\%                     0.000000                    0.000000   
        50\%                     0.000000                    0.000000   
        75\%                     0.000000                    0.000000   
        max                     2.000000                    2.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_MON  AMT\_REQ\_CREDIT\_BUREAU\_QRT  \textbackslash{}
        count               42695.000000               42695.000000   
        mean                    0.009299                   0.546902   
        std                     0.110924                   0.693305   
        min                     0.000000                   0.000000   
        25\%                     0.000000                   0.000000   
        50\%                     0.000000                   0.000000   
        75\%                     0.000000                   1.000000   
        max                     6.000000                   7.000000   
        
               AMT\_REQ\_CREDIT\_BUREAU\_YEAR  
        count                42695.000000  
        mean                     1.983769  
        std                      1.838873  
        min                      0.000000  
        25\%                      0.000000  
        50\%                      2.000000  
        75\%                      3.000000  
        max                     17.000000  
        
        [8 rows x 105 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}9}]:} 0    282686
        1     24825
        Name: TARGET, dtype: int64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{int}\PY{p}{)}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    From this information, we see this is an imbalanced class
problem(http://www.chioka.in/class-imbalance-problem/). There are far
more loans that were repaid on time than loans that were not repaid.
Once we get into more sophisticated machine learning models, we can
weight the classes by their representation in the data to reflect this
imbalance.

    Examine Missing Values

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{c+c1}{\PYZsh{} Function to calculate missing values by column\PYZsh{} Funct }
         \PY{k}{def} \PY{n+nf}{missing\PYZus{}values\PYZus{}table}\PY{p}{(}\PY{n}{df}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} Total missing values}
                 \PY{n}{mis\PYZus{}val} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Percentage of missing values}
                 \PY{n}{mis\PYZus{}val\PYZus{}percent} \PY{o}{=} \PY{l+m+mi}{100} \PY{o}{*} \PY{n}{df}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{df}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Make a table with the results}
                 \PY{n}{mis\PYZus{}val\PYZus{}table} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{concat}\PY{p}{(}\PY{p}{[}\PY{n}{mis\PYZus{}val}\PY{p}{,} \PY{n}{mis\PYZus{}val\PYZus{}percent}\PY{p}{]}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Rename the columns}
                 \PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns} \PY{o}{=} \PY{n}{mis\PYZus{}val\PYZus{}table}\PY{o}{.}\PY{n}{rename}\PY{p}{(}
                 \PY{n}{columns} \PY{o}{=} \PY{p}{\PYZob{}}\PY{l+m+mi}{0} \PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Missing Values}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+m+mi}{1} \PY{p}{:} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{} o}\PY{l+s+s1}{f Total Values}\PY{l+s+s1}{\PYZsq{}}\PY{p}{\PYZcb{}}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Sort the table by percentage of missing descending}
                 \PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns} \PY{o}{=} \PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns}\PY{p}{[}
                     \PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{!=} \PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}
                 \PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{} o}\PY{l+s+s1}{f Total Values}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{ascending}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}\PY{o}{.}\PY{n}{round}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Print some summary information}
                 \PY{k}{print} \PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Your selected dataframe has }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{df}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{)} \PY{o}{+} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ columns.}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}      
                     \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{There are }\PY{l+s+s2}{\PYZdq{}} \PY{o}{+} \PY{n+nb}{str}\PY{p}{(}\PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{o}{+}
                       \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ columns that have missing values.}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
                 
                 \PY{c+c1}{\PYZsh{} Return the dataframe with missing information}
                 \PY{k}{return} \PY{n}{mis\PYZus{}val\PYZus{}table\PYZus{}ren\PYZus{}columns}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{c+c1}{\PYZsh{} Missing values statistics}
         \PY{n}{missing\PYZus{}values} \PY{o}{=} \PY{n}{missing\PYZus{}values\PYZus{}table}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{n}{missing\PYZus{}values}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Your selected dataframe has 122 columns.
There are 67 columns that have missing values.

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}12}]:}                           Missing Values  \% of Total Values
         COMMONAREA\_MEDI                   214865               69.9
         COMMONAREA\_AVG                    214865               69.9
         COMMONAREA\_MODE                   214865               69.9
         NONLIVINGAPARTMENTS\_MEDI          213514               69.4
         NONLIVINGAPARTMENTS\_MODE          213514               69.4
         NONLIVINGAPARTMENTS\_AVG           213514               69.4
         FONDKAPREMONT\_MODE                210295               68.4
         LIVINGAPARTMENTS\_MODE             210199               68.4
         LIVINGAPARTMENTS\_MEDI             210199               68.4
         LIVINGAPARTMENTS\_AVG              210199               68.4
         FLOORSMIN\_MODE                    208642               67.8
         FLOORSMIN\_MEDI                    208642               67.8
         FLOORSMIN\_AVG                     208642               67.8
         YEARS\_BUILD\_MODE                  204488               66.5
         YEARS\_BUILD\_MEDI                  204488               66.5
         YEARS\_BUILD\_AVG                   204488               66.5
         OWN\_CAR\_AGE                       202929               66.0
         LANDAREA\_AVG                      182590               59.4
         LANDAREA\_MEDI                     182590               59.4
         LANDAREA\_MODE                     182590               59.4
\end{Verbatim}
            
    When it comes time to build our machine learning models, we will have to
fill in these missing values (known as imputation). In later work, we
will use models such as XGBoost that can handle missing values with no
need for imputation. Another option would be to drop columns with a high
percentage of missing values, although it is impossible to know ahead of
time if these columns will be helpful to our model. Therefore, we will
keep all of the columns for now.

    Column Types

    Let's look at the number of columns of each data type. \texttt{int64}
and \texttt{float64} are numeric variables
(\href{https://stats.stackexchange.com/questions/206/what-is-the-difference-between-discrete-data-and-continuous-data}{which
can be either discrete or continuous}). \texttt{object} columns contain
strings and are
\href{http://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/what-are-categorical-discrete-and-continuous-variables/}{categorical
features.} .

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{c+c1}{\PYZsh{} Number of each type of column}
         \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{dtypes}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}13}]:} float64    65
         int64      41
         object     16
         dtype: int64
\end{Verbatim}
            
    Let's now look at the number of unique entries in each of the object
(categorical) columns.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} Number of unique classes in each object column}
         \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{select\PYZus{}dtypes}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{object}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{o}{.}\PY{n}{nunique}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}14}]:} NAME\_CONTRACT\_TYPE             2
         CODE\_GENDER                    3
         FLAG\_OWN\_CAR                   2
         FLAG\_OWN\_REALTY                2
         NAME\_TYPE\_SUITE                7
         NAME\_INCOME\_TYPE               8
         NAME\_EDUCATION\_TYPE            5
         NAME\_FAMILY\_STATUS             6
         NAME\_HOUSING\_TYPE              6
         OCCUPATION\_TYPE               18
         WEEKDAY\_APPR\_PROCESS\_START     7
         ORGANIZATION\_TYPE             58
         FONDKAPREMONT\_MODE             4
         HOUSETYPE\_MODE                 3
         WALLSMATERIAL\_MODE             7
         EMERGENCYSTATE\_MODE            2
         dtype: int64
\end{Verbatim}
            
    Most of the categorical variables have a relatively small number of
unique entries. We will need to find a way to deal with these
categorical variables!

    Encoding Categorical Variables

    Before we go any further, we need to deal with pesky categorical
variables. A machine learning model unfortunately cannot deal with
categorical variables (except for some models such as LightGBM).
Therefore, we have to find a way to encode (represent) these variables
as numbers before handing them off to the model. There are two main ways
to carry out this process:

Label encoding: assign each unique category in a categorical variable
with an integer. No new columns are created. An example is shown below
image
\includegraphics{https://raw.githubusercontent.com/WillKoehrsen/Machine-Learning-Projects/master/label_encoding.png}

One-hot encoding: create a new column for each unique category in a
categorical variable. Each observation recieves a 1 in the column for
its corresponding category and a 0 in all other new columns. image
\includegraphics{https://raw.githubusercontent.com/WillKoehrsen/Machine-Learning-Projects/master/one_hot_encoding.png}

The problem with label encoding is that it gives the categories an
arbitrary ordering. The value assigned to each of the categories is
random and does not reflect any inherent aspect of the category. In the
example above, programmer recieves a 4 and data scientist a 1, but if we
did the same process again, the labels could be reversed or completely
different. The actual assignment of the integers is arbitrary.
Therefore, when we perform label encoding, the model might use the
relative value of the feature (for example programmer = 4 and data
scientist = 1) to assign weights which is not what we want. If we only
have two unique values for a categorical variable (such as Male/Female),
then label encoding is fine, but for more than 2 unique categories,
one-hot encoding is the safe option.

There is some debate about the relative merits of these approaches, and
some models can deal with label encoded categorical variables with no
issues. Here is a good Stack Overflow discussion. I think (and this is
just a personal opinion) for categorical variables with many classes,
one-hot encoding is the safest approach because it does not impose
arbitrary values to categories. The only downside to one-hot encoding is
that the number of features (dimensions of the data) can explode with
categorical variables with many categories. To deal with this, we can
perform one-hot encoding followed by PCA or other dimensionality
reduction methods to reduce the number of dimensions (while still trying
to preserve information).

In this notebook, we will use Label Encoding for any categorical
variables with only 2 categories and One-Hot Encoding for any
categorical variables with more than 2 categories. This process may need
to change as we get further into the project, but for now, we will see
where this gets us. (We will also not use any dimensionality reduction
in this notebook but will explore in future iter

    Label Encoding and One-Hot Encoding

    Let's implement the policy described above: for any categorical variable
(\texttt{dtype\ ==\ object}) with 2 unique categories, we will use label
encoding, and for any categorical variable with more than 2 unique
categories, we will use one-hot encoding.

For label encoding, we use the Scikit-Learn \texttt{LabelEncoder} and
for one-hot encoding, the pandas \texttt{get\_dummies(df)} function.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.preprocessing} \PY{k+kn}{import} \PY{n}{LabelEncoder}
         \PY{c+c1}{\PYZsh{} Create a label encoder object}
         \PY{n}{le} \PY{o}{=} \PY{n}{LabelEncoder}\PY{p}{(}\PY{p}{)}
         \PY{n}{le\PYZus{}count} \PY{o}{=} \PY{l+m+mi}{0}
         
         \PY{c+c1}{\PYZsh{} Iterate through the columns}
         \PY{k}{for} \PY{n}{col} \PY{o+ow}{in} \PY{n}{df\PYZus{}train}\PY{p}{:}
             \PY{k}{if} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{dtype} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{object}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} If 2 or fewer unique categories}
                 \PY{k}{if} \PY{n+nb}{len}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZlt{}}\PY{o}{=} \PY{l+m+mi}{2}\PY{p}{:}
                     \PY{c+c1}{\PYZsh{} Train on the training data}
                     \PY{n}{le}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{p}{)}
                     \PY{c+c1}{\PYZsh{} Transform both training and testing data}
                     \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]} \PY{o}{=} \PY{n}{le}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{p}{)}
                     \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{n}{col}\PY{p}{]} \PY{o}{=} \PY{n}{le}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{p}{)}
                     
                     \PY{c+c1}{\PYZsh{} Keep track of how many columns were label encoded}
                     \PY{n}{le\PYZus{}count} \PY{o}{+}\PY{o}{=} \PY{l+m+mi}{1}
                     
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{ columns were label encoded.}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{le\PYZus{}count}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
3 columns were label encoded.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{c+c1}{\PYZsh{} one\PYZhy{}hot encoding of categorical variables}
         \PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{n}{df\PYZus{}test} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{)}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Testing Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Training Features shape: ', (307511, 243))
('Testing Features shape: ', (48744, 239))

    \end{Verbatim}

    Aligning Training and Testing Data

    Aligning Training and Testing Data There need to be the same features
(columns) in both the training and testing data. One-hot encoding has
created more columns in the training data because there were some
categorical variables with categories not represented in the testing
data. To remove the columns in the training data that are not in the
testing data, we need to align the dataframes. First we extract the
target column from the training data (because this is not in the testing
data but we need to keep this information). When we do the align, we
must make sure to set axis = 1 to align the dataframes based on the
columns and not on the rows!

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{train\PYZus{}labels} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} Align the training and testing data, keep only columns present in both dataframes}
         \PY{n}{df\PYZus{}train}\PY{p}{,} \PY{n}{df\PYZus{}test} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{align}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{,} \PY{n}{join} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inner}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Add the target back in}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{train\PYZus{}labels}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Testing Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Training Features shape: ', (307511, 240))
('Testing Features shape: ', (48744, 239))

    \end{Verbatim}

    The training and testing datasets now have the same features which is
required for machine learning. The number of features has grown
significantly due to one-hot encoding. At some point we probably will
want to try dimensionality reduction (removing features that are not
relevant) to reduce the size of the datasets.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{c+c1}{\PYZsh{} \PYZsh{} Missing Value Strategy}
         \PY{c+c1}{\PYZsh{} from sklearn.ensemble import RandomForestRegressor}
         \PY{c+c1}{\PYZsh{} from sklearn.pipeline import Pipeline}
         \PY{c+c1}{\PYZsh{} from sklearn.preprocessing import Imputer}
         \PY{c+c1}{\PYZsh{} from sklearn.model\PYZus{}selection import cross\PYZus{}val\PYZus{}score}
         
         \PY{c+c1}{\PYZsh{} rng = np.random.RandomState(0)}
         
         \PY{c+c1}{\PYZsh{} \PYZsh{} X\PYZus{}full, y\PYZus{}full = df\PYZus{}train.iloc[:, :\PYZhy{}1], df\PYZus{}train.iloc[:, \PYZhy{}1]}
         \PY{c+c1}{\PYZsh{} n\PYZus{}samples = X\PYZus{}full.shape[0]}
         \PY{c+c1}{\PYZsh{} n\PYZus{}features = X\PYZus{}full.shape[1]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{c+c1}{\PYZsh{} \PYZsh{} Estimate the score on the entire dataset, with no missing values}
         \PY{c+c1}{\PYZsh{} estimator = RandomForestRegressor(random\PYZus{}state=0, n\PYZus{}estimators=100)}
         \PY{c+c1}{\PYZsh{} score = cross\PYZus{}val\PYZus{}score(estimator, X\PYZus{}full, y\PYZus{}full).mean()}
         \PY{c+c1}{\PYZsh{} print(\PYZdq{}Score with the entire dataset = \PYZpc{}.2f\PYZdq{} \PYZpc{} score)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{c+c1}{\PYZsh{} \PYZsh{} Add missing values in 75\PYZpc{} of the lines}
         \PY{c+c1}{\PYZsh{} missing\PYZus{}rate = 0.75}
         \PY{c+c1}{\PYZsh{} n\PYZus{}missing\PYZus{}samples = np.floor(n\PYZus{}samples * missing\PYZus{}rate)}
         \PY{c+c1}{\PYZsh{} missing\PYZus{}samples = np.hstack((np.zeros(n\PYZus{}samples \PYZhy{} n\PYZus{}missing\PYZus{}samples,}
         \PY{c+c1}{\PYZsh{}                                       dtype=np.bool),}
         \PY{c+c1}{\PYZsh{}                              np.ones(n\PYZus{}missing\PYZus{}samples,}
         \PY{c+c1}{\PYZsh{}                                      dtype=np.bool)))}
         \PY{c+c1}{\PYZsh{} rng.shuffle(missing\PYZus{}samples)}
         \PY{c+c1}{\PYZsh{} missing\PYZus{}features = rng.randint(0, n\PYZus{}features, n\PYZus{}missing\PYZus{}samples)}
         
         \PY{c+c1}{\PYZsh{} \PYZsh{} Estimate the score without the lines containing missing values}
         \PY{c+c1}{\PYZsh{} X\PYZus{}filtered = X\PYZus{}full[\PYZti{}missing\PYZus{}samples, :]}
         \PY{c+c1}{\PYZsh{} y\PYZus{}filtered = y\PYZus{}full[\PYZti{}missing\PYZus{}samples]}
         \PY{c+c1}{\PYZsh{} estimator = RandomForestRegressor(random\PYZus{}state=0, n\PYZus{}estimators=100)}
         \PY{c+c1}{\PYZsh{} score = cross\PYZus{}val\PYZus{}score(estimator, X\PYZus{}filtered, y\PYZus{}filtered).mean()}
         \PY{c+c1}{\PYZsh{} print(\PYZdq{}Score without the samples containing missing values = \PYZpc{}.2f\PYZdq{} \PYZpc{} score)}
         
         
         \PY{c+c1}{\PYZsh{} \PYZsh{} Estimate the score after imputation of the missing values}
         \PY{c+c1}{\PYZsh{} X\PYZus{}missing = X\PYZus{}full.copy()}
         \PY{c+c1}{\PYZsh{} X\PYZus{}missing[np.where(missing\PYZus{}samples)[0], missing\PYZus{}features] = 0}
         \PY{c+c1}{\PYZsh{} y\PYZus{}missing = y\PYZus{}full.copy()}
         \PY{c+c1}{\PYZsh{} estimator = Pipeline([(\PYZdq{}imputer\PYZdq{}, Imputer(missing\PYZus{}values=0,}
         \PY{c+c1}{\PYZsh{}                                           strategy=\PYZdq{}mean\PYZdq{},}
         \PY{c+c1}{\PYZsh{}                                           axis=0)),}
         \PY{c+c1}{\PYZsh{}                       (\PYZdq{}forest\PYZdq{}, RandomForestRegressor(random\PYZus{}state=0,}
         \PY{c+c1}{\PYZsh{}                                                        n\PYZus{}estimators=100))])}
         \PY{c+c1}{\PYZsh{} score = cross\PYZus{}val\PYZus{}score(estimator, X\PYZus{}missing, y\PYZus{}missing).mean()}
         \PY{c+c1}{\PYZsh{} print(\PYZdq{}Score after imputation of the missing values = \PYZpc{}.2f\PYZdq{} \PYZpc{} score)}
\end{Verbatim}


    Resuming Exploratory Data Analysis

    Anomalies

One problem we always want to be on the lookout for when doing EDA is
anomalies within the data. These may be due to mis-typed numbers, errors
in measuring equipment, or they could be valid but extreme measurements.
One way to support anomalies quantitatively is by looking at the
statistics of a column using the \texttt{describe} method. The numbers
in the \texttt{DAYS\_BIRTH} column are negative because they are
recorded relative to the current loan application. To see these stats in
years, we can mutliple by -1 and divide by the number of days in a year:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{c+c1}{\PYZsh{} \PYZsh{} Missing values statistics}
         \PY{c+c1}{\PYZsh{} missing\PYZus{}values = missing\PYZus{}values\PYZus{}table(df\PYZus{}train)}
         \PY{c+c1}{\PYZsh{} missing\PYZus{}values.head(20)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{o}{\PYZhy{}}\PY{l+m+mi}{365}\PY{p}{)}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}22}]:} count    307511.000000
         mean         43.936973
         std          11.956133
         min          20.517808
         25\%          34.008219
         50\%          43.150685
         75\%          53.923288
         max          69.120548
         Name: DAYS\_BIRTH, dtype: float64
\end{Verbatim}
            
    Those ages look reasonable. There are no outliers for the age on either
the high or low end. How about the days of employment?

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}23}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}23}]:} count    307511.000000
         mean      63815.045904
         std      141275.766519
         min      -17912.000000
         25\%       -2760.000000
         50\%       -1213.000000
         75\%        -289.000000
         max      365243.000000
         Name: DAYS\_EMPLOYED, dtype: float64
\end{Verbatim}
            
    That doesn't look right! The maximum value (besides being positive) is
about 1000 years!

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}24}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{title} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days Employment Histogram}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days Employment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_48_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Just out of curiousity, let's subset the anomalous clients and see if
they tend to have higher or low rates of default than the rest of the
clients.

    Missing Values Strategy \# 1 - Identify Features with Missing Values
-\textgreater{} Replace with NaN -\textgreater{} Remove all Features
with Missing Value -\textgreater{} Assess Model using Logistic
Regression

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{c+c1}{\PYZsh{} Missing values statistics}
         \PY{n}{missing\PYZus{}values} \PY{o}{=} \PY{n}{missing\PYZus{}values\PYZus{}table}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{n}{missing\PYZus{}values}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Your selected dataframe has 240 columns.
There are 61 columns that have missing values.

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}25}]:}                           Missing Values  \% of Total Values
         COMMONAREA\_MODE                   214865               69.9
         COMMONAREA\_MEDI                   214865               69.9
         COMMONAREA\_AVG                    214865               69.9
         NONLIVINGAPARTMENTS\_MODE          213514               69.4
         NONLIVINGAPARTMENTS\_AVG           213514               69.4
         NONLIVINGAPARTMENTS\_MEDI          213514               69.4
         LIVINGAPARTMENTS\_MEDI             210199               68.4
         LIVINGAPARTMENTS\_AVG              210199               68.4
         LIVINGAPARTMENTS\_MODE             210199               68.4
         FLOORSMIN\_MEDI                    208642               67.8
         FLOORSMIN\_MODE                    208642               67.8
         FLOORSMIN\_AVG                     208642               67.8
         YEARS\_BUILD\_AVG                   204488               66.5
         YEARS\_BUILD\_MODE                  204488               66.5
         YEARS\_BUILD\_MEDI                  204488               66.5
         OWN\_CAR\_AGE                       202929               66.0
         LANDAREA\_MEDI                     182590               59.4
         LANDAREA\_MODE                     182590               59.4
         LANDAREA\_AVG                      182590               59.4
         BASEMENTAREA\_MODE                 179943               58.5
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{c+c1}{\PYZsh{}Omitting TARGET from Column list}
         \PY{n}{train}\PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} Replace Nulls with NaN}
         \PY{c+c1}{\PYZsh{} mark zero values as missing or NaN}
         \PY{n}{train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{p}{]} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}} \PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{NaN}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} count the number of NaN values in each column}
         \PY{k}{print}\PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
SK\_ID\_CURR                                       0
NAME\_CONTRACT\_TYPE                               0
FLAG\_OWN\_CAR                                     0
FLAG\_OWN\_REALTY                                  0
CNT\_CHILDREN                                     0
AMT\_INCOME\_TOTAL                                 0
AMT\_CREDIT                                       0
AMT\_ANNUITY                                     12
AMT\_GOODS\_PRICE                                278
REGION\_POPULATION\_RELATIVE                       0
DAYS\_BIRTH                                       0
DAYS\_EMPLOYED                                    0
DAYS\_REGISTRATION                                0
DAYS\_ID\_PUBLISH                                  0
OWN\_CAR\_AGE                                 202929
FLAG\_MOBIL                                       0
FLAG\_EMP\_PHONE                                   0
FLAG\_WORK\_PHONE                                  0
FLAG\_CONT\_MOBILE                                 0
FLAG\_PHONE                                       0
FLAG\_EMAIL                                       0
CNT\_FAM\_MEMBERS                                  2
REGION\_RATING\_CLIENT                             0
REGION\_RATING\_CLIENT\_W\_CITY                      0
HOUR\_APPR\_PROCESS\_START                          0
REG\_REGION\_NOT\_LIVE\_REGION                       0
REG\_REGION\_NOT\_WORK\_REGION                       0
LIVE\_REGION\_NOT\_WORK\_REGION                      0
REG\_CITY\_NOT\_LIVE\_CITY                           0
REG\_CITY\_NOT\_WORK\_CITY                           0
                                             {\ldots}  
ORGANIZATION\_TYPE\_Telecom                        0
ORGANIZATION\_TYPE\_Trade: type 1                  0
ORGANIZATION\_TYPE\_Trade: type 2                  0
ORGANIZATION\_TYPE\_Trade: type 3                  0
ORGANIZATION\_TYPE\_Trade: type 4                  0
ORGANIZATION\_TYPE\_Trade: type 5                  0
ORGANIZATION\_TYPE\_Trade: type 6                  0
ORGANIZATION\_TYPE\_Trade: type 7                  0
ORGANIZATION\_TYPE\_Transport: type 1              0
ORGANIZATION\_TYPE\_Transport: type 2              0
ORGANIZATION\_TYPE\_Transport: type 3              0
ORGANIZATION\_TYPE\_Transport: type 4              0
ORGANIZATION\_TYPE\_University                     0
ORGANIZATION\_TYPE\_XNA                            0
FONDKAPREMONT\_MODE\_not specified                 0
FONDKAPREMONT\_MODE\_org spec account              0
FONDKAPREMONT\_MODE\_reg oper account              0
FONDKAPREMONT\_MODE\_reg oper spec account         0
HOUSETYPE\_MODE\_block of flats                    0
HOUSETYPE\_MODE\_specific housing                  0
HOUSETYPE\_MODE\_terraced house                    0
WALLSMATERIAL\_MODE\_Block                         0
WALLSMATERIAL\_MODE\_Mixed                         0
WALLSMATERIAL\_MODE\_Monolithic                    0
WALLSMATERIAL\_MODE\_Others                        0
WALLSMATERIAL\_MODE\_Panel                         0
WALLSMATERIAL\_MODE\_Stone, brick                  0
WALLSMATERIAL\_MODE\_Wooden                        0
EMERGENCYSTATE\_MODE\_No                           0
EMERGENCYSTATE\_MODE\_Yes                          0
Length: 239, dtype: int64

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{c+c1}{\PYZsh{} print the first 20 rows of data}
         \PY{k}{print}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
    SK\_ID\_CURR  NAME\_CONTRACT\_TYPE  FLAG\_OWN\_CAR  FLAG\_OWN\_REALTY  \textbackslash{}
0       100002                   0             0                1   
1       100003                   0             0                0   
2       100004                   1             1                1   
3       100006                   0             0                1   
4       100007                   0             0                1   
5       100008                   0             0                1   
6       100009                   0             1                1   
7       100010                   0             1                1   
8       100011                   0             0                1   
9       100012                   1             0                1   
10      100014                   0             0                1   
11      100015                   0             0                1   
12      100016                   0             0                1   
13      100017                   0             1                0   
14      100018                   0             0                1   
15      100019                   0             1                1   
16      100020                   0             0                0   
17      100021                   1             0                1   
18      100022                   1             0                1   
19      100023                   0             0                1   

    CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  AMT\_GOODS\_PRICE  \textbackslash{}
0              0        202500.000    406597.5      24700.5         351000.0   
1              0        270000.000   1293502.5      35698.5        1129500.0   
2              0         67500.000    135000.0       6750.0         135000.0   
3              0        135000.000    312682.5      29686.5         297000.0   
4              0        121500.000    513000.0      21865.5         513000.0   
5              0         99000.000    490495.5      27517.5         454500.0   
6              1        171000.000   1560726.0      41301.0        1395000.0   
7              0        360000.000   1530000.0      42075.0        1530000.0   
8              0        112500.000   1019610.0      33826.5         913500.0   
9              0        135000.000    405000.0      20250.0         405000.0   
10             1        112500.000    652500.0      21177.0         652500.0   
11             0         38419.155    148365.0      10678.5         135000.0   
12             0         67500.000     80865.0       5881.5          67500.0   
13             1        225000.000    918468.0      28966.5         697500.0   
14             0        189000.000    773680.5      32778.0         679500.0   
15             0        157500.000    299772.0      20160.0         247500.0   
16             0        108000.000    509602.5      26149.5         387000.0   
17             1         81000.000    270000.0      13500.0         270000.0   
18             0        112500.000    157500.0       7875.0         157500.0   
19             1         90000.000    544491.0      17563.5         454500.0   

    REGION\_POPULATION\_RELATIVE   {\ldots}    WALLSMATERIAL\_MODE\_Block  \textbackslash{}
0                     0.018801   {\ldots}                           0   
1                     0.003541   {\ldots}                           1   
2                     0.010032   {\ldots}                           0   
3                     0.008019   {\ldots}                           0   
4                     0.028663   {\ldots}                           0   
5                     0.035792   {\ldots}                           0   
6                     0.035792   {\ldots}                           0   
7                     0.003122   {\ldots}                           0   
8                     0.018634   {\ldots}                           0   
9                     0.019689   {\ldots}                           0   
10                    0.022800   {\ldots}                           0   
11                    0.015221   {\ldots}                           0   
12                    0.031329   {\ldots}                           0   
13                    0.016612   {\ldots}                           0   
14                    0.010006   {\ldots}                           0   
15                    0.020713   {\ldots}                           0   
16                    0.018634   {\ldots}                           0   
17                    0.010966   {\ldots}                           0   
18                    0.046220   {\ldots}                           0   
19                    0.015221   {\ldots}                           0   

    WALLSMATERIAL\_MODE\_Mixed  WALLSMATERIAL\_MODE\_Monolithic  \textbackslash{}
0                          0                              0   
1                          0                              0   
2                          0                              0   
3                          0                              0   
4                          0                              0   
5                          0                              0   
6                          0                              0   
7                          0                              0   
8                          0                              0   
9                          0                              0   
10                         0                              0   
11                         0                              0   
12                         0                              0   
13                         0                              0   
14                         0                              0   
15                         0                              0   
16                         0                              0   
17                         0                              0   
18                         0                              0   
19                         0                              0   

    WALLSMATERIAL\_MODE\_Others  WALLSMATERIAL\_MODE\_Panel  \textbackslash{}
0                           0                         0   
1                           0                         0   
2                           0                         0   
3                           0                         0   
4                           0                         0   
5                           0                         0   
6                           0                         0   
7                           0                         0   
8                           0                         0   
9                           0                         0   
10                          0                         0   
11                          0                         0   
12                          0                         0   
13                          0                         1   
14                          0                         1   
15                          0                         0   
16                          0                         0   
17                          0                         0   
18                          0                         0   
19                          0                         0   

    WALLSMATERIAL\_MODE\_Stone, brick  WALLSMATERIAL\_MODE\_Wooden  \textbackslash{}
0                                 1                          0   
1                                 0                          0   
2                                 0                          0   
3                                 0                          0   
4                                 0                          0   
5                                 0                          0   
6                                 0                          0   
7                                 0                          0   
8                                 0                          0   
9                                 0                          0   
10                                0                          0   
11                                0                          0   
12                                0                          0   
13                                0                          0   
14                                0                          0   
15                                0                          0   
16                                0                          0   
17                                0                          0   
18                                1                          0   
19                                0                          0   

    EMERGENCYSTATE\_MODE\_No  EMERGENCYSTATE\_MODE\_Yes  TARGET  
0                        1                        0       1  
1                        1                        0       0  
2                        0                        0       0  
3                        0                        0       0  
4                        0                        0       0  
5                        0                        0       0  
6                        0                        0       0  
7                        0                        0       0  
8                        0                        0       0  
9                        0                        0       0  
10                       0                        0       0  
11                       0                        0       0  
12                       1                        0       0  
13                       1                        0       0  
14                       1                        0       0  
15                       0                        0       0  
16                       0                        0       0  
17                       0                        0       0  
18                       1                        0       0  
19                       0                        0       0  

[20 rows x 240 columns]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{k}{print} \PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
   SK\_ID\_CURR  NAME\_CONTRACT\_TYPE  FLAG\_OWN\_CAR  FLAG\_OWN\_REALTY  \textbackslash{}
0      100002                   0             0                1   
1      100003                   0             0                0   
2      100004                   1             1                1   
3      100006                   0             0                1   
4      100007                   0             0                1   
5      100008                   0             0                1   
6      100009                   0             1                1   
7      100010                   0             1                1   
8      100011                   0             0                1   
9      100012                   1             0                1   

   CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  AMT\_GOODS\_PRICE  \textbackslash{}
0             0          202500.0    406597.5      24700.5         351000.0   
1             0          270000.0   1293502.5      35698.5        1129500.0   
2             0           67500.0    135000.0       6750.0         135000.0   
3             0          135000.0    312682.5      29686.5         297000.0   
4             0          121500.0    513000.0      21865.5         513000.0   
5             0           99000.0    490495.5      27517.5         454500.0   
6             1          171000.0   1560726.0      41301.0        1395000.0   
7             0          360000.0   1530000.0      42075.0        1530000.0   
8             0          112500.0   1019610.0      33826.5         913500.0   
9             0          135000.0    405000.0      20250.0         405000.0   

   REGION\_POPULATION\_RELATIVE           {\ldots}             \textbackslash{}
0                    0.018801           {\ldots}              
1                    0.003541           {\ldots}              
2                    0.010032           {\ldots}              
3                    0.008019           {\ldots}              
4                    0.028663           {\ldots}              
5                    0.035792           {\ldots}              
6                    0.035792           {\ldots}              
7                    0.003122           {\ldots}              
8                    0.018634           {\ldots}              
9                    0.019689           {\ldots}              

   HOUSETYPE\_MODE\_terraced house  WALLSMATERIAL\_MODE\_Block  \textbackslash{}
0                              0                         0   
1                              0                         1   
2                              0                         0   
3                              0                         0   
4                              0                         0   
5                              0                         0   
6                              0                         0   
7                              0                         0   
8                              0                         0   
9                              0                         0   

   WALLSMATERIAL\_MODE\_Mixed  WALLSMATERIAL\_MODE\_Monolithic  \textbackslash{}
0                         0                              0   
1                         0                              0   
2                         0                              0   
3                         0                              0   
4                         0                              0   
5                         0                              0   
6                         0                              0   
7                         0                              0   
8                         0                              0   
9                         0                              0   

   WALLSMATERIAL\_MODE\_Others  WALLSMATERIAL\_MODE\_Panel  \textbackslash{}
0                          0                         0   
1                          0                         0   
2                          0                         0   
3                          0                         0   
4                          0                         0   
5                          0                         0   
6                          0                         0   
7                          0                         0   
8                          0                         0   
9                          0                         0   

   WALLSMATERIAL\_MODE\_Stone, brick  WALLSMATERIAL\_MODE\_Wooden  \textbackslash{}
0                                1                          0   
1                                0                          0   
2                                0                          0   
3                                0                          0   
4                                0                          0   
5                                0                          0   
6                                0                          0   
7                                0                          0   
8                                0                          0   
9                                0                          0   

   EMERGENCYSTATE\_MODE\_No  EMERGENCYSTATE\_MODE\_Yes  
0                       1                        0  
1                       1                        0  
2                       0                        0  
3                       0                        0  
4                       0                        0  
5                       0                        0  
6                       0                        0  
7                       0                        0  
8                       0                        0  
9                       0                        0  

[10 rows x 239 columns]

    \end{Verbatim}

    Baseline Model

    Dropping Rows with Missing Values -\textgreater{}Baselining model with
Logistic Regression

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{c+c1}{\PYZsh{} drop rows with missing values}
         \PY{n}{train}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{n}{inplace}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} summarize the number of rows and columns in the dataset}
         \PY{c+c1}{\PYZsh{}Add in the TARGET}
         \PY{n}{train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{=}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         \PY{k}{print}\PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(11351, 240)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}30}]:} \PY{n}{train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}30}]:}      SK\_ID\_CURR  NAME\_CONTRACT\_TYPE  FLAG\_OWN\_CAR  FLAG\_OWN\_REALTY  \textbackslash{}
         71       100083                   0             1                1   
         124      100145                   0             1                1   
         143      100165                   0             1                1   
         152      100179                   0             1                0   
         161      100190                   0             1                0   
         164      100193                   0             1                0   
         249      100289                   0             1                0   
         255      100295                   0             1                0   
         296      100341                   0             1                1   
         298      100343                   0             1                1   
         
              CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  AMT\_GOODS\_PRICE  \textbackslash{}
         71              0          103500.0    573628.5      24435.0         463500.0   
         124             1          202500.0    260725.5      16789.5         198000.0   
         143             0          175500.0   1293502.5      35568.0        1129500.0   
         152             0          202500.0    675000.0      53329.5         675000.0   
         161             0          162000.0    263686.5      24781.5         238500.0   
         164             0          225000.0    296280.0      15124.5         225000.0   
         249             0          202500.0    526491.0      26878.5         454500.0   
         255             1          225000.0   1019205.0      31032.0         774000.0   
         296             0           76500.0    545040.0      20677.5         450000.0   
         298             0          315000.0     90000.0       4504.5          90000.0   
         
              REGION\_POPULATION\_RELATIVE   {\ldots}    WALLSMATERIAL\_MODE\_Block  \textbackslash{}
         71                     0.009657   {\ldots}                           0   
         124                    0.018850   {\ldots}                           0   
         143                    0.018850   {\ldots}                           0   
         152                    0.031329   {\ldots}                           0   
         161                    0.022625   {\ldots}                           0   
         164                    0.020246   {\ldots}                           0   
         249                    0.022625   {\ldots}                           0   
         255                    0.072508   {\ldots}                           0   
         296                    0.031329   {\ldots}                           0   
         298                    0.022800   {\ldots}                           0   
         
              WALLSMATERIAL\_MODE\_Mixed  WALLSMATERIAL\_MODE\_Monolithic  \textbackslash{}
         71                          0                              0   
         124                         0                              0   
         143                         0                              0   
         152                         0                              1   
         161                         0                              0   
         164                         0                              0   
         249                         0                              0   
         255                         0                              0   
         296                         0                              0   
         298                         0                              0   
         
              WALLSMATERIAL\_MODE\_Others  WALLSMATERIAL\_MODE\_Panel  \textbackslash{}
         71                           0                         0   
         124                          0                         1   
         143                          0                         1   
         152                          0                         0   
         161                          0                         1   
         164                          0                         0   
         249                          0                         1   
         255                          0                         1   
         296                          0                         0   
         298                          0                         1   
         
              WALLSMATERIAL\_MODE\_Stone, brick  WALLSMATERIAL\_MODE\_Wooden  \textbackslash{}
         71                                 1                          0   
         124                                0                          0   
         143                                0                          0   
         152                                0                          0   
         161                                0                          0   
         164                                1                          0   
         249                                0                          0   
         255                                0                          0   
         296                                1                          0   
         298                                0                          0   
         
              EMERGENCYSTATE\_MODE\_No  EMERGENCYSTATE\_MODE\_Yes  TARGET  
         71                        1                        0       0  
         124                       1                        0       0  
         143                       1                        0       0  
         152                       1                        0       0  
         161                       1                        0       0  
         164                       1                        0       0  
         249                       1                        0       0  
         255                       1                        0       1  
         296                       1                        0       0  
         298                       1                        0       0  
         
         [10 rows x 240 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}31}]:} \PY{c+c1}{\PYZsh{}Deploying Logistic Regression}
         \PY{c+c1}{\PYZsh{}Splitting the dataset}
         
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{preprocessing}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{rc}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{font}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LogisticRegression}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.cross\PYZus{}validation} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
         
         \PY{n}{X} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{y} \PY{o}{=} \PY{n}{train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{metrics}
         \PY{n}{logreg} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
         \PY{n}{logreg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
/anaconda2/lib/python2.7/site-packages/sklearn/cross\_validation.py:41: DeprecationWarning:

This module was deprecated in version 0.18 in favor of the model\_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.


    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}31}]:} LogisticRegression(C=1.0, class\_weight=None, dual=False, fit\_intercept=True,
                   intercept\_scaling=1, max\_iter=100, multi\_class='ovr', n\_jobs=1,
                   penalty='l2', random\_state=None, solver='liblinear', tol=0.0001,
                   verbose=0, warm\_start=False)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}32}]:} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{logreg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy of logistic regression classifier on test set: \PYZob{}:.2f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{logreg}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy of logistic regression classifier on test set: 0.93

    \end{Verbatim}

    Another Approach: Identify Features with Missing Values -\textgreater{}
Replace with NaN -\textgreater{} Impute all Features with Missing Value
-\textgreater{} Assess Model using Logistic Regression

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}33}]:} \PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{application\PYZus{}train.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}34}]:} \PY{n}{missing\PYZus{}values} \PY{o}{=} \PY{n}{missing\PYZus{}values\PYZus{}table}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Your selected dataframe has 122 columns.
There are 67 columns that have missing values.

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}35}]:} \PY{k}{print} \PY{p}{(}\PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(48744, 239)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{c+c1}{\PYZsh{} Number of unique classes in each object column}
         \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{select\PYZus{}dtypes}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{object}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{pd}\PY{o}{.}\PY{n}{Series}\PY{o}{.}\PY{n}{nunique}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{0}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}36}]:} NAME\_CONTRACT\_TYPE             2
         CODE\_GENDER                    3
         FLAG\_OWN\_CAR                   2
         FLAG\_OWN\_REALTY                2
         NAME\_TYPE\_SUITE                7
         NAME\_INCOME\_TYPE               8
         NAME\_EDUCATION\_TYPE            5
         NAME\_FAMILY\_STATUS             6
         NAME\_HOUSING\_TYPE              6
         OCCUPATION\_TYPE               18
         WEEKDAY\_APPR\_PROCESS\_START     7
         ORGANIZATION\_TYPE             58
         FONDKAPREMONT\_MODE             4
         HOUSETYPE\_MODE                 3
         WALLSMATERIAL\_MODE             7
         EMERGENCYSTATE\_MODE            2
         dtype: int64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}37}]:} \PY{k}{print} \PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{unique}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[1, 0]

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}38}]:} \PY{c+c1}{\PYZsh{} from sklearn.preprocessing import LabelEncoder}
         \PY{c+c1}{\PYZsh{} \PYZsh{} Create a label encoder object}
         \PY{c+c1}{\PYZsh{} le = LabelEncoder()}
         \PY{c+c1}{\PYZsh{} le\PYZus{}count = 0}
         
         \PY{c+c1}{\PYZsh{} \PYZsh{} Iterate through the columns}
         \PY{c+c1}{\PYZsh{} for col in df\PYZus{}train:}
         \PY{c+c1}{\PYZsh{}     if df\PYZus{}train[col].dtype == \PYZsq{}object\PYZsq{}:}
         \PY{c+c1}{\PYZsh{}         \PYZsh{} If 2 or fewer unique categories}
         \PY{c+c1}{\PYZsh{}         if len(list(df\PYZus{}train[col].unique())) \PYZlt{}= 2:}
         \PY{c+c1}{\PYZsh{}             \PYZsh{} Train on the training data}
         \PY{c+c1}{\PYZsh{}             le.fit(df\PYZus{}train[col])}
         \PY{c+c1}{\PYZsh{}             \PYZsh{} Transform both training and testing data}
         \PY{c+c1}{\PYZsh{}             df\PYZus{}train[col] = le.transform(df\PYZus{}train[col])}
         \PY{c+c1}{\PYZsh{}             df\PYZus{}test[col] = le.transform(df\PYZus{}test[col])}
                     
         \PY{c+c1}{\PYZsh{}             \PYZsh{} Keep track of how many columns were label encoded}
         \PY{c+c1}{\PYZsh{}             le\PYZus{}count += 1}
                     
         \PY{c+c1}{\PYZsh{} print(\PYZsq{}\PYZpc{}d columns were label encoded.\PYZsq{} \PYZpc{} le\PYZus{}count)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{n}{df\PYZus{}train} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{get\PYZus{}dummies}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Training Features shape: ', (307511, 246))

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}40}]:} \PY{n}{train\PYZus{}labels} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} Align the training and testing data, keep only columns present in both dataframes}
         \PY{n}{df\PYZus{}train}\PY{p}{,} \PY{n}{df\PYZus{}test} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{align}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{,} \PY{n}{join} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{inner}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{axis} \PY{o}{=} \PY{l+m+mi}{1}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Add the target back in}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{train\PYZus{}labels}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Testing Features shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Training Features shape: ', (307511, 237))
('Testing Features shape: ', (48744, 236))

    \end{Verbatim}

    Missing Values Strategy \# 2 - Identify Features with Missing Values
-\textgreater{} Replace with NaN -\textgreater{} Impute all Features
with Missing Value -\textgreater{} Assess Model using Logistic
Regression

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}41}]:} \PY{c+c1}{\PYZsh{} Missing values statistics}
         \PY{n}{missing\PYZus{}values} \PY{o}{=} \PY{n}{missing\PYZus{}values\PYZus{}table}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{n}{missing\PYZus{}values}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Your selected dataframe has 237 columns.
There are 61 columns that have missing values.

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}41}]:}                           Missing Values  \% of Total Values
         COMMONAREA\_MODE                   214865               69.9
         COMMONAREA\_MEDI                   214865               69.9
         COMMONAREA\_AVG                    214865               69.9
         NONLIVINGAPARTMENTS\_MODE          213514               69.4
         NONLIVINGAPARTMENTS\_AVG           213514               69.4
         NONLIVINGAPARTMENTS\_MEDI          213514               69.4
         LIVINGAPARTMENTS\_MEDI             210199               68.4
         LIVINGAPARTMENTS\_AVG              210199               68.4
         LIVINGAPARTMENTS\_MODE             210199               68.4
         FLOORSMIN\_MEDI                    208642               67.8
         FLOORSMIN\_MODE                    208642               67.8
         FLOORSMIN\_AVG                     208642               67.8
         YEARS\_BUILD\_AVG                   204488               66.5
         YEARS\_BUILD\_MODE                  204488               66.5
         YEARS\_BUILD\_MEDI                  204488               66.5
         OWN\_CAR\_AGE                       202929               66.0
         LANDAREA\_MEDI                     182590               59.4
         LANDAREA\_MODE                     182590               59.4
         LANDAREA\_AVG                      182590               59.4
         BASEMENTAREA\_MODE                 179943               58.5
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}42}]:} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}42}]:}    SK\_ID\_CURR  CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  \textbackslash{}
         0      100002             0          202500.0    406597.5      24700.5   
         1      100003             0          270000.0   1293502.5      35698.5   
         2      100004             0           67500.0    135000.0       6750.0   
         3      100006             0          135000.0    312682.5      29686.5   
         4      100007             0          121500.0    513000.0      21865.5   
         5      100008             0           99000.0    490495.5      27517.5   
         6      100009             1          171000.0   1560726.0      41301.0   
         7      100010             0          360000.0   1530000.0      42075.0   
         8      100011             0          112500.0   1019610.0      33826.5   
         9      100012             0          135000.0    405000.0      20250.0   
         
            AMT\_GOODS\_PRICE  REGION\_POPULATION\_RELATIVE  DAYS\_BIRTH  DAYS\_EMPLOYED  \textbackslash{}
         0         351000.0                    0.018801       -9461           -637   
         1        1129500.0                    0.003541      -16765          -1188   
         2         135000.0                    0.010032      -19046           -225   
         3         297000.0                    0.008019      -19005          -3039   
         4         513000.0                    0.028663      -19932          -3038   
         5         454500.0                    0.035792      -16941          -1588   
         6        1395000.0                    0.035792      -13778          -3130   
         7        1530000.0                    0.003122      -18850           -449   
         8         913500.0                    0.018634      -20099         365243   
         9         405000.0                    0.019689      -14469          -2019   
         
            DAYS\_REGISTRATION   {\ldots}    WALLSMATERIAL\_MODE\_Block  \textbackslash{}
         0            -3648.0   {\ldots}                           0   
         1            -1186.0   {\ldots}                           1   
         2            -4260.0   {\ldots}                           0   
         3            -9833.0   {\ldots}                           0   
         4            -4311.0   {\ldots}                           0   
         5            -4970.0   {\ldots}                           0   
         6            -1213.0   {\ldots}                           0   
         7            -4597.0   {\ldots}                           0   
         8            -7427.0   {\ldots}                           0   
         9           -14437.0   {\ldots}                           0   
         
            WALLSMATERIAL\_MODE\_Mixed  WALLSMATERIAL\_MODE\_Monolithic  \textbackslash{}
         0                         0                              0   
         1                         0                              0   
         2                         0                              0   
         3                         0                              0   
         4                         0                              0   
         5                         0                              0   
         6                         0                              0   
         7                         0                              0   
         8                         0                              0   
         9                         0                              0   
         
            WALLSMATERIAL\_MODE\_Others  WALLSMATERIAL\_MODE\_Panel  \textbackslash{}
         0                          0                         0   
         1                          0                         0   
         2                          0                         0   
         3                          0                         0   
         4                          0                         0   
         5                          0                         0   
         6                          0                         0   
         7                          0                         0   
         8                          0                         0   
         9                          0                         0   
         
            WALLSMATERIAL\_MODE\_Stone, brick  WALLSMATERIAL\_MODE\_Wooden  \textbackslash{}
         0                                1                          0   
         1                                0                          0   
         2                                0                          0   
         3                                0                          0   
         4                                0                          0   
         5                                0                          0   
         6                                0                          0   
         7                                0                          0   
         8                                0                          0   
         9                                0                          0   
         
            EMERGENCYSTATE\_MODE\_No  EMERGENCYSTATE\_MODE\_Yes  TARGET  
         0                       1                        0       1  
         1                       1                        0       0  
         2                       0                        0       0  
         3                       0                        0       0  
         4                       0                        0       0  
         5                       0                        0       0  
         6                       0                        0       0  
         7                       0                        0       0  
         8                       0                        0       0  
         9                       0                        0       0  
         
         [10 rows x 237 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}43}]:} \PY{c+c1}{\PYZsh{} Replace Nulls with NaN}
         \PY{c+c1}{\PYZsh{} mark zero values as missing or NaN}
         
         \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{NaN}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} count the number of NaN values in each column}
         \PY{k}{print}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} fill missing values with mean column values}
         \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{fillna}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n}{inplace}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} count the number of NaN values in each column}
         \PY{k}{print}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{isnull}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
SK\_ID\_CURR                                       0
CNT\_CHILDREN                                     0
AMT\_INCOME\_TOTAL                                 0
AMT\_CREDIT                                       0
AMT\_ANNUITY                                     12
AMT\_GOODS\_PRICE                                278
REGION\_POPULATION\_RELATIVE                       0
DAYS\_BIRTH                                       0
DAYS\_EMPLOYED                                    0
DAYS\_REGISTRATION                                0
DAYS\_ID\_PUBLISH                                  0
OWN\_CAR\_AGE                                 202929
FLAG\_MOBIL                                       0
FLAG\_EMP\_PHONE                                   0
FLAG\_WORK\_PHONE                                  0
FLAG\_CONT\_MOBILE                                 0
FLAG\_PHONE                                       0
FLAG\_EMAIL                                       0
CNT\_FAM\_MEMBERS                                  2
REGION\_RATING\_CLIENT                             0
REGION\_RATING\_CLIENT\_W\_CITY                      0
HOUR\_APPR\_PROCESS\_START                          0
REG\_REGION\_NOT\_LIVE\_REGION                       0
REG\_REGION\_NOT\_WORK\_REGION                       0
LIVE\_REGION\_NOT\_WORK\_REGION                      0
REG\_CITY\_NOT\_LIVE\_CITY                           0
REG\_CITY\_NOT\_WORK\_CITY                           0
LIVE\_CITY\_NOT\_WORK\_CITY                          0
EXT\_SOURCE\_1                                173378
EXT\_SOURCE\_2                                   660
                                             {\ldots}  
ORGANIZATION\_TYPE\_Trade: type 1                  0
ORGANIZATION\_TYPE\_Trade: type 2                  0
ORGANIZATION\_TYPE\_Trade: type 3                  0
ORGANIZATION\_TYPE\_Trade: type 4                  0
ORGANIZATION\_TYPE\_Trade: type 5                  0
ORGANIZATION\_TYPE\_Trade: type 6                  0
ORGANIZATION\_TYPE\_Trade: type 7                  0
ORGANIZATION\_TYPE\_Transport: type 1              0
ORGANIZATION\_TYPE\_Transport: type 2              0
ORGANIZATION\_TYPE\_Transport: type 3              0
ORGANIZATION\_TYPE\_Transport: type 4              0
ORGANIZATION\_TYPE\_University                     0
ORGANIZATION\_TYPE\_XNA                            0
FONDKAPREMONT\_MODE\_not specified                 0
FONDKAPREMONT\_MODE\_org spec account              0
FONDKAPREMONT\_MODE\_reg oper account              0
FONDKAPREMONT\_MODE\_reg oper spec account         0
HOUSETYPE\_MODE\_block of flats                    0
HOUSETYPE\_MODE\_specific housing                  0
HOUSETYPE\_MODE\_terraced house                    0
WALLSMATERIAL\_MODE\_Block                         0
WALLSMATERIAL\_MODE\_Mixed                         0
WALLSMATERIAL\_MODE\_Monolithic                    0
WALLSMATERIAL\_MODE\_Others                        0
WALLSMATERIAL\_MODE\_Panel                         0
WALLSMATERIAL\_MODE\_Stone, brick                  0
WALLSMATERIAL\_MODE\_Wooden                        0
EMERGENCYSTATE\_MODE\_No                           0
EMERGENCYSTATE\_MODE\_Yes                          0
TARGET                                           0
Length: 237, dtype: int64
SK\_ID\_CURR                                  0
CNT\_CHILDREN                                0
AMT\_INCOME\_TOTAL                            0
AMT\_CREDIT                                  0
AMT\_ANNUITY                                 0
AMT\_GOODS\_PRICE                             0
REGION\_POPULATION\_RELATIVE                  0
DAYS\_BIRTH                                  0
DAYS\_EMPLOYED                               0
DAYS\_REGISTRATION                           0
DAYS\_ID\_PUBLISH                             0
OWN\_CAR\_AGE                                 0
FLAG\_MOBIL                                  0
FLAG\_EMP\_PHONE                              0
FLAG\_WORK\_PHONE                             0
FLAG\_CONT\_MOBILE                            0
FLAG\_PHONE                                  0
FLAG\_EMAIL                                  0
CNT\_FAM\_MEMBERS                             0
REGION\_RATING\_CLIENT                        0
REGION\_RATING\_CLIENT\_W\_CITY                 0
HOUR\_APPR\_PROCESS\_START                     0
REG\_REGION\_NOT\_LIVE\_REGION                  0
REG\_REGION\_NOT\_WORK\_REGION                  0
LIVE\_REGION\_NOT\_WORK\_REGION                 0
REG\_CITY\_NOT\_LIVE\_CITY                      0
REG\_CITY\_NOT\_WORK\_CITY                      0
LIVE\_CITY\_NOT\_WORK\_CITY                     0
EXT\_SOURCE\_1                                0
EXT\_SOURCE\_2                                0
                                           ..
ORGANIZATION\_TYPE\_Trade: type 1             0
ORGANIZATION\_TYPE\_Trade: type 2             0
ORGANIZATION\_TYPE\_Trade: type 3             0
ORGANIZATION\_TYPE\_Trade: type 4             0
ORGANIZATION\_TYPE\_Trade: type 5             0
ORGANIZATION\_TYPE\_Trade: type 6             0
ORGANIZATION\_TYPE\_Trade: type 7             0
ORGANIZATION\_TYPE\_Transport: type 1         0
ORGANIZATION\_TYPE\_Transport: type 2         0
ORGANIZATION\_TYPE\_Transport: type 3         0
ORGANIZATION\_TYPE\_Transport: type 4         0
ORGANIZATION\_TYPE\_University                0
ORGANIZATION\_TYPE\_XNA                       0
FONDKAPREMONT\_MODE\_not specified            0
FONDKAPREMONT\_MODE\_org spec account         0
FONDKAPREMONT\_MODE\_reg oper account         0
FONDKAPREMONT\_MODE\_reg oper spec account    0
HOUSETYPE\_MODE\_block of flats               0
HOUSETYPE\_MODE\_specific housing             0
HOUSETYPE\_MODE\_terraced house               0
WALLSMATERIAL\_MODE\_Block                    0
WALLSMATERIAL\_MODE\_Mixed                    0
WALLSMATERIAL\_MODE\_Monolithic               0
WALLSMATERIAL\_MODE\_Others                   0
WALLSMATERIAL\_MODE\_Panel                    0
WALLSMATERIAL\_MODE\_Stone, brick             0
WALLSMATERIAL\_MODE\_Wooden                   0
EMERGENCYSTATE\_MODE\_No                      0
EMERGENCYSTATE\_MODE\_Yes                     0
TARGET                                      0
Length: 237, dtype: int64

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}44}]:}    SK\_ID\_CURR  CNT\_CHILDREN  AMT\_INCOME\_TOTAL  AMT\_CREDIT  AMT\_ANNUITY  \textbackslash{}
         0      100002             0          202500.0    406597.5      24700.5   
         1      100003             0          270000.0   1293502.5      35698.5   
         2      100004             0           67500.0    135000.0       6750.0   
         3      100006             0          135000.0    312682.5      29686.5   
         4      100007             0          121500.0    513000.0      21865.5   
         5      100008             0           99000.0    490495.5      27517.5   
         6      100009             1          171000.0   1560726.0      41301.0   
         7      100010             0          360000.0   1530000.0      42075.0   
         8      100011             0          112500.0   1019610.0      33826.5   
         9      100012             0          135000.0    405000.0      20250.0   
         
            AMT\_GOODS\_PRICE  REGION\_POPULATION\_RELATIVE  DAYS\_BIRTH  DAYS\_EMPLOYED  \textbackslash{}
         0         351000.0                    0.018801       -9461           -637   
         1        1129500.0                    0.003541      -16765          -1188   
         2         135000.0                    0.010032      -19046           -225   
         3         297000.0                    0.008019      -19005          -3039   
         4         513000.0                    0.028663      -19932          -3038   
         5         454500.0                    0.035792      -16941          -1588   
         6        1395000.0                    0.035792      -13778          -3130   
         7        1530000.0                    0.003122      -18850           -449   
         8         913500.0                    0.018634      -20099         365243   
         9         405000.0                    0.019689      -14469          -2019   
         
            DAYS\_REGISTRATION   {\ldots}    WALLSMATERIAL\_MODE\_Block  \textbackslash{}
         0            -3648.0   {\ldots}                           0   
         1            -1186.0   {\ldots}                           1   
         2            -4260.0   {\ldots}                           0   
         3            -9833.0   {\ldots}                           0   
         4            -4311.0   {\ldots}                           0   
         5            -4970.0   {\ldots}                           0   
         6            -1213.0   {\ldots}                           0   
         7            -4597.0   {\ldots}                           0   
         8            -7427.0   {\ldots}                           0   
         9           -14437.0   {\ldots}                           0   
         
            WALLSMATERIAL\_MODE\_Mixed  WALLSMATERIAL\_MODE\_Monolithic  \textbackslash{}
         0                         0                              0   
         1                         0                              0   
         2                         0                              0   
         3                         0                              0   
         4                         0                              0   
         5                         0                              0   
         6                         0                              0   
         7                         0                              0   
         8                         0                              0   
         9                         0                              0   
         
            WALLSMATERIAL\_MODE\_Others  WALLSMATERIAL\_MODE\_Panel  \textbackslash{}
         0                          0                         0   
         1                          0                         0   
         2                          0                         0   
         3                          0                         0   
         4                          0                         0   
         5                          0                         0   
         6                          0                         0   
         7                          0                         0   
         8                          0                         0   
         9                          0                         0   
         
            WALLSMATERIAL\_MODE\_Stone, brick  WALLSMATERIAL\_MODE\_Wooden  \textbackslash{}
         0                                1                          0   
         1                                0                          0   
         2                                0                          0   
         3                                0                          0   
         4                                0                          0   
         5                                0                          0   
         6                                0                          0   
         7                                0                          0   
         8                                0                          0   
         9                                0                          0   
         
            EMERGENCYSTATE\_MODE\_No  EMERGENCYSTATE\_MODE\_Yes  TARGET  
         0                       1                        0       1  
         1                       1                        0       0  
         2                       0                        0       0  
         3                       0                        0       0  
         4                       0                        0       0  
         5                       0                        0       0  
         6                       0                        0       0  
         7                       0                        0       0  
         8                       0                        0       0  
         9                       0                        0       0  
         
         [10 rows x 237 columns]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}45}]:} \PY{c+c1}{\PYZsh{} \PYZsh{}Impute all features with Missing values}
         
         \PY{c+c1}{\PYZsh{} from sklearn.preprocessing import Imputer}
         \PY{c+c1}{\PYZsh{} \PYZsh{} fill missing values with mean column values}
         \PY{c+c1}{\PYZsh{} values = df\PYZus{}train.values}
         \PY{c+c1}{\PYZsh{} imputer = Imputer()}
         \PY{c+c1}{\PYZsh{} transformed\PYZus{}values = imputer.fit\PYZus{}transform(values)}
         \PY{c+c1}{\PYZsh{} \PYZsh{} count the number of NaN values in each column}
         \PY{c+c1}{\PYZsh{} print(np.isnan(transformed\PYZus{}values).sum())}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}46}]:} \PY{c+c1}{\PYZsh{}df\PYZus{}train.head(df\PYZus{}train.iloc[:,\PYZhy{}1]==0)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}47}]:} \PY{c+c1}{\PYZsh{}LDA}
         
         \PY{k+kn}{from} \PY{n+nn}{sklearn.preprocessing} \PY{k+kn}{import} \PY{n}{Imputer}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.discriminant\PYZus{}analysis} \PY{k+kn}{import} \PY{n}{LinearDiscriminantAnalysis}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{KFold}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.model\PYZus{}selection} \PY{k+kn}{import} \PY{n}{cross\PYZus{}val\PYZus{}score}
         
         \PY{c+c1}{\PYZsh{} split dataset into inputs and outputs}
         \PY{c+c1}{\PYZsh{}values = dataset.values}
         \PY{n}{X} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{y} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{c+c1}{\PYZsh{} fill missing values with mean column values}
         \PY{n}{imputer} \PY{o}{=} \PY{n}{Imputer}\PY{p}{(}\PY{p}{)}
         \PY{n}{transformed\PYZus{}X} \PY{o}{=} \PY{n}{imputer}\PY{o}{.}\PY{n}{fit\PYZus{}transform}\PY{p}{(}\PY{n}{X}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} evaluate an LDA model on the dataset using k\PYZhy{}fold cross validation}
         \PY{n}{model} \PY{o}{=} \PY{n}{LinearDiscriminantAnalysis}\PY{p}{(}\PY{p}{)}
         \PY{n}{kfold} \PY{o}{=} \PY{n}{KFold}\PY{p}{(}\PY{n}{n\PYZus{}splits}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{7}\PY{p}{)}
         \PY{n}{result} \PY{o}{=} \PY{n}{cross\PYZus{}val\PYZus{}score}\PY{p}{(}\PY{n}{model}\PY{p}{,} \PY{n}{transformed\PYZus{}X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{cv}\PY{o}{=}\PY{n}{kfold}\PY{p}{,} \PY{n}{scoring}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{n}{result}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
0.9189199767969486

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}48}]:} \PY{c+c1}{\PYZsh{} Deploying Logistic Regression}
         \PY{c+c1}{\PYZsh{}Splitting the dataset}
         \PY{c+c1}{\PYZsh{}Keep the following 6 features (variables) which are important}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{preprocessing}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt} 
         \PY{n}{plt}\PY{o}{.}\PY{n}{rc}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{font}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{14}\PY{p}{)}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LogisticRegression}
         \PY{k+kn}{from} \PY{n+nn}{sklearn.cross\PYZus{}validation} \PY{k+kn}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
         
         \PY{n}{X} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{y} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}test} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{test\PYZus{}size}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{random\PYZus{}state}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{k+kn}{from} \PY{n+nn}{sklearn} \PY{k+kn}{import} \PY{n}{metrics}
         \PY{n}{logreg} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{p}{)}
         \PY{n}{logreg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}48}]:} LogisticRegression(C=1.0, class\_weight=None, dual=False, fit\_intercept=True,
                   intercept\_scaling=1, max\_iter=100, multi\_class='ovr', n\_jobs=1,
                   penalty='l2', random\_state=None, solver='liblinear', tol=0.0001,
                   verbose=0, warm\_start=False)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}49}]:} \PY{n}{y\PYZus{}pred} \PY{o}{=} \PY{n}{logreg}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Accuracy of logistic regression classifier on test set: \PYZob{}:.2f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{logreg}\PY{o}{.}\PY{n}{score}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{,} \PY{n}{y\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Accuracy of logistic regression classifier on test set: 0.92

    \end{Verbatim}

    Baseline with Feature Scaling

     To get a baseline, we will use all of the features after encoding the
categorical variables. We will preprocess the data by filling in the
missing values (imputation) and normalizing the range of the features
(feature scaling). The following code performs both of these
preprocessing steps.

    To get a baseline, we will use all of the features after encoding the
categorical variables. We will preprocess the data by filling in the
missing values (imputation) and normalizing the range of the features
(feature scaling). The following code performs both of these
preprocessing steps.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}50}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.preprocessing} \PY{k+kn}{import} \PY{n}{MinMaxScaler}\PY{p}{,} \PY{n}{Imputer}
         
         \PY{c+c1}{\PYZsh{} Drop the target from the training data}
         \PY{k}{if} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}} \PY{o+ow}{in} \PY{n}{df\PYZus{}train}\PY{p}{:}
             \PY{n}{train} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{k}{else}\PY{p}{:}
             \PY{n}{train} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
             
         \PY{c+c1}{\PYZsh{} Feature names}
         \PY{n}{features} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n}{train}\PY{o}{.}\PY{n}{columns}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Copy of the testing data}
         \PY{n}{test} \PY{o}{=} \PY{n}{df\PYZus{}test}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Median imputation of missing values}
         \PY{n}{imputer} \PY{o}{=} \PY{n}{Imputer}\PY{p}{(}\PY{n}{strategy} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{median}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Scale each feature to 0\PYZhy{}1}
         \PY{n}{scaler} \PY{o}{=} \PY{n}{MinMaxScaler}\PY{p}{(}\PY{n}{feature\PYZus{}range} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Fit on the training data}
         \PY{n}{imputer}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Transform both training and testing data}
         \PY{n}{train} \PY{o}{=} \PY{n}{imputer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{train}\PY{p}{)}
         \PY{n}{test} \PY{o}{=} \PY{n}{imputer}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Repeat with the scaler}
         \PY{n}{scaler}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train}\PY{p}{)}
         \PY{n}{train} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{train}\PY{p}{)}
         \PY{n}{test} \PY{o}{=} \PY{n}{scaler}\PY{o}{.}\PY{n}{transform}\PY{p}{(}\PY{n}{test}\PY{p}{)}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Training data shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{train}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Testing data shape: }\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{test}\PY{o}{.}\PY{n}{shape}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Training data shape: ', (307511, 236))
('Testing data shape: ', (48744, 236))

    \end{Verbatim}

    We will use LogisticRegressionfrom Scikit-Learn for our first model. The
only change we will make from the default model settings is to lower the
regularization parameter, C, which controls the amount of overfitting (a
lower value should decrease overfitting). This will get us slightly
better results than the default LogisticRegression, but it still will
set a low bar for any future models.

Here we use the familiar Scikit-Learn modeling syntax: we first create
the model, then we train the model using .fit and then we make
predictions on the testing data using .predict\_proba (remember that we
want probabilities and not a 0 or 1).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}51}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn.linear\PYZus{}model} \PY{k+kn}{import} \PY{n}{LogisticRegression}
         
         \PY{c+c1}{\PYZsh{} Make the model with the specified regularization parameter}
         \PY{n}{log\PYZus{}reg} \PY{o}{=} \PY{n}{LogisticRegression}\PY{p}{(}\PY{n}{C} \PY{o}{=} \PY{l+m+mf}{0.0001}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Train on the training data}
         \PY{n}{log\PYZus{}reg}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{train}\PY{p}{,} \PY{n}{train\PYZus{}labels}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}51}]:} LogisticRegression(C=0.0001, class\_weight=None, dual=False,
                   fit\_intercept=True, intercept\_scaling=1, max\_iter=100,
                   multi\_class='ovr', n\_jobs=1, penalty='l2', random\_state=None,
                   solver='liblinear', tol=0.0001, verbose=0, warm\_start=False)
\end{Verbatim}
            
    Now that the model has been trained, we can use it to make predictions.
We want to predict the probabilities of not paying a loan, so we use the
model predict.proba method. This returns an m x 2 array where m is the
number of observations. The first column is the probability of the
target being 0 and the second column is the probability of the target
being 1 (so for a single row, the two columns must sum to 1). We want
the probability the loan is not repaid, so we will select the second
column.

The following code makes the predictions and selects the correct column.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}52}]:} \PY{c+c1}{\PYZsh{} Make predictions}
         \PY{c+c1}{\PYZsh{} Make sure to select the last column only}
         \PY{n}{log\PYZus{}reg\PYZus{}pred} \PY{o}{=} \PY{n}{log\PYZus{}reg}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{test}\PY{p}{)}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
\end{Verbatim}


    The predictions must be in the format shown in the
sample\_submission.csv file, where there are only two columns:
SK\_ID\_CURR and TARGET. We will create a dataframe in this format from
the test set and the predictions called submit.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}53}]:} \PY{c+c1}{\PYZsh{} Submission dataframe}
         \PY{n}{submit} \PY{o}{=} \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{SK\PYZus{}ID\PYZus{}CURR}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
         \PY{n}{submit}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{log\PYZus{}reg\PYZus{}pred}
         
         \PY{n}{submit}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}53}]:}    SK\_ID\_CURR    TARGET
         0      100001  0.065186
         1      100005  0.123897
         2      100013  0.088657
         3      100028  0.058601
         4      100038  0.130668
\end{Verbatim}
            
    The predictions represent a probability between 0 and 1 that the loan
will not be repaid. If we were using these predictions to classify
applicants, we could set a probability threshold for determining that a
loan is risky.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}54}]:} \PY{c+c1}{\PYZsh{} Save the submission to a csv file}
         \PY{n}{submit}\PY{o}{.}\PY{n}{to\PYZus{}csv}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log\PYZus{}reg\PYZus{}baseline.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{index} \PY{o}{=} \PY{n+nb+bp}{False}\PY{p}{)}
\end{Verbatim}


    The submission has now been saved to the virtual environment in which
our notebook is running. This runs the entire notebook and then lets us
download any files that are created during the run.

Once we run the notebook, the files created are available in the
Versions tab under the Output sub-tab.

     This is Data Wrangling complete with Baseline Model determined with
Logistic Regresssion; next we may proceed with EDA \& Inferential
Statistics,

    Inferential Statistics

    Function to Explore Numeric Data

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}55}]:} \PY{k}{def} \PY{n+nf}{numeric}\PY{p}{(}\PY{n}{col}\PY{p}{)}\PY{p}{:}
             \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{)}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Distribution of }\PY{l+s+s2}{\PYZdq{}}\PY{o}{+}\PY{n}{col}\PY{p}{)}
             \PY{n}{ax} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{distplot}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}56}]:} \PY{n}{numeric}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AMT\PYZus{}CREDIT}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_97_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}57}]:} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AMT\PYZus{}INCOME\PYZus{}TOTAL}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{dtype}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}57}]:} dtype('float64')
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}58}]:} \PY{n}{numeric}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AMT\PYZus{}INCOME\PYZus{}TOTAL}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_99_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}59}]:} \PY{n}{numeric}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AMT\PYZus{}ANNUITY}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_100_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}60}]:} \PY{n}{numeric}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{AMT\PYZus{}GOODS\PYZus{}PRICE}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_101_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}61}]:} \PY{n}{anom} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{365243}\PY{p}{]}
         \PY{n}{non\PYZus{}anom} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{!=} \PY{l+m+mi}{365243}\PY{p}{]}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The non\PYZhy{}anomalies default on }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+si}{\PYZpc{}\PYZpc{}}\PY{l+s+s1}{ of loans}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{100} \PY{o}{*} \PY{n}{non\PYZus{}anom}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{The anomalies default on }\PY{l+s+si}{\PYZpc{}0.2f}\PY{l+s+si}{\PYZpc{}\PYZpc{}}\PY{l+s+s1}{ of loans}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{l+m+mi}{100} \PY{o}{*} \PY{n}{anom}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{There are }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{ anomalous days of employment}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n+nb}{len}\PY{p}{(}\PY{n}{anom}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
The non-anomalies default on 8.66\% of loans
The anomalies default on 5.40\% of loans
There are 55374 anomalous days of employment

    \end{Verbatim}

    Well that is extremely interesting! It turns out that the anomalies have
a lower rate of default. Handling the anomalies depends on the exact
situation, with no set rules. One of the safest approaches is just to
set the anomalies to a missing value and then have them filled in (using
Imputation) before machine learning. In this case, since all the
anomalies have the exact same value, we want to fill them in with the
same value in case all of these loans share something in common. The
anomalous values seem to have some importance, so we want to tell the
machine learning model if we did in fact fill in these values. As a
solution, we will fill in the anomalous values with not a number
(np.nan) and then create a new boolean column indicating whether or not
the value was anomalous.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}62}]:} \PY{c+c1}{\PYZsh{} Create an anomalous flag column}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED\PYZus{}ANOM}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{365243}
         
         \PY{c+c1}{\PYZsh{} Replace the anomalous values with nan}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+m+mi}{365243}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{nan}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{inplace} \PY{o}{=} \PY{n+nb+bp}{True}\PY{p}{)}
         
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{title} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days Employment Histogram}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days Employment}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_104_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The distribution looks to be much more in line with what we would
expect, and we also have created a new column to tell the model that
these values were originally anomalous (becuase we will have to fill in
the nans with some value, probably the median of the column). The other
columns with DAYS in the dataframe look to be about what we expect with
no obvious outliers. As an extremely important note, anything we do to
the training data we also have to do to the testing data. Let's make
sure to create the new column and fill in the existing column with
np.nan in the testing data. The distribution looks to be much more in
line with what we would expect, and we also have created a new column to
tell the model that these values were originally anomalous (becuase we
will have to fill in the nans with some value, probably the median of
the column). The other columns with DAYS in the dataframe look to be
about what we expect with no obvious outliers. As an extremely important
note, anything we do to the training data we also have to do to the
testing data. Let's make sure to create the new column and fill in the
existing column with np.nan in the testing data.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}63}]:} \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED\PYZus{}ANOM}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{365243}
         \PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{replace}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+m+mi}{365243}\PY{p}{:} \PY{n}{np}\PY{o}{.}\PY{n}{nan}\PY{p}{\PYZcb{}}\PY{p}{,} \PY{n}{inplace} \PY{o}{=} \PY{n+nb+bp}{True}\PY{p}{)}
         
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{There are }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{ anomalies in the test data out of }\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{ entries}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{DAYS\PYZus{}EMPLOYED\PYZus{}ANOM}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sum}\PY{p}{(}\PY{p}{)}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{df\PYZus{}test}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
There are 9274 anomalies in the test data out of 48744 entries

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}117}]:} \PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{/}\PY{l+m+mf}{365.0}\PY{p}{)}\PY{o}{.}\PY{n}{describe}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}117}]:} count    307511.000000
          mean         43.936973
          std          11.956133
          min          20.517808
          25\%          34.008219
          50\%          43.150685
          75\%          53.923288
          max          69.120548
          Name: DAYS\_BIRTH, dtype: float64
\end{Verbatim}
            
    Dataset Prep for Another set of EDA

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}64}]:} \PY{k+kn}{from} \PY{n+nn}{plotly.offline} \PY{k+kn}{import} \PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{,} \PY{n}{iplot}
         \PY{k+kn}{from} \PY{n+nn}{wordcloud} \PY{k+kn}{import} \PY{n}{WordCloud}
         \PY{k+kn}{import} \PY{n+nn}{plotly.graph\PYZus{}objs} \PY{k+kn}{as} \PY{n+nn}{go}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib.pyplot} \PY{k+kn}{as} \PY{n+nn}{plt}
         \PY{k+kn}{import} \PY{n+nn}{plotly.plotly} \PY{k+kn}{as} \PY{n+nn}{py}
         \PY{k+kn}{from} \PY{n+nn}{plotly} \PY{k+kn}{import} \PY{n}{tools}
         \PY{k+kn}{from} \PY{n+nn}{datetime} \PY{k+kn}{import} \PY{n}{date}
         \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k+kn}{as} \PY{n+nn}{pd}
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k+kn}{as} \PY{n+nn}{np} 
         \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k+kn}{as} \PY{n+nn}{sns}
         \PY{k+kn}{import} \PY{n+nn}{random} 
         \PY{k+kn}{import} \PY{n+nn}{warnings}
         \PY{n}{warnings}\PY{o}{.}\PY{n}{filterwarnings}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{ignore}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}
         \PY{n}{init\PYZus{}notebook\PYZus{}mode}\PY{p}{(}\PY{n}{connected}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
         
         \PY{n}{path} \PY{o}{=} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{../input/}\PY{l+s+s2}{\PYZdq{}}
         
         \PY{k}{def} \PY{n+nf}{bar\PYZus{}hor}\PY{p}{(}\PY{n}{df}\PY{p}{,} \PY{n}{col}\PY{p}{,} \PY{n}{title}\PY{p}{,} \PY{n}{color}\PY{p}{,} \PY{n}{w}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{h}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{lm}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{limit}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{return\PYZus{}trace}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{,} \PY{n}{rev}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{,} \PY{n}{xlb} \PY{o}{=} \PY{n+nb+bp}{False}\PY{p}{)}\PY{p}{:}
             \PY{n}{cnt\PYZus{}srs} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
             \PY{n}{yy} \PY{o}{=} \PY{n}{cnt\PYZus{}srs}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{limit}\PY{p}{)}\PY{o}{.}\PY{n}{index}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} 
             \PY{n}{xx} \PY{o}{=} \PY{n}{cnt\PYZus{}srs}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{n}{limit}\PY{p}{)}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} 
             \PY{k}{if} \PY{n}{rev}\PY{p}{:}
                 \PY{n}{yy} \PY{o}{=} \PY{n}{cnt\PYZus{}srs}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{n}{limit}\PY{p}{)}\PY{o}{.}\PY{n}{index}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} 
                 \PY{n}{xx} \PY{o}{=} \PY{n}{cnt\PYZus{}srs}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{n}{limit}\PY{p}{)}\PY{o}{.}\PY{n}{values}\PY{p}{[}\PY{p}{:}\PY{p}{:}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]} 
             \PY{k}{if} \PY{n}{xlb}\PY{p}{:}
                 \PY{n}{trace} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{n}{xlb}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{xx}\PY{p}{,} \PY{n}{orientation} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{h}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{n}{color}\PY{p}{)}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                 \PY{n}{trace} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{n}{yy}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{xx}\PY{p}{,} \PY{n}{orientation} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{h}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{n}{color}\PY{p}{)}\PY{p}{)}
             \PY{k}{if} \PY{n}{return\PYZus{}trace}\PY{p}{:}
                 \PY{k}{return} \PY{n}{trace} 
             \PY{n}{layout} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{title}\PY{o}{=}\PY{n}{title}\PY{p}{,} \PY{n}{margin}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{l}\PY{o}{=}\PY{n}{lm}\PY{p}{)}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{n}{w}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{n}{h}\PY{p}{)}
             \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{n}{trace}\PY{p}{]}
             \PY{n}{fig} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Figure}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,} \PY{n}{layout}\PY{o}{=}\PY{n}{layout}\PY{p}{)}
             \PY{n}{iplot}\PY{p}{(}\PY{n}{fig}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{bar\PYZus{}hor\PYZus{}noagg}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{title}\PY{p}{,} \PY{n}{color}\PY{p}{,} \PY{n}{w}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{h}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{lm}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{limit}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{rt}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{)}\PY{p}{:}
             \PY{n}{trace} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{n}{x}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{y}\PY{p}{,} \PY{n}{orientation} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{h}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{n}{color}\PY{p}{)}\PY{p}{)}
             \PY{k}{if} \PY{n}{rt}\PY{p}{:}
                 \PY{k}{return} \PY{n}{trace}
             \PY{n}{layout} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{title}\PY{o}{=}\PY{n}{title}\PY{p}{,} \PY{n}{margin}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{l}\PY{o}{=}\PY{n}{lm}\PY{p}{)}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{n}{w}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{n}{h}\PY{p}{)}
             \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{n}{trace}\PY{p}{]}
             \PY{n}{fig} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Figure}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,} \PY{n}{layout}\PY{o}{=}\PY{n}{layout}\PY{p}{)}
             \PY{n}{iplot}\PY{p}{(}\PY{n}{fig}\PY{p}{)}
         
         
         \PY{k}{def} \PY{n+nf}{bar\PYZus{}ver\PYZus{}noagg}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{title}\PY{p}{,} \PY{n}{color}\PY{p}{,} \PY{n}{w}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{h}\PY{o}{=}\PY{n+nb+bp}{None}\PY{p}{,} \PY{n}{lm}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{rt} \PY{o}{=} \PY{n+nb+bp}{False}\PY{p}{)}\PY{p}{:}
             \PY{n}{trace} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{y}\PY{o}{=}\PY{n}{y}\PY{p}{,} \PY{n}{x}\PY{o}{=}\PY{n}{x}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{n}{color}\PY{p}{)}\PY{p}{)}
             \PY{k}{if} \PY{n}{rt}\PY{p}{:}
                 \PY{k}{return} \PY{n}{trace}
             \PY{n}{layout} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{title}\PY{o}{=}\PY{n}{title}\PY{p}{,} \PY{n}{margin}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{l}\PY{o}{=}\PY{n}{lm}\PY{p}{)}\PY{p}{,} \PY{n}{width}\PY{o}{=}\PY{n}{w}\PY{p}{,} \PY{n}{height}\PY{o}{=}\PY{n}{h}\PY{p}{)}
             \PY{n}{data} \PY{o}{=} \PY{p}{[}\PY{n}{trace}\PY{p}{]}
             \PY{n}{fig} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Figure}\PY{p}{(}\PY{n}{data}\PY{o}{=}\PY{n}{data}\PY{p}{,} \PY{n}{layout}\PY{o}{=}\PY{n}{layout}\PY{p}{)}
             \PY{n}{iplot}\PY{p}{(}\PY{n}{fig}\PY{p}{)}
             
         \PY{k}{def} \PY{n+nf}{gp}\PY{p}{(}\PY{n}{col}\PY{p}{,} \PY{n}{title}\PY{p}{)}\PY{p}{:}
             \PY{n}{df1} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TARGET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{]}
             \PY{n}{df0} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{TARGET}\PY{l+s+s2}{\PYZdq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{]}
             \PY{n}{a1} \PY{o}{=} \PY{n}{df1}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
             \PY{n}{b1} \PY{o}{=} \PY{n}{df0}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
             
             \PY{n}{total} \PY{o}{=} \PY{n+nb}{dict}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{n}{col}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}\PY{p}{)}
             \PY{n}{x0} \PY{o}{=} \PY{n}{a1}\PY{o}{.}\PY{n}{index}
             \PY{n}{x1} \PY{o}{=} \PY{n}{b1}\PY{o}{.}\PY{n}{index}
             
             \PY{n}{y0} \PY{o}{=} \PY{p}{[}\PY{n+nb}{float}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100} \PY{o}{/} \PY{n}{total}\PY{p}{[}\PY{n}{x0}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{]} \PY{k}{for} \PY{n}{i}\PY{p}{,}\PY{n}{x} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{a1}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{]}
             \PY{n}{y1} \PY{o}{=} \PY{p}{[}\PY{n+nb}{float}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{100} \PY{o}{/} \PY{n}{total}\PY{p}{[}\PY{n}{x1}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{]} \PY{k}{for} \PY{n}{i}\PY{p}{,}\PY{n}{x} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{b1}\PY{o}{.}\PY{n}{values}\PY{p}{)}\PY{p}{]}
         
             \PY{n}{trace1} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{a1}\PY{o}{.}\PY{n}{index}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{y0}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Target : 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}96D38C}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
             \PY{n}{trace2} \PY{o}{=} \PY{n}{go}\PY{o}{.}\PY{n}{Bar}\PY{p}{(}\PY{n}{x}\PY{o}{=}\PY{n}{b1}\PY{o}{.}\PY{n}{index}\PY{p}{,} \PY{n}{y}\PY{o}{=}\PY{n}{y1}\PY{p}{,} \PY{n}{name}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Target : 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{n+nb}{dict}\PY{p}{(}\PY{n}{color}\PY{o}{=}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZsh{}FEBFB3}\PY{l+s+s2}{\PYZdq{}}\PY{p}{)}\PY{p}{)}
             \PY{k}{return} \PY{n}{trace1}\PY{p}{,} \PY{n}{trace2} 
\end{Verbatim}


    
    
    Imbalance of Data

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}65}]:} \PY{n}{target\PYZus{}distribution} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{value\PYZus{}counts}\PY{p}{(}\PY{p}{)}
         \PY{n}{target\PYZus{}distribution}\PY{o}{.}\PY{n}{plot}\PY{o}{.}\PY{n}{pie}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}\PY{p}{,}
                                      \PY{n}{title}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Target Distribution}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                                      \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{15}\PY{p}{,} 
                                      \PY{n}{legend}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{,} 
                                      \PY{n}{autopct}\PY{o}{=}\PY{k}{lambda} \PY{n}{v}\PY{p}{:} \PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{\PYZob{}:0.1f\PYZcb{}}\PY{l+s+s2}{\PYZpc{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{v}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}65}]:} <matplotlib.axes.\_subplots.AxesSubplot at 0x109157990>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_111_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Correlations

    Now that we have dealt with the categorical variables and the outliers,
let's continue with the EDA. One way to try and understand the data is
by looking for correlations between the features and the target. We can
calculate the Pearson correlation coefficient between every variable and
the target using the \texttt{.corr} dataframe method.

The correlation coefficient is not the greatest method to represent
"relevance" of a feature, but it does give us an idea of possible
relationships within the data. Some
\href{http://www.statstutor.ac.uk/resources/uploaded/pearsons.pdf}{general
interpretations of the absolute value of the correlation coefficent}
are:

\begin{itemize}
\tightlist
\item
  .00-.19 ``very weak''
\item
  .20-.39 ``weak''
\item
  .40-.59 ``moderate''
\item
  .60-.79 ``strong''
\item
  .80-1.0 ``very strong''
\end{itemize}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}66}]:} \PY{c+c1}{\PYZsh{} Find correlations with the target and sort}
         \PY{n}{correlations} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{p}{)}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Display correlations}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Most Positive Correlations:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{correlations}\PY{o}{.}\PY{n}{tail}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{)}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{Most Negative Correlations:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{correlations}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
('Most Positive Correlations:\textbackslash{}n', OCCUPATION\_TYPE\_Laborers                             0.043019
FLAG\_DOCUMENT\_3                                      0.044346
REG\_CITY\_NOT\_LIVE\_CITY                               0.044395
FLAG\_EMP\_PHONE                                       0.045982
NAME\_EDUCATION\_TYPE\_Secondary / secondary special    0.049824
REG\_CITY\_NOT\_WORK\_CITY                               0.050994
DAYS\_ID\_PUBLISH                                      0.051457
CODE\_GENDER\_M                                        0.054713
DAYS\_LAST\_PHONE\_CHANGE                               0.055218
NAME\_INCOME\_TYPE\_Working                             0.057481
REGION\_RATING\_CLIENT                                 0.058899
REGION\_RATING\_CLIENT\_W\_CITY                          0.060893
DAYS\_EMPLOYED                                        0.074958
DAYS\_BIRTH                                           0.078239
TARGET                                               1.000000
Name: TARGET, dtype: float64)
('\textbackslash{}nMost Negative Correlations:\textbackslash{}n', EXT\_SOURCE\_2                           -0.160303
EXT\_SOURCE\_3                           -0.157397
EXT\_SOURCE\_1                           -0.099152
NAME\_EDUCATION\_TYPE\_Higher education   -0.056593
CODE\_GENDER\_F                          -0.054704
NAME\_INCOME\_TYPE\_Pensioner             -0.046209
DAYS\_EMPLOYED\_ANOM                     -0.045987
ORGANIZATION\_TYPE\_XNA                  -0.045987
EMERGENCYSTATE\_MODE\_No                 -0.042201
HOUSETYPE\_MODE\_block of flats          -0.040594
AMT\_GOODS\_PRICE                        -0.039628
REGION\_POPULATION\_RELATIVE             -0.037227
WALLSMATERIAL\_MODE\_Panel               -0.033119
AMT\_CREDIT                             -0.030369
FLOORSMAX\_AVG                          -0.029145
Name: TARGET, dtype: float64)

    \end{Verbatim}

    Let's take a look at some of more significant correlations: the
DAYS\_BIRTH is the most positive correlation. (except for TARGET because
the correlation of a variable with itself is always 1!) Looking at the
documentation, DAYS\_BIRTH is the age in days of the client at the time
of the loan in negative days (for whatever reason!). The correlation is
positive, but the value of this feature is actually negative, meaning
that as the client gets older, they are less likely to default on their
loan (ie the target == 0). That's a little confusing, so we will take
the absolute value of the feature and then the correlation will be
negative.

    Effect of Age on Repayment

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}67}]:} \PY{c+c1}{\PYZsh{} Find the correlation of the positive days since birth and target}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n+nb}{abs}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}67}]:} -0.07823930830982706
\end{Verbatim}
            
    As the client gets older, there is a negative linear relationship with
the target meaning that as clients get older, they tend to repay their
loans on time more often.

Let's start looking at this variable. First, we can make a histogram of
the age. We will put the x axis in years to make the plot a little more
understandable.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}68}]:} \PY{c+c1}{\PYZsh{} Set the style of plots}
         \PY{n}{plt}\PY{o}{.}\PY{n}{style}\PY{o}{.}\PY{n}{use}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{fivethirtyeight}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Plot the distribution of ages in years}
         \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{365}\PY{p}{,} \PY{n}{edgecolor} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{bins} \PY{o}{=} \PY{l+m+mi}{25}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age of Client}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age (years)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Count}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_119_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    By itself, the distribution of age does not tell us much other than that
there are no outliers as all the ages are reasonable. To visualize the
effect of the age on the target, we will next make a kernel density
estimation plot (KDE) colored by the value of the target. A kernel
density estimate plot shows the distribution of a single variable and
can be thought of as a smoothed histogram (it is created by computing a
kernel, usually a Gaussian, at each data point and then averaging all
the individual kernels to develop a single smooth curve). We will use
the seaborn kdeplot for this graph.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}69}]:} \PY{k+kn}{import} \PY{n+nn}{seaborn} \PY{k+kn}{as} \PY{n+nn}{sns}
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} KDE plot of loans that were repaid on time}
         \PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{365}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target == 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} KDE plot of loans which were not repaid on time}
         \PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{365}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target == 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Labeling of plot}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age (years)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Density}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Distribution of Ages}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_121_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    The target == 1 curve skews towards the younger end of the range.
Although this is not a significant correlation (-0.07 correlation
coefficient), this variable is likely going to be useful in a machine
learning model because it does affect the target. Let's look at this
relationship in another way: average failure to repay loans by age
bracket.

To make this graph, first we cut the age category into bins of 5 years
each. Then, for each bin, we calculate the average value of the target,
which tells us the ratio of loans that were not repaid in each age
category.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}70}]:} \PY{c+c1}{\PYZsh{} Age information into a separate dataframe}
         \PY{n}{age\PYZus{}data} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
         \PY{n}{age\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{age\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{/} \PY{l+m+mi}{365}
         
         \PY{c+c1}{\PYZsh{} Bin the age data}
         \PY{n}{age\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BINNED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{cut}\PY{p}{(}\PY{n}{age\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{bins} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{70}\PY{p}{,} \PY{n}{num} \PY{o}{=} \PY{l+m+mi}{11}\PY{p}{)}\PY{p}{)}
         \PY{n}{age\PYZus{}data}\PY{o}{.}\PY{n}{head}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}70}]:}    TARGET  DAYS\_BIRTH  YEARS\_BIRTH  YEARS\_BINNED
         0       1        9461    25.920548  (25.0, 30.0]
         1       0       16765    45.931507  (45.0, 50.0]
         2       0       19046    52.180822  (50.0, 55.0]
         3       0       19005    52.068493  (50.0, 55.0]
         4       0       19932    54.608219  (50.0, 55.0]
         5       0       16941    46.413699  (45.0, 50.0]
         6       0       13778    37.747945  (35.0, 40.0]
         7       0       18850    51.643836  (50.0, 55.0]
         8       0       20099    55.065753  (55.0, 60.0]
         9       0       14469    39.641096  (35.0, 40.0]
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}71}]:} \PY{c+c1}{\PYZsh{} Group by the bin and calculate averages}
         \PY{n}{age\PYZus{}groups}  \PY{o}{=} \PY{n}{age\PYZus{}data}\PY{o}{.}\PY{n}{groupby}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BINNED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{p}{)}
         \PY{n}{age\PYZus{}groups}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}71}]:}                 TARGET    DAYS\_BIRTH  YEARS\_BIRTH
         YEARS\_BINNED                                     
         (20.0, 25.0]  0.123036   8532.795625    23.377522
         (25.0, 30.0]  0.111436  10155.219250    27.822518
         (30.0, 35.0]  0.102814  11854.848377    32.479037
         (35.0, 40.0]  0.089414  13707.908253    37.555913
         (40.0, 45.0]  0.078491  15497.661233    42.459346
         (45.0, 50.0]  0.074171  17323.900441    47.462741
         (50.0, 55.0]  0.066968  19196.494791    52.593136
         (55.0, 60.0]  0.055314  20984.262742    57.491131
         (60.0, 65.0]  0.052737  22780.547460    62.412459
         (65.0, 70.0]  0.037270  24292.614340    66.555108
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}72}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{8}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Graph the age bins and the average of the target as a bar plot}
         \PY{n}{plt}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{n}{age\PYZus{}groups}\PY{o}{.}\PY{n}{index}\PY{o}{.}\PY{n}{astype}\PY{p}{(}\PY{n+nb}{str}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{100} \PY{o}{*} \PY{n}{age\PYZus{}groups}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Plot labeling}
         \PY{n}{plt}\PY{o}{.}\PY{n}{xticks}\PY{p}{(}\PY{n}{rotation} \PY{o}{=} \PY{l+m+mi}{75}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Age Group (years)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Failure to Repay (}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Failure to Repay by Age Group}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_125_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    There is a clear trend: younger applicants are more likely to not repay
the loan! The rate of failure to repay is above 10\% for the youngest
three age groups and beolow 5\% for the oldest age group. This is
information that could be directly used by the bank: because younger
clients are less likely to repay the loan, maybe they should be provided
with more guidance or financial planning tips. This does not mean the
bank should discriminate against younger clients, but it would be smart
to take precautionary measures to help younger clients pay on time.

    Exterior Sources

    Exterior Sources The 3 variables with the strongest negative
correlations with the target are EXT\_SOURCE\_1, EXT\_SOURCE\_2, and
EXT\_SOURCE\_3. According to the documentation, these features represent
a "normalized score from external data source". I'm not sure what this
exactly means, but it may be a cumulative sort of credit rating made
using numerous sources of data.

Let's take a look at these variables.

First, we can show the correlations of the EXT\_SOURCE features with the
target and with each other.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}73}]:} \PY{c+c1}{\PYZsh{} Extract the EXT\PYZus{}SOURCE variables and show correlations}
         \PY{n}{ext\PYZus{}data} \PY{o}{=} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}EMPLOYED}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{NAME\PYZus{}EDUCATION\PYZus{}TYPE\PYZus{}Higher education}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{CODE\PYZus{}GENDER\PYZus{}F}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{]}
         \PY{n}{ext\PYZus{}data\PYZus{}corrs} \PY{o}{=} \PY{n}{ext\PYZus{}data}\PY{o}{.}\PY{n}{corr}\PY{p}{(}\PY{p}{)}
         \PY{n}{ext\PYZus{}data\PYZus{}corrs}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{25}\PY{p}{,} \PY{l+m+mi}{36}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}73}]:} <matplotlib.figure.Figure at 0x1a0bfe6350>
\end{Verbatim}
            
    
    \begin{verbatim}
<matplotlib.figure.Figure at 0x1a0bfe6350>
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}74}]:} \PY{c+c1}{\PYZsh{} Heatmap of correlations}
         \PY{n}{sns}\PY{o}{.}\PY{n}{heatmap}\PY{p}{(}\PY{n}{ext\PYZus{}data\PYZus{}corrs}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{RdYlBu\PYZus{}r}\PY{p}{,} \PY{n}{vmin} \PY{o}{=} \PY{o}{\PYZhy{}}\PY{l+m+mf}{0.02}\PY{p}{,} \PY{n}{annot} \PY{o}{=} \PY{n+nb+bp}{True}\PY{p}{,} \PY{n}{vmax} \PY{o}{=} \PY{l+m+mf}{0.5}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Correlation Heatmap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_130_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    All three EXT\_SOURCE featureshave negative correlations with the
target, indicating that as the value of the EXT\_SOURCE increases, the
client is more likely to repay the loan. We can also see that
DAYS\_BIRTH is positively correlated with EXT\_SOURCE\_1 indicating that
maybe one of the factors in this score is the client age.

Next we can look at the distribution of each of these features colored
by the value of the target. This will let us visualize the effect of
this variable on the target.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}75}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize} \PY{o}{=} \PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{l+m+mi}{12}\PY{p}{)}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} iterate through the sources}
         \PY{k}{for} \PY{n}{i}\PY{p}{,} \PY{n}{source} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}3}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
             
             \PY{c+c1}{\PYZsh{} create a new subplot for each source}
             \PY{n}{plt}\PY{o}{.}\PY{n}{subplot}\PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{i} \PY{o}{+} \PY{l+m+mi}{1}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} plot repaid loans}
             \PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{,} \PY{n}{source}\PY{p}{]}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target == 0}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{c+c1}{\PYZsh{} plot loans that were not repaid}
             \PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{source}\PY{p}{]}\PY{p}{,} \PY{n}{label} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{target == 1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} Label the plots}
             \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Distribution of }\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s1}{ by Target Value}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{source}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+si}{\PYZpc{}s}\PY{l+s+s1}{\PYZsq{}} \PY{o}{\PYZpc{}} \PY{n}{source}\PY{p}{)}\PY{p}{;} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Density}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
             
         \PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{n}{h\PYZus{}pad} \PY{o}{=} \PY{l+m+mf}{2.5}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_132_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    EXT\_SOURCE\_3 displays the greatest difference between the values of
the target. We can clearly see that this feature has some relationship
to the likelihood of an applicant to repay a loan. The relationship is
not very strong (in fact they are all considered very weak, but these
variables will still be useful for a machine learning model to predict
whether or not an applicant will repay a loan on time.

    Pairs Plot

    As a final exploratory plot, we can make a pairs plot of the
\texttt{EXT\_SOURCE} variables and the \texttt{DAYS\_BIRTH} variable.
The
\href{https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166}{Pairs
Plot} is a great exploration tool because it lets us see relationships
between multiple pairs of variables as well as distributions of single
variables. Here we are using the seaborn visualization library and the
PairGrid function to create a Pairs Plot with scatterplots on the upper
triangle, histograms on the diagonal, and 2D kernel density plots and
correlation coefficients on the lower triangle.

If you don't understand this code, that's all right! Plotting in Python
can be overly complex, and for anything beyond the simplest graphs, I
usually find an existing implementation and adapt the code (don't repeat
yourself)!

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}115}]:} \PY{c+c1}{\PYZsh{} Copy the data for plotting}
          \PY{n}{plot\PYZus{}data} \PY{o}{=} \PY{n}{ext\PYZus{}data}\PY{o}{.}\PY{n}{drop}\PY{p}{(}\PY{n}{columns} \PY{o}{=} \PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{copy}\PY{p}{(}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Add in the age of the client in years}
          \PY{n}{plot\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{age\PYZus{}data}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{YEARS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}
          
          \PY{c+c1}{\PYZsh{} Drop na values and limit to first 100000 rows}
          \PY{n}{plot\PYZus{}data} \PY{o}{=} \PY{n}{plot\PYZus{}data}\PY{o}{.}\PY{n}{dropna}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{loc}\PY{p}{[}\PY{p}{:}\PY{l+m+mi}{100000}\PY{p}{,} \PY{p}{:}\PY{p}{]}
          
          \PY{c+c1}{\PYZsh{} Function to calculate correlation coefficient between two columns}
          \PY{k}{def} \PY{n+nf}{corr\PYZus{}func}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{o}{*}\PY{o}{*}\PY{n}{kwargs}\PY{p}{)}\PY{p}{:}
              \PY{n}{r} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{corrcoef}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}
              \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{gca}\PY{p}{(}\PY{p}{)}
              \PY{n}{ax}\PY{o}{.}\PY{n}{annotate}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{r = \PYZob{}:.2f\PYZcb{}}\PY{l+s+s2}{\PYZdq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{r}\PY{p}{)}\PY{p}{,}
                          \PY{n}{xy}\PY{o}{=}\PY{p}{(}\PY{o}{.}\PY{l+m+mi}{2}\PY{p}{,} \PY{o}{.}\PY{l+m+mi}{8}\PY{p}{)}\PY{p}{,} \PY{n}{xycoords}\PY{o}{=}\PY{n}{ax}\PY{o}{.}\PY{n}{transAxes}\PY{p}{,}
                          \PY{n}{size} \PY{o}{=} \PY{l+m+mi}{20}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Create the pairgrid object}
          \PY{n}{grid} \PY{o}{=} \PY{n}{sns}\PY{o}{.}\PY{n}{PairGrid}\PY{p}{(}\PY{n}{data} \PY{o}{=} \PY{n}{plot\PYZus{}data}\PY{p}{,} \PY{n}{size} \PY{o}{=} \PY{l+m+mi}{3}\PY{p}{,} \PY{n}{diag\PYZus{}sharey}\PY{o}{=}\PY{n+nb+bp}{False}\PY{p}{,}
                              \PY{n}{hue} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} 
                              \PY{n+nb}{vars} \PY{o}{=} \PY{p}{[}\PY{n}{x} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n+nb}{list}\PY{p}{(}\PY{n}{plot\PYZus{}data}\PY{o}{.}\PY{n}{columns}\PY{p}{)} \PY{k}{if} \PY{n}{x} \PY{o}{!=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Upper is a scatter plot}
          \PY{n}{grid}\PY{o}{.}\PY{n}{map\PYZus{}upper}\PY{p}{(}\PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{,} \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.2}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Diagonal is a histogram}
          \PY{n}{grid}\PY{o}{.}\PY{n}{map\PYZus{}diag}\PY{p}{(}\PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Bottom is density plot}
          \PY{n}{grid}\PY{o}{.}\PY{n}{map\PYZus{}lower}\PY{p}{(}\PY{n}{sns}\PY{o}{.}\PY{n}{kdeplot}\PY{p}{,} \PY{n}{cmap} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{cm}\PY{o}{.}\PY{n}{OrRd\PYZus{}r}\PY{p}{)}\PY{p}{;}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{suptitle}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Ext Source and Age Features Pairs Plot}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{size} \PY{o}{=} \PY{l+m+mi}{32}\PY{p}{,} \PY{n}{y} \PY{o}{=} \PY{l+m+mf}{1.05}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_136_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    In this plot, the red indicates loans that were not repaid and the blue
are loans that are paid. We can see the different relationships within
the data. There does appear to be a moderate positive linear
relationship between the \texttt{EXT\_SOURCE\_1} and the
\texttt{DAYS\_BIRTH} (or equivalently \texttt{YEARS\_BIRTH}), indicating
that this feature may take into account the age of the client.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}94}]:} \PY{n}{n}\PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{)}
         \PY{k}{print}\PY{p}{(}\PY{n}{n}\PY{p}{)}
         \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)} 
         \PY{k}{print} \PY{p}{(}\PY{n}{y}\PY{p}{)}
         
         \PY{n}{\PYZus{}}\PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{marker} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{\PYZus{}}\PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Customer Credibility to Repay Loan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{\PYZus{}}\PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ECDF}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{\PYZus{}}\PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{margins}\PY{p}{(}\PY{o}{.}\PY{l+m+mo}{02}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
307511
[3.25191619e-06 6.50383238e-06 9.75574857e-06 {\ldots} 9.99993496e-01
 9.99996748e-01 1.00000000e+00]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_138_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}95}]:} \PY{c+c1}{\PYZsh{} Checking ECDF Distribution of Ability to Repay Loan across the real data and theoretical samples of data}
         \PY{k}{def} \PY{n+nf}{ecdf}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{:}
             \PY{n}{x}\PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{data}\PY{p}{)}
             \PY{n}{n}\PY{o}{=} \PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{)}
             \PY{n}{y} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{n}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n}{n}
             \PY{k}{return} \PY{n}{x}\PY{p}{,}\PY{n}{y}
         
         \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
         \PY{n}{plt}\PY{o}{.}\PY{n}{figure}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{25}\PY{p}{,}\PY{l+m+mi}{20}\PY{p}{)}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Seed the random number generator:}
         \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{15}\PY{p}{)}
         \PY{c+c1}{\PYZsh{}Sample data for theortical normal dist}
         \PY{n}{samples} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{TARGET}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{TARGET}\PY{p}{)}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{10000}\PY{p}{)}
         \PY{n}{samples}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}95}]:} array([-0.00435514,  0.17315615,  0.0382565 , {\ldots},  0.28558261,
                -0.14273527,  0.07132198])
\end{Verbatim}
            
    
    \begin{verbatim}
<matplotlib.figure.Figure at 0x1a45ff2ad0>
    \end{verbatim}

    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}96}]:} \PY{c+c1}{\PYZsh{}find ecdf of data}
         \PY{n}{x\PYZus{}count}\PY{p}{,} \PY{n}{y\PYZus{}count} \PY{o}{=} \PY{n}{ecdf}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{o}{.}\PY{n}{TARGET}\PY{p}{)}
         \PY{n}{x\PYZus{}theor}\PY{p}{,} \PY{n}{y\PYZus{}theor} \PY{o}{=} \PY{n}{ecdf}\PY{p}{(}\PY{n}{samples}\PY{p}{)}
         
         \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x\PYZus{}count}\PY{p}{,} \PY{n}{y\PYZus{}count}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x\PYZus{}theor}\PY{p}{,} \PY{n}{y\PYZus{}theor}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Label axes and add legend and a title:}
         \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Customer Credibility to Repay Loan VS Theoretical Normal Dist}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Customer to Repay Loan}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{fig} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ECDF}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} Save and display the plots:}
         \PY{c+c1}{\PYZsh{}plt.savefig(\PYZsq{}reports/figures/cdf\PYZus{}body\PYZus{}temps.png\PYZsq{})}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_140_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Compare the distribution of the data to the theoretical distribution of
the data. This is done by comparing the ecdf First define a function for
computing the ecdf from a data set. Next use np.random.normal to sample
the theoretical normal distribution and overlay the ecdf of both data
sets to compare distribution. Since theoretical ECDF is continuous curve
while real data set is contiguous bar for 0 \& 1 since it's
classification problem but we may consider any data points closer to
value '0' indicates 'will repay loan on time', 1 (will have difficulty
repaying loan)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}97}]:} \PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{l+m+mi}{25}\PY{p}{,} \PY{l+m+mi}{50}\PY{p}{,} \PY{l+m+mi}{75}\PY{p}{,} \PY{l+m+mi}{90}\PY{p}{,} \PY{l+m+mi}{98}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}97}]:} array([0., 0., 0., 0., 1., 1.])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}98}]:} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{,} \PY{n}{column}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}98}]:} array([[<matplotlib.axes.\_subplots.AxesSubplot object at 0x1a36675210>]],
               dtype=object)
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_143_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
     Variance

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}99}]:} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}99}]:} 0.0742116771655796
\end{Verbatim}
            
     Standard Deviation

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}100}]:} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}100}]:} 0.27241820270602257
\end{Verbatim}
            
     Covariance

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}101}]:} \PY{n}{np}\PY{o}{.}\PY{n}{cov}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}101}]:} array([[ 0.07421192, -0.0037652 ],
                 [-0.0037652 ,  0.01943096]])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}102}]:} \PY{n}{np}\PY{o}{.}\PY{n}{cov}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}102}]:} array([[ 7.42119185e-02, -9.30133834e+01],
                 [-9.30133834e+01,  1.90443968e+07]])
\end{Verbatim}
            
     Pearson Correlation Coeffient

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}103}]:} \PY{n}{np}\PY{o}{.}\PY{n}{corrcoef}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{DAYS\PYZus{}BIRTH}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}103}]:} array([[ 1.        , -0.07823931],
                 [-0.07823931,  1.        ]])
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}104}]:} \PY{c+c1}{\PYZsh{}\PYZlt{}b\PYZgt{} Is the sample size large? Are the observations independent?}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}105}]:} \PY{c+c1}{\PYZsh{} print(\PYZsq{}We have\PYZsq{}, len(df\PYZus{}train), \PYZsq{}samples across\PYZsq{}, len(list(df\PYZus{}train.columns)), \PYZsq{}features.\PYZsq{})}
          \PY{c+c1}{\PYZsh{} \PYZsh{} confirmed here: https://ww2.amstat.org/publications/jse/datasets/normtemp.txt}
          
          \PY{c+c1}{\PYZsh{} print(df\PYZus{}train.groupby([\PYZsq{}CODE\PYZus{}GENDER\PYZsq{}]).count(), df\PYZus{}train.info())}
\end{Verbatim}


    Confidence Interval

     Step 1: Build a function to create a bootstrap replicate

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}106}]:} \PY{k}{def} \PY{n+nf}{bootstrap\PYZus{}replicate\PYZus{}1d}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{func}\PY{p}{)}\PY{p}{:}
              \PY{k}{return} \PY{n}{func}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}\PY{p}{)}
          \PY{c+c1}{\PYZsh{}np.random.choice() works on linear model}
\end{Verbatim}


     Step 2: Another function to generate multiple such bootstrap samples

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}107}]:} \PY{k}{def} \PY{n+nf}{draw\PYZus{}bs\PYZus{}reps}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{func}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Draw bootstrap replicates.\PYZdq{}\PYZdq{}\PYZdq{}}
          
              \PY{c+c1}{\PYZsh{} Initialize array of replicates: bs\PYZus{}replicates}
              \PY{n}{bs\PYZus{}replicates} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{empty}\PY{p}{(}\PY{n}{size}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Generate replicates}
              \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{size}\PY{p}{)}\PY{p}{:}
                  \PY{n}{bs\PYZus{}replicates}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{bootstrap\PYZus{}replicate\PYZus{}1d}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{func}\PY{p}{)}
          
              \PY{k}{return} \PY{n}{bs\PYZus{}replicates}
\end{Verbatim}


     Step 3: Plot the histogram for bootstrap replicates

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}108}]:} \PY{c+c1}{\PYZsh{} Take 10,000 bootstrap replicates of the mean: bs\PYZus{}replicates}
          \PY{n}{bs\PYZus{}replicates} \PY{o}{=} \PY{n}{draw\PYZus{}bs\PYZus{}reps}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{,} \PY{l+m+mi}{10000}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Compute and print SEM Standard Error of the Mean}
          \PY{n}{sem} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
          \PY{k}{print}\PY{p}{(}\PY{n}{sem}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Compute and print standard deviation of bootstrap replicates}
          \PY{n}{bs\PYZus{}std} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{bs\PYZus{}replicates}\PY{p}{)}
          \PY{k}{print}\PY{p}{(}\PY{n}{bs\PYZus{}std}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Make a histogram of the results}
          \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{bs\PYZus{}replicates}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{normed}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
          \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Credit Loan Default Risk}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ECDF}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Show the plot}
          \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
0.0004912536560492155
0.0004897216997795728

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_161_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
     This is bootstrap estimate of the probability distribution function of
the mean of 'Credit Loan Default Risk'at the Home Credit Group.
Remember, we are estimating the mean 'Credit Loan Default Risk' we would
get if the Home Credit Group could repeat all of the measurements over
and over again. This is a probabilistic estimate of the mean. I plot the
PDF as a histogram, and I see that it is not Normal as it has slightly
longer right tail.

In fact, it can be shown theoretically that under not-too-restrictive
conditions, the value of the mean will always be Normally distributed.
(This does not hold in general, just for the mean and a few other
statistics.) The standard deviation of this distribution, called the
standard error of the mean, or SEM, is given by the standard deviation
of the data divided by the square root of the number of data points.
I.e., for a data set. Notice that the SEM we got from the known
expression and the bootstrap replicates is the same and the distribution
of the bootstrap replicates of the mean is Normal.

     Assuming 95\% Confidence interval i.e. give the 2.5th and 97.5th
percentile of bootstrap replicates is stored as bs\_replicates

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}110}]:} \PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{bs\PYZus{}replicates}\PY{p}{,} \PY{p}{[}\PY{l+m+mf}{2.5}\PY{p}{,} \PY{l+m+mf}{97.5}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}110}]:} array([0.07979544, 0.08170765])
\end{Verbatim}
            
     The above steps may be repeated to show for Variance function as well

     Extending Confidence Interval Concept to Pairs Bootstrap

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}111}]:} \PY{c+c1}{\PYZsh{}Finding pairs bootstrap for slope \PYZam{} intercept of a linear function between Bike REntal Count and Registered User Type}
          \PY{k}{def} \PY{n+nf}{draw\PYZus{}bs\PYZus{}pairs\PYZus{}linreg}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Perform pairs bootstrap for linear regression.\PYZdq{}\PYZdq{}\PYZdq{}}
          
              \PY{c+c1}{\PYZsh{} Set up array of indices to sample from: inds}
              \PY{n}{inds} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Initialize replicates: bs\PYZus{}slope\PYZus{}reps, bs\PYZus{}intercept\PYZus{}reps}
              \PY{n}{bs\PYZus{}slope\PYZus{}reps} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{empty}\PY{p}{(}\PY{n}{size}\PY{p}{)}
              \PY{n}{bs\PYZus{}intercept\PYZus{}reps} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{empty}\PY{p}{(}\PY{n}{size}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Generate replicates}
              \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{size}\PY{p}{)}\PY{p}{:}
                  \PY{n}{bs\PYZus{}inds} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{inds}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{inds}\PY{p}{)}\PY{p}{)}
                  \PY{n}{bs\PYZus{}x}\PY{p}{,} \PY{n}{bs\PYZus{}y} \PY{o}{=} \PY{n}{x}\PY{p}{[}\PY{n}{bs\PYZus{}inds}\PY{p}{]}\PY{p}{,} \PY{n}{y}\PY{p}{[}\PY{n}{bs\PYZus{}inds}\PY{p}{]}
                  \PY{n}{bs\PYZus{}slope\PYZus{}reps}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{bs\PYZus{}intercept\PYZus{}reps}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{polyfit}\PY{p}{(}\PY{n}{bs\PYZus{}x}\PY{p}{,} \PY{n}{bs\PYZus{}y}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
          
              \PY{k}{return} \PY{n}{bs\PYZus{}slope\PYZus{}reps}\PY{p}{,} \PY{n}{bs\PYZus{}intercept\PYZus{}reps}
          
          \PY{c+c1}{\PYZsh{} Generate replicates of slope and intercept using pairs bootstrap}
          \PY{n}{bs\PYZus{}slope\PYZus{}reps}\PY{p}{,} \PY{n}{bs\PYZus{}intercept\PYZus{}reps} \PY{o}{=} \PY{n}{draw\PYZus{}bs\PYZus{}pairs\PYZus{}linreg}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{TARGET}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{l+m+mi}{1000}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Compute and print 95\PYZpc{} CI for slope}
          \PY{k}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{bs\PYZus{}slope\PYZus{}reps}\PY{p}{,} \PY{p}{[}\PY{l+m+mf}{2.5}\PY{p}{,} \PY{l+m+mf}{97.5}\PY{p}{]}\PY{p}{)}\PY{p}{)}
          \PY{c+c1}{\PYZsh{} Plot the histogram}
          \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{bs\PYZus{}slope\PYZus{}reps}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{normed}\PY{o}{=}\PY{n+nb+bp}{True}\PY{p}{)}
          \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{slope}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{PDF}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[-0.20051359 -0.1864092 ]

    \end{Verbatim}

    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_167_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Hypothesis Testing

     Null Hypothesis- There is no significant difference between
EXT\_SOURCE\_1 and EXT\_SOURCE\_2 mean on 'Ability to Repay Loan' H0:
EXT\_SOURCE\_1EXT\_SOURCE\_2=0 Significance Level: 95\% Confidence
=0.05 Alternate Hypothesis - There is significant difference between
EXT\_SOURCE\_1 and EXT\_SOURCE\_2 mean on 'Ability to Repay Loan' HA :
EXT\_SOURCE\_1EXT\_SOURCE\_2 != 0

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}113}]:} \PY{k}{def} \PY{n+nf}{permutation\PYZus{}sample}\PY{p}{(}\PY{n}{data1}\PY{p}{,} \PY{n}{data2}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}Generate a permutation sample from two data sets.\PYZdq{}\PYZdq{}\PYZdq{}}
          
              \PY{c+c1}{\PYZsh{} Concatenate the data sets: data}
              \PY{n}{data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{concatenate}\PY{p}{(}\PY{p}{(}\PY{n}{data1}\PY{p}{,} \PY{n}{data2}\PY{p}{)}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Permute the concatenated array: permuted\PYZus{}data}
              \PY{n}{permuted\PYZus{}data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{permutation}\PY{p}{(}\PY{n}{data}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Split the permuted array into two: perm\PYZus{}sample\PYZus{}1, perm\PYZus{}sample\PYZus{}2}
              \PY{n}{perm\PYZus{}sample\PYZus{}1} \PY{o}{=} \PY{n}{permuted\PYZus{}data}\PY{p}{[}\PY{p}{:}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data1}\PY{p}{)}\PY{p}{]}
              \PY{n}{perm\PYZus{}sample\PYZus{}2} \PY{o}{=} \PY{n}{permuted\PYZus{}data}\PY{p}{[}\PY{n+nb}{len}\PY{p}{(}\PY{n}{data1}\PY{p}{)}\PY{p}{:}\PY{p}{]}
          
              \PY{k}{return} \PY{n}{perm\PYZus{}sample\PYZus{}1}\PY{p}{,} \PY{n}{perm\PYZus{}sample\PYZus{}2}
          
          \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{50}\PY{p}{)}\PY{p}{:}
              \PY{c+c1}{\PYZsh{} Generate permutation samples}
              \PY{n}{perm\PYZus{}sample\PYZus{}1}\PY{p}{,} \PY{n}{perm\PYZus{}sample\PYZus{}2} \PY{o}{=} \PY{n}{permutation\PYZus{}sample}\PY{p}{(}
                                              \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          
              \PY{c+c1}{\PYZsh{} Compute and plot ECDF from permutation sample 1 }
              \PY{n}{x1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{perm\PYZus{}sample\PYZus{}1}\PY{p}{)}
              \PY{n}{y1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{p}{)} 
              
              \PY{c+c1}{\PYZsh{} Compute and plot ECDF from permutation sample 2}
              \PY{n}{x2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{perm\PYZus{}sample\PYZus{}2}\PY{p}{)}
              \PY{n}{y2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)}
          
          
              \PY{c+c1}{\PYZsh{} Plot ECDFs of permutation sample}
              \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{y1}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                           \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.02}\PY{p}{)}
              \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x2}\PY{p}{,} \PY{n}{y2}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{linestyle}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{none}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}
                           \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.02}\PY{p}{)}
          \PY{c+c1}{\PYZsh{} Compute and plot ECDF from original \PYZsq{}registered\PYZsq{}}
          \PY{n}{x11} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}1}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{y11} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x11}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x11}\PY{p}{)}\PY{p}{)} 
          
          \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x11}\PY{p}{,} \PY{n}{y11}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Compute and plot ECDF from original \PYZsq{}casual\PYZsq{}}
          \PY{n}{x22} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sort}\PY{p}{(}\PY{n}{df\PYZus{}train}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{EXT\PYZus{}SOURCE\PYZus{}2}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
          \PY{n}{y22} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x22}\PY{p}{)}\PY{o}{+}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{/}\PY{n+nb}{float}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{x22}\PY{p}{)}\PY{p}{)} 
          
          \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x22}\PY{p}{,} \PY{n}{y22}\PY{p}{,} \PY{n}{marker}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{.}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{blue}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{c+c1}{\PYZsh{} Make margins and label axes}
          \PY{n}{plt}\PY{o}{.}\PY{n}{margins}\PY{p}{(}\PY{l+m+mf}{0.02}\PY{p}{)}
          \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{External Data Source Influence}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{ECDF}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} Show the plot}
          \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_170_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
     Permutation samples ECDFs overlap and give a purple haze. Few of the
ECDFs from the permutation samples overlap with the observed External
Source Data1 data towards right of the graph \& even fewer overlap
towards left, suggesting that the hypothesis is not commensurate with
the data. External Source Data1 \& External Source Data2 are not
identically distributed and do not influence data in similar way. So
Null Hypothesis is rejected.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
